{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 라이브러리 선언및 데이터 불러오기 (타입통합/숫자컬럼추가)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 정의 import tensorflow.keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONID</th>\n",
       "      <th>PRODUCTGROUP</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>YEARWEEK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>QTY</th>\n",
       "      <th>HOLIDAY</th>\n",
       "      <th>HCLUS</th>\n",
       "      <th>PROMOTION</th>\n",
       "      <th>PRO_PERCENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201501</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1225</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.209442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201502</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>968</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.209442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGIONID PRODUCTGROUP      PRODUCT      ITEM  YEARWEEK  YEAR  WEEK  \\\n",
       "0  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201501  2015     1   \n",
       "1  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201502  2015     2   \n",
       "\n",
       "    QTY HOLIDAY  HCLUS PROMOTION  PRO_PERCENT  \n",
       "0  1225       Y      1         Y     0.209442  \n",
       "1   968       N      4         Y     0.209442  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresData = pd.read_csv(\"../dataset/feature_regression_example.csv\")\n",
    "featuresData.dtypes\n",
    "featuresData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le_yn = LabelEncoder()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresData[\"LE_PROMO\"] = le_yn.fit_transform(featuresData.PROMOTION)\n",
    "featuresData[\"LE_HORI\"] = le_yn.fit_transform(featuresData.HOLIDAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n",
       "       'Y', 'N', 'N', 'N', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y',\n",
       "       'Y', 'Y', 'Y', 'N', 'N', 'N', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N',\n",
       "       'N', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y',\n",
       "       'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y',\n",
       "       'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'N', 'Y', 'Y', 'Y', 'Y', 'N', 'Y',\n",
       "       'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y',\n",
       "       'Y', 'Y', 'Y', 'Y', 'N', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y', 'Y',\n",
       "       'Y', 'N', 'N'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le_yn.inverse_transform(featuresData.LE_PROMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONID</th>\n",
       "      <th>PRODUCTGROUP</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>YEARWEEK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>QTY</th>\n",
       "      <th>HOLIDAY</th>\n",
       "      <th>HCLUS</th>\n",
       "      <th>PROMOTION</th>\n",
       "      <th>PRO_PERCENT</th>\n",
       "      <th>LE_PROMO</th>\n",
       "      <th>LE_HORI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201501</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1225</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.209442</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201502</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>968</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.209442</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201503</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>1209</td>\n",
       "      <td>N</td>\n",
       "      <td>4</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.208155</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201504</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>1810</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.208155</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGIONID PRODUCTGROUP      PRODUCT      ITEM  YEARWEEK  YEAR  WEEK  \\\n",
       "0  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201501  2015     1   \n",
       "1  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201502  2015     2   \n",
       "2  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201503  2015     3   \n",
       "3  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201504  2015     4   \n",
       "\n",
       "    QTY HOLIDAY  HCLUS PROMOTION  PRO_PERCENT  LE_PROMO  LE_HORI  \n",
       "0  1225       Y      1         Y     0.209442         1        1  \n",
       "1   968       N      4         Y     0.209442         1        0  \n",
       "2  1209       N      4         Y     0.208155         1        0  \n",
       "3  1810       Y      2         Y     0.208155         1        1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featuresData.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특성전정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = list(featuresData.select_dtypes(np.number).columns)\n",
    "# features\n",
    "label = ['QTY']\n",
    "# features= list(set(featuresData.select_dtypes(np.number).columns) - set(label))\n",
    "# features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrdf = featuresData.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = list(corrdf[(abs(corrdf.QTY) > 0.5) & (corrdf.QTY <1)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['HCLUS', 'PRO_PERCENT', 'LE_PROMO', 'LE_HORI']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdIndex= int(len(featuresData)*0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "201633"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stdYearweek = featuresData.loc[stdIndex,\"YEARWEEK\"]\n",
    "stdYearweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_features = featuresData[featuresData.YEARWEEK <= stdYearweek ][features]\n",
    "trainingData_label = featuresData[featuresData.YEARWEEK <= stdYearweek ][label]\n",
    "testData_features = featuresData[featuresData.YEARWEEK > stdYearweek ][features]\n",
    "testData_label= featuresData[featuresData.YEARWEEK > stdYearweek ][label]\n",
    "testData_all = featuresData[featuresData.YEARWEEK > stdYearweek]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 86 21 21 21\n"
     ]
    }
   ],
   "source": [
    "print(len(trainingData_features), len(trainingData_label), len(testData_features), len(testData_label),len(testData_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QTY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     QTY\n",
       "86  1700\n",
       "87  1514\n",
       "88  1501\n",
       "89  1491\n",
       "90   806"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData_label.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputDim = trainingData_features.loc[0,:].shape\n",
    "inputDim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=8, activation=\"relu\",input_shape=inputDim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=8, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_model(model,show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 컴파일(훈련 준비 전단계)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer = optimizers.Adam(), metrics=['mean_squared_error','mean_absolute_error'])\n",
    "#model.compile(loss=\"mean_squared_error\", optimizers = \"adam\", metrics=[\"mean_squared_error\",\"mean_absolute_error\"])\n",
    "\n",
    "#optimizer = keras.optimizers.RMSprop(0.001)\n",
    "# optimizer = keras.optimizers.Adam()\n",
    "# model.compile(loss='mean_squared_error',\n",
    "#                 optimizer=optimizer,\n",
    "#                 metrics=['mean_absolute_error','mean_squared_error'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs\\\\20191015_145409'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#callback List를 만들기 위한 선언 및 변수 설정\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "log_folder = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "\n",
    "\n",
    "log_dirs = os.path.join(\"logs\",log_folder)\n",
    "log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_list = [\n",
    "    TensorBoard(log_dir = log_dirs),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10), \n",
    "    ModelCheckpoint(filepath=\"./model_r_weights.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True)   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 14:54:12.763252 15840 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1344209.2500 - mean_squared_error: 1344209.2500 - mean_absolute_error: 1016.7117\n",
      "Epoch 00001: val_loss improved from inf to 1948912.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 3ms/sample - loss: 1926240.8971 - mean_squared_error: 1926241.0000 - mean_absolute_error: 1107.7406 - val_loss: 1948912.8750 - val_mean_squared_error: 1948912.8750 - val_mean_absolute_error: 1160.8413\n",
      "Epoch 2/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2377378.5000 - mean_squared_error: 2377378.5000 - mean_absolute_error: 1222.1818\n",
      "Epoch 00002: val_loss improved from 1948912.87500 to 1948850.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 447us/sample - loss: 1926172.6176 - mean_squared_error: 1926172.6250 - mean_absolute_error: 1107.6956 - val_loss: 1948850.2500 - val_mean_squared_error: 1948850.2500 - val_mean_absolute_error: 1160.8046\n",
      "Epoch 3/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2210274.5000 - mean_squared_error: 2210274.5000 - mean_absolute_error: 1203.6178\n",
      "Epoch 00003: val_loss improved from 1948850.25000 to 1948791.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1926105.0735 - mean_squared_error: 1926105.0000 - mean_absolute_error: 1107.6512 - val_loss: 1948791.5000 - val_mean_squared_error: 1948791.5000 - val_mean_absolute_error: 1160.7695\n",
      "Epoch 4/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2053037.5000 - mean_squared_error: 2053037.5000 - mean_absolute_error: 1127.4868\n",
      "Epoch 00004: val_loss improved from 1948791.50000 to 1948735.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1926043.0221 - mean_squared_error: 1926043.0000 - mean_absolute_error: 1107.6110 - val_loss: 1948735.3750 - val_mean_squared_error: 1948735.3750 - val_mean_absolute_error: 1160.7365\n",
      "Epoch 5/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2337138.5000 - mean_squared_error: 2337138.5000 - mean_absolute_error: 1262.3022\n",
      "Epoch 00005: val_loss improved from 1948735.37500 to 1948677.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1925978.9191 - mean_squared_error: 1925979.0000 - mean_absolute_error: 1107.5693 - val_loss: 1948677.3750 - val_mean_squared_error: 1948677.3750 - val_mean_absolute_error: 1160.7025\n",
      "Epoch 6/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2141946.5000 - mean_squared_error: 2141946.5000 - mean_absolute_error: 1166.6819\n",
      "Epoch 00006: val_loss improved from 1948677.37500 to 1948618.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1925914.6471 - mean_squared_error: 1925914.6250 - mean_absolute_error: 1107.5283 - val_loss: 1948618.5000 - val_mean_squared_error: 1948618.5000 - val_mean_absolute_error: 1160.6678\n",
      "Epoch 7/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1519827.7500 - mean_squared_error: 1519827.7500 - mean_absolute_error: 968.0527\n",
      "Epoch 00007: val_loss improved from 1948618.50000 to 1948560.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1925850.8529 - mean_squared_error: 1925851.0000 - mean_absolute_error: 1107.4872 - val_loss: 1948560.5000 - val_mean_squared_error: 1948560.5000 - val_mean_absolute_error: 1160.6338\n",
      "Epoch 8/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1999728.3750 - mean_squared_error: 1999728.3750 - mean_absolute_error: 1164.4468\n",
      "Epoch 00008: val_loss improved from 1948560.50000 to 1948503.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1925786.8309 - mean_squared_error: 1925786.8750 - mean_absolute_error: 1107.4442 - val_loss: 1948503.7500 - val_mean_squared_error: 1948503.7500 - val_mean_absolute_error: 1160.6002\n",
      "Epoch 9/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2214137.0000 - mean_squared_error: 2214137.0000 - mean_absolute_error: 1087.7352\n",
      "Epoch 00009: val_loss improved from 1948503.75000 to 1948447.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1925720.8971 - mean_squared_error: 1925721.0000 - mean_absolute_error: 1107.4042 - val_loss: 1948447.3750 - val_mean_squared_error: 1948447.3750 - val_mean_absolute_error: 1160.5670\n",
      "Epoch 10/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1400729.0000 - mean_squared_error: 1400729.0000 - mean_absolute_error: 1029.0516\n",
      "Epoch 00010: val_loss improved from 1948447.37500 to 1948374.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1925659.3401 - mean_squared_error: 1925659.2500 - mean_absolute_error: 1107.3622 - val_loss: 1948374.5000 - val_mean_squared_error: 1948374.5000 - val_mean_absolute_error: 1160.5284\n",
      "Epoch 11/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2179613.0000 - mean_squared_error: 2179613.0000 - mean_absolute_error: 1160.5546\n",
      "Epoch 00011: val_loss improved from 1948374.50000 to 1948263.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1925576.2353 - mean_squared_error: 1925576.2500 - mean_absolute_error: 1107.3157 - val_loss: 1948263.7500 - val_mean_squared_error: 1948263.7500 - val_mean_absolute_error: 1160.4768\n",
      "Epoch 12/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1874822.0000 - mean_squared_error: 1874822.0000 - mean_absolute_error: 1103.1829\n",
      "Epoch 00012: val_loss improved from 1948263.75000 to 1948142.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1925474.1176 - mean_squared_error: 1925474.1250 - mean_absolute_error: 1107.2622 - val_loss: 1948142.5000 - val_mean_squared_error: 1948142.5000 - val_mean_absolute_error: 1160.4209\n",
      "Epoch 13/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1508178.2500 - mean_squared_error: 1508178.2500 - mean_absolute_error: 1011.3918\n",
      "Epoch 00013: val_loss improved from 1948142.50000 to 1948015.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1925365.1765 - mean_squared_error: 1925365.1250 - mean_absolute_error: 1107.2057 - val_loss: 1948015.1250 - val_mean_squared_error: 1948015.1250 - val_mean_absolute_error: 1160.3628\n",
      "Epoch 14/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1386507.7500 - mean_squared_error: 1386507.7500 - mean_absolute_error: 922.1344\n",
      "Epoch 00014: val_loss improved from 1948015.12500 to 1947888.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1925254.0882 - mean_squared_error: 1925254.1250 - mean_absolute_error: 1107.1484 - val_loss: 1947888.2500 - val_mean_squared_error: 1947888.2500 - val_mean_absolute_error: 1160.3041\n",
      "Epoch 15/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1972338.8750 - mean_squared_error: 1972338.8750 - mean_absolute_error: 1166.9622\n",
      "Epoch 00015: val_loss improved from 1947888.25000 to 1947758.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1925148.2868 - mean_squared_error: 1925148.2500 - mean_absolute_error: 1107.0894 - val_loss: 1947758.8750 - val_mean_squared_error: 1947758.8750 - val_mean_absolute_error: 1160.2441\n",
      "Epoch 16/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1719062.1250 - mean_squared_error: 1719062.1250 - mean_absolute_error: 1039.8574\n",
      "Epoch 00016: val_loss improved from 1947758.87500 to 1947628.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1925023.9118 - mean_squared_error: 1925023.8750 - mean_absolute_error: 1107.0288 - val_loss: 1947628.2500 - val_mean_squared_error: 1947628.2500 - val_mean_absolute_error: 1160.1833\n",
      "Epoch 17/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 2083196.3750 - mean_squared_error: 2083196.3750 - mean_absolute_error: 1224.0861\n",
      "Epoch 00017: val_loss improved from 1947628.25000 to 1947492.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1924901.0221 - mean_squared_error: 1924901.0000 - mean_absolute_error: 1106.9646 - val_loss: 1947492.0000 - val_mean_squared_error: 1947492.0000 - val_mean_absolute_error: 1160.1201\n",
      "Epoch 18/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2156258.0000 - mean_squared_error: 2156258.0000 - mean_absolute_error: 1193.5908\n",
      "Epoch 00018: val_loss improved from 1947492.00000 to 1947356.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1924768.6397 - mean_squared_error: 1924768.6250 - mean_absolute_error: 1106.8989 - val_loss: 1947356.5000 - val_mean_squared_error: 1947356.5000 - val_mean_absolute_error: 1160.0568\n",
      "Epoch 19/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1675479.0000 - mean_squared_error: 1675479.0000 - mean_absolute_error: 1015.9258\n",
      "Epoch 00019: val_loss improved from 1947356.50000 to 1947219.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1924634.5000 - mean_squared_error: 1924634.5000 - mean_absolute_error: 1106.8331 - val_loss: 1947219.7500 - val_mean_squared_error: 1947219.7500 - val_mean_absolute_error: 1159.9928\n",
      "Epoch 20/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2098243.5000 - mean_squared_error: 2098243.5000 - mean_absolute_error: 1136.0022\n",
      "Epoch 00020: val_loss improved from 1947219.75000 to 1947078.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1924502.0882 - mean_squared_error: 1924502.1250 - mean_absolute_error: 1106.7659 - val_loss: 1947078.6250 - val_mean_squared_error: 1947078.6250 - val_mean_absolute_error: 1159.9271\n",
      "Epoch 21/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1704272.0000 - mean_squared_error: 1704272.0000 - mean_absolute_error: 1057.5760\n",
      "Epoch 00021: val_loss improved from 1947078.62500 to 1946932.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1924361.7132 - mean_squared_error: 1924361.7500 - mean_absolute_error: 1106.6962 - val_loss: 1946932.2500 - val_mean_squared_error: 1946932.2500 - val_mean_absolute_error: 1159.8584\n",
      "Epoch 22/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1677030.1250 - mean_squared_error: 1677030.1250 - mean_absolute_error: 1018.6343\n",
      "Epoch 00022: val_loss improved from 1946932.25000 to 1946782.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1924217.9182 - mean_squared_error: 1924217.8750 - mean_absolute_error: 1106.6233 - val_loss: 1946782.5000 - val_mean_squared_error: 1946782.5000 - val_mean_absolute_error: 1159.7883\n",
      "Epoch 23/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2237237.5000 - mean_squared_error: 2237237.5000 - mean_absolute_error: 1193.4268\n",
      "Epoch 00023: val_loss improved from 1946782.50000 to 1946632.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1924075.2169 - mean_squared_error: 1924075.1250 - mean_absolute_error: 1106.5497 - val_loss: 1946632.6250 - val_mean_squared_error: 1946632.6250 - val_mean_absolute_error: 1159.7180\n",
      "Epoch 24/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1447252.6250 - mean_squared_error: 1447252.6250 - mean_absolute_error: 966.6373\n",
      "Epoch 00024: val_loss improved from 1946632.62500 to 1946478.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1923924.9118 - mean_squared_error: 1923924.8750 - mean_absolute_error: 1106.4771 - val_loss: 1946478.5000 - val_mean_squared_error: 1946478.5000 - val_mean_absolute_error: 1159.6456\n",
      "Epoch 25/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1641610.5000 - mean_squared_error: 1641610.5000 - mean_absolute_error: 995.6433\n",
      "Epoch 00025: val_loss improved from 1946478.50000 to 1946315.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1923774.8824 - mean_squared_error: 1923774.8750 - mean_absolute_error: 1106.4008 - val_loss: 1946315.1250 - val_mean_squared_error: 1946315.1250 - val_mean_absolute_error: 1159.5697\n",
      "Epoch 26/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1961060.3750 - mean_squared_error: 1961060.3750 - mean_absolute_error: 1081.7473\n",
      "Epoch 00026: val_loss improved from 1946315.12500 to 1946145.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1923616.9412 - mean_squared_error: 1923617.0000 - mean_absolute_error: 1106.3201 - val_loss: 1946145.5000 - val_mean_squared_error: 1946145.5000 - val_mean_absolute_error: 1159.4907\n",
      "Epoch 27/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2402788.5000 - mean_squared_error: 2402788.5000 - mean_absolute_error: 1235.0723\n",
      "Epoch 00027: val_loss improved from 1946145.50000 to 1945969.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1923454.0882 - mean_squared_error: 1923454.1250 - mean_absolute_error: 1106.2377 - val_loss: 1945969.7500 - val_mean_squared_error: 1945969.7500 - val_mean_absolute_error: 1159.4095\n",
      "Epoch 28/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2355641.0000 - mean_squared_error: 2355641.0000 - mean_absolute_error: 1235.1079\n",
      "Epoch 00028: val_loss improved from 1945969.75000 to 1945786.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1923286.0000 - mean_squared_error: 1923286.0000 - mean_absolute_error: 1106.1527 - val_loss: 1945786.0000 - val_mean_squared_error: 1945786.0000 - val_mean_absolute_error: 1159.3243\n",
      "Epoch 29/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2096283.3750 - mean_squared_error: 2096283.3750 - mean_absolute_error: 1154.2802\n",
      "Epoch 00029: val_loss improved from 1945786.00000 to 1945597.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1923107.3493 - mean_squared_error: 1923107.3750 - mean_absolute_error: 1106.0637 - val_loss: 1945597.7500 - val_mean_squared_error: 1945597.7500 - val_mean_absolute_error: 1159.2369\n",
      "Epoch 30/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2784648.0000 - mean_squared_error: 2784648.0000 - mean_absolute_error: 1288.2947\n",
      "Epoch 00030: val_loss improved from 1945597.75000 to 1945408.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1922928.3952 - mean_squared_error: 1922928.5000 - mean_absolute_error: 1105.9722 - val_loss: 1945408.0000 - val_mean_squared_error: 1945408.0000 - val_mean_absolute_error: 1159.1489\n",
      "Epoch 31/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1666041.1250 - mean_squared_error: 1666041.1250 - mean_absolute_error: 1036.5817\n",
      "Epoch 00031: val_loss improved from 1945408.00000 to 1945218.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1922740.8529 - mean_squared_error: 1922740.8750 - mean_absolute_error: 1105.8807 - val_loss: 1945218.2500 - val_mean_squared_error: 1945218.2500 - val_mean_absolute_error: 1159.0602\n",
      "Epoch 32/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1495945.0000 - mean_squared_error: 1495945.0000 - mean_absolute_error: 984.1506\n",
      "Epoch 00032: val_loss improved from 1945218.25000 to 1945023.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1922557.8971 - mean_squared_error: 1922557.8750 - mean_absolute_error: 1105.7889 - val_loss: 1945023.5000 - val_mean_squared_error: 1945023.5000 - val_mean_absolute_error: 1158.9692\n",
      "Epoch 33/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1852680.5000 - mean_squared_error: 1852680.5000 - mean_absolute_error: 1142.2401\n",
      "Epoch 00033: val_loss improved from 1945023.50000 to 1944821.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1922373.2647 - mean_squared_error: 1922373.2500 - mean_absolute_error: 1105.6935 - val_loss: 1944821.1250 - val_mean_squared_error: 1944821.1250 - val_mean_absolute_error: 1158.8749\n",
      "Epoch 34/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1218450.1250 - mean_squared_error: 1218450.1250 - mean_absolute_error: 969.2602\n",
      "Epoch 00034: val_loss improved from 1944821.12500 to 1944612.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1922172.2941 - mean_squared_error: 1922172.3750 - mean_absolute_error: 1105.5951 - val_loss: 1944612.2500 - val_mean_squared_error: 1944612.2500 - val_mean_absolute_error: 1158.7778\n",
      "Epoch 35/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2689358.2500 - mean_squared_error: 2689358.2500 - mean_absolute_error: 1294.5011\n",
      "Epoch 00035: val_loss improved from 1944612.25000 to 1944392.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1921977.4118 - mean_squared_error: 1921977.3750 - mean_absolute_error: 1105.4924 - val_loss: 1944392.0000 - val_mean_squared_error: 1944392.0000 - val_mean_absolute_error: 1158.6759\n",
      "Epoch 36/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1645886.0000 - mean_squared_error: 1645886.0000 - mean_absolute_error: 995.3372\n",
      "Epoch 00036: val_loss improved from 1944392.00000 to 1944170.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1921760.1250 - mean_squared_error: 1921760.1250 - mean_absolute_error: 1105.3857 - val_loss: 1944170.0000 - val_mean_squared_error: 1944170.0000 - val_mean_absolute_error: 1158.5729\n",
      "Epoch 37/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1954459.7500 - mean_squared_error: 1954459.7500 - mean_absolute_error: 1123.3557\n",
      "Epoch 00037: val_loss improved from 1944170.00000 to 1943941.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1921550.7647 - mean_squared_error: 1921550.8750 - mean_absolute_error: 1105.2803 - val_loss: 1943941.7500 - val_mean_squared_error: 1943941.7500 - val_mean_absolute_error: 1158.4673\n",
      "Epoch 38/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1444774.2500 - mean_squared_error: 1444774.2500 - mean_absolute_error: 1005.5332\n",
      "Epoch 00038: val_loss improved from 1943941.75000 to 1943701.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1921327.4485 - mean_squared_error: 1921327.3750 - mean_absolute_error: 1105.1697 - val_loss: 1943701.7500 - val_mean_squared_error: 1943701.7500 - val_mean_absolute_error: 1158.3568\n",
      "Epoch 39/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2351918.7500 - mean_squared_error: 2351918.7500 - mean_absolute_error: 1254.5455\n",
      "Epoch 00039: val_loss improved from 1943701.75000 to 1943457.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1921105.9926 - mean_squared_error: 1921105.8750 - mean_absolute_error: 1105.0541 - val_loss: 1943457.3750 - val_mean_squared_error: 1943457.3750 - val_mean_absolute_error: 1158.2440\n",
      "Epoch 40/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2350664.5000 - mean_squared_error: 2350664.5000 - mean_absolute_error: 1225.3430\n",
      "Epoch 00040: val_loss improved from 1943457.37500 to 1943212.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1920867.8713 - mean_squared_error: 1920867.8750 - mean_absolute_error: 1104.9369 - val_loss: 1943212.2500 - val_mean_squared_error: 1943212.2500 - val_mean_absolute_error: 1158.1311\n",
      "Epoch 41/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2025740.7500 - mean_squared_error: 2025740.7500 - mean_absolute_error: 1119.3284\n",
      "Epoch 00041: val_loss improved from 1943212.25000 to 1942957.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1920629.4706 - mean_squared_error: 1920629.3750 - mean_absolute_error: 1104.8204 - val_loss: 1942957.7500 - val_mean_squared_error: 1942957.7500 - val_mean_absolute_error: 1158.0134\n",
      "Epoch 42/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1993874.7500 - mean_squared_error: 1993874.7500 - mean_absolute_error: 1056.8409\n",
      "Epoch 00042: val_loss improved from 1942957.75000 to 1942692.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1920380.7426 - mean_squared_error: 1920380.7500 - mean_absolute_error: 1104.6978 - val_loss: 1942692.5000 - val_mean_squared_error: 1942692.5000 - val_mean_absolute_error: 1157.8914\n",
      "Epoch 43/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2036471.7500 - mean_squared_error: 2036471.7500 - mean_absolute_error: 1129.0437\n",
      "Epoch 00043: val_loss improved from 1942692.50000 to 1942414.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1920126.2500 - mean_squared_error: 1920126.2500 - mean_absolute_error: 1104.5690 - val_loss: 1942414.6250 - val_mean_squared_error: 1942414.6250 - val_mean_absolute_error: 1157.7637\n",
      "Epoch 44/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1789305.5000 - mean_squared_error: 1789305.5000 - mean_absolute_error: 1114.5115\n",
      "Epoch 00044: val_loss improved from 1942414.62500 to 1942130.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1919864.0074 - mean_squared_error: 1919864.0000 - mean_absolute_error: 1104.4370 - val_loss: 1942130.2500 - val_mean_squared_error: 1942130.2500 - val_mean_absolute_error: 1157.6331\n",
      "Epoch 45/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1422548.5000 - mean_squared_error: 1422548.5000 - mean_absolute_error: 931.6251\n",
      "Epoch 00045: val_loss improved from 1942130.25000 to 1941841.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1919579.6471 - mean_squared_error: 1919579.6250 - mean_absolute_error: 1104.3019 - val_loss: 1941841.3750 - val_mean_squared_error: 1941841.3750 - val_mean_absolute_error: 1157.5010\n",
      "Epoch 46/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2049386.5000 - mean_squared_error: 2049386.5000 - mean_absolute_error: 1059.3765\n",
      "Epoch 00046: val_loss improved from 1941841.37500 to 1941537.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1919308.3382 - mean_squared_error: 1919308.3750 - mean_absolute_error: 1104.1644 - val_loss: 1941537.3750 - val_mean_squared_error: 1941537.3750 - val_mean_absolute_error: 1157.3623\n",
      "Epoch 47/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1801871.0000 - mean_squared_error: 1801871.0000 - mean_absolute_error: 1151.8021\n",
      "Epoch 00047: val_loss improved from 1941537.37500 to 1941230.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1919027.2445 - mean_squared_error: 1919027.2500 - mean_absolute_error: 1104.0210 - val_loss: 1941230.6250 - val_mean_squared_error: 1941230.6250 - val_mean_absolute_error: 1157.2223\n",
      "Epoch 48/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1535800.5000 - mean_squared_error: 1535800.5000 - mean_absolute_error: 1063.0250\n",
      "Epoch 00048: val_loss improved from 1941230.62500 to 1940922.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1918728.0882 - mean_squared_error: 1918728.1250 - mean_absolute_error: 1103.8772 - val_loss: 1940922.6250 - val_mean_squared_error: 1940922.6250 - val_mean_absolute_error: 1157.0819\n",
      "Epoch 49/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1902288.1250 - mean_squared_error: 1902288.1250 - mean_absolute_error: 1094.3220\n",
      "Epoch 00049: val_loss improved from 1940922.62500 to 1940598.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1918430.4706 - mean_squared_error: 1918430.5000 - mean_absolute_error: 1103.7322 - val_loss: 1940598.8750 - val_mean_squared_error: 1940598.8750 - val_mean_absolute_error: 1156.9346\n",
      "Epoch 50/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1719777.7500 - mean_squared_error: 1719777.7500 - mean_absolute_error: 987.9124\n",
      "Epoch 00050: val_loss improved from 1940598.87500 to 1940260.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1918116.0515 - mean_squared_error: 1918116.0000 - mean_absolute_error: 1103.5781 - val_loss: 1940260.5000 - val_mean_squared_error: 1940260.5000 - val_mean_absolute_error: 1156.7808\n",
      "Epoch 51/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2222965.7500 - mean_squared_error: 2222965.7500 - mean_absolute_error: 1274.7747\n",
      "Epoch 00051: val_loss improved from 1940260.50000 to 1939914.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1917805.7647 - mean_squared_error: 1917805.6250 - mean_absolute_error: 1103.4192 - val_loss: 1939914.0000 - val_mean_squared_error: 1939914.0000 - val_mean_absolute_error: 1156.6234\n",
      "Epoch 52/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1890771.0000 - mean_squared_error: 1890771.0000 - mean_absolute_error: 1103.5659\n",
      "Epoch 00052: val_loss improved from 1939914.00000 to 1939562.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1917467.5441 - mean_squared_error: 1917467.5000 - mean_absolute_error: 1103.2572 - val_loss: 1939562.0000 - val_mean_squared_error: 1939562.0000 - val_mean_absolute_error: 1156.4641\n",
      "Epoch 53/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2504706.0000 - mean_squared_error: 2504706.0000 - mean_absolute_error: 1210.9888\n",
      "Epoch 00053: val_loss improved from 1939562.00000 to 1939191.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 499us/sample - loss: 1917131.5000 - mean_squared_error: 1917131.5000 - mean_absolute_error: 1103.0927 - val_loss: 1939191.5000 - val_mean_squared_error: 1939191.5000 - val_mean_absolute_error: 1156.2969\n",
      "Epoch 54/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1378498.5000 - mean_squared_error: 1378498.5000 - mean_absolute_error: 980.6085\n",
      "Epoch 00054: val_loss improved from 1939191.50000 to 1938802.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1916771.5882 - mean_squared_error: 1916771.5000 - mean_absolute_error: 1102.9220 - val_loss: 1938802.8750 - val_mean_squared_error: 1938802.8750 - val_mean_absolute_error: 1156.1221\n",
      "Epoch 55/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1669569.5000 - mean_squared_error: 1669569.5000 - mean_absolute_error: 1123.5498\n",
      "Epoch 00055: val_loss improved from 1938802.87500 to 1938396.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1916408.9559 - mean_squared_error: 1916409.0000 - mean_absolute_error: 1102.7427 - val_loss: 1938396.0000 - val_mean_squared_error: 1938396.0000 - val_mean_absolute_error: 1155.9395\n",
      "Epoch 56/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2393983.0000 - mean_squared_error: 2393983.0000 - mean_absolute_error: 1245.0081\n",
      "Epoch 00056: val_loss improved from 1938396.00000 to 1937979.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1916032.4301 - mean_squared_error: 1916032.5000 - mean_absolute_error: 1102.5549 - val_loss: 1937979.5000 - val_mean_squared_error: 1937979.5000 - val_mean_absolute_error: 1155.7526\n",
      "Epoch 57/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1713770.1250 - mean_squared_error: 1713770.1250 - mean_absolute_error: 1045.2946\n",
      "Epoch 00057: val_loss improved from 1937979.50000 to 1937572.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1915634.9449 - mean_squared_error: 1915635.0000 - mean_absolute_error: 1102.3687 - val_loss: 1937572.0000 - val_mean_squared_error: 1937572.0000 - val_mean_absolute_error: 1155.5698\n",
      "Epoch 58/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1980085.0000 - mean_squared_error: 1980085.0000 - mean_absolute_error: 1109.1805\n",
      "Epoch 00058: val_loss improved from 1937572.00000 to 1937159.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1915252.2941 - mean_squared_error: 1915252.2500 - mean_absolute_error: 1102.1835 - val_loss: 1937159.3750 - val_mean_squared_error: 1937159.3750 - val_mean_absolute_error: 1155.3859\n",
      "Epoch 59/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1702706.0000 - mean_squared_error: 1702706.0000 - mean_absolute_error: 1049.3461\n",
      "Epoch 00059: val_loss improved from 1937159.37500 to 1936732.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1914858.2941 - mean_squared_error: 1914858.3750 - mean_absolute_error: 1101.9954 - val_loss: 1936732.8750 - val_mean_squared_error: 1936732.8750 - val_mean_absolute_error: 1155.1963\n",
      "Epoch 60/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2052356.5000 - mean_squared_error: 2052356.5000 - mean_absolute_error: 1198.5712\n",
      "Epoch 00060: val_loss improved from 1936732.87500 to 1936292.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1914462.7647 - mean_squared_error: 1914462.8750 - mean_absolute_error: 1101.8031 - val_loss: 1936292.0000 - val_mean_squared_error: 1936292.0000 - val_mean_absolute_error: 1155.0002\n",
      "Epoch 61/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1876574.2500 - mean_squared_error: 1876574.2500 - mean_absolute_error: 1128.6074\n",
      "Epoch 00061: val_loss improved from 1936292.00000 to 1935841.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 1914043.1801 - mean_squared_error: 1914043.2500 - mean_absolute_error: 1101.6031 - val_loss: 1935841.7500 - val_mean_squared_error: 1935841.7500 - val_mean_absolute_error: 1154.8007\n",
      "Epoch 62/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1931958.8750 - mean_squared_error: 1931958.8750 - mean_absolute_error: 1159.9849\n",
      "Epoch 00062: val_loss improved from 1935841.75000 to 1935388.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1913623.8456 - mean_squared_error: 1913623.8750 - mean_absolute_error: 1101.4016 - val_loss: 1935388.5000 - val_mean_squared_error: 1935388.5000 - val_mean_absolute_error: 1154.5990\n",
      "Epoch 63/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1884162.0000 - mean_squared_error: 1884162.0000 - mean_absolute_error: 1150.8011\n",
      "Epoch 00063: val_loss improved from 1935388.50000 to 1934928.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1913197.4706 - mean_squared_error: 1913197.3750 - mean_absolute_error: 1101.1985 - val_loss: 1934928.5000 - val_mean_squared_error: 1934928.5000 - val_mean_absolute_error: 1154.3937\n",
      "Epoch 64/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1300903.0000 - mean_squared_error: 1300903.0000 - mean_absolute_error: 857.0046\n",
      "Epoch 00064: val_loss improved from 1934928.50000 to 1934452.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1912743.8529 - mean_squared_error: 1912743.8750 - mean_absolute_error: 1100.9897 - val_loss: 1934452.8750 - val_mean_squared_error: 1934452.8750 - val_mean_absolute_error: 1154.1814\n",
      "Epoch 65/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 2367081.0000 - mean_squared_error: 2367081.0000 - mean_absolute_error: 1217.1566\n",
      "Epoch 00065: val_loss improved from 1934452.87500 to 1933967.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1912319.5423 - mean_squared_error: 1912319.6250 - mean_absolute_error: 1100.7726 - val_loss: 1933967.3750 - val_mean_squared_error: 1933967.3750 - val_mean_absolute_error: 1153.9641\n",
      "Epoch 66/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2160925.5000 - mean_squared_error: 2160925.5000 - mean_absolute_error: 1154.5330\n",
      "Epoch 00066: val_loss improved from 1933967.37500 to 1933486.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1911855.8346 - mean_squared_error: 1911855.8750 - mean_absolute_error: 1100.5531 - val_loss: 1933486.5000 - val_mean_squared_error: 1933486.5000 - val_mean_absolute_error: 1153.7487\n",
      "Epoch 67/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1145003.2500 - mean_squared_error: 1145003.2500 - mean_absolute_error: 945.3398\n",
      "Epoch 00067: val_loss improved from 1933486.50000 to 1932995.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1911396.8750 - mean_squared_error: 1911396.8750 - mean_absolute_error: 1100.3365 - val_loss: 1932995.3750 - val_mean_squared_error: 1932995.3750 - val_mean_absolute_error: 1153.5284\n",
      "Epoch 68/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2172411.0000 - mean_squared_error: 2172411.0000 - mean_absolute_error: 1130.4785\n",
      "Epoch 00068: val_loss improved from 1932995.37500 to 1932494.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1910940.2243 - mean_squared_error: 1910940.2500 - mean_absolute_error: 1100.1111 - val_loss: 1932494.6250 - val_mean_squared_error: 1932494.6250 - val_mean_absolute_error: 1153.3048\n",
      "Epoch 69/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2040430.8750 - mean_squared_error: 2040430.8750 - mean_absolute_error: 1202.0593\n",
      "Epoch 00069: val_loss improved from 1932494.62500 to 1931975.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1910466.3235 - mean_squared_error: 1910466.3750 - mean_absolute_error: 1099.8861 - val_loss: 1931975.7500 - val_mean_squared_error: 1931975.7500 - val_mean_absolute_error: 1153.0740\n",
      "Epoch 70/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2628079.0000 - mean_squared_error: 2628079.0000 - mean_absolute_error: 1315.2327\n",
      "Epoch 00070: val_loss improved from 1931975.75000 to 1931414.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 499us/sample - loss: 1909985.7059 - mean_squared_error: 1909985.7500 - mean_absolute_error: 1099.6493 - val_loss: 1931414.6250 - val_mean_squared_error: 1931414.6250 - val_mean_absolute_error: 1152.8264\n",
      "Epoch 71/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2151654.5000 - mean_squared_error: 2151654.5000 - mean_absolute_error: 1171.4413\n",
      "Epoch 00071: val_loss improved from 1931414.62500 to 1930846.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1909457.2096 - mean_squared_error: 1909457.1250 - mean_absolute_error: 1099.4000 - val_loss: 1930846.0000 - val_mean_squared_error: 1930846.0000 - val_mean_absolute_error: 1152.5750\n",
      "Epoch 72/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2187937.0000 - mean_squared_error: 2187937.0000 - mean_absolute_error: 1197.7318\n",
      "Epoch 00072: val_loss improved from 1930846.00000 to 1930272.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1908918.6471 - mean_squared_error: 1908918.6250 - mean_absolute_error: 1099.1475 - val_loss: 1930272.5000 - val_mean_squared_error: 1930272.5000 - val_mean_absolute_error: 1152.3209\n",
      "Epoch 73/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1662278.5000 - mean_squared_error: 1662278.5000 - mean_absolute_error: 1005.4277\n",
      "Epoch 00073: val_loss improved from 1930272.50000 to 1929677.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1908372.8750 - mean_squared_error: 1908372.8750 - mean_absolute_error: 1098.8912 - val_loss: 1929677.3750 - val_mean_squared_error: 1929677.3750 - val_mean_absolute_error: 1152.0583\n",
      "Epoch 74/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2436041.7500 - mean_squared_error: 2436041.7500 - mean_absolute_error: 1162.2222\n",
      "Epoch 00074: val_loss improved from 1929677.37500 to 1929071.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1907821.3603 - mean_squared_error: 1907821.3750 - mean_absolute_error: 1098.6266 - val_loss: 1929071.7500 - val_mean_squared_error: 1929071.7500 - val_mean_absolute_error: 1151.7920\n",
      "Epoch 75/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1811516.7500 - mean_squared_error: 1811516.7500 - mean_absolute_error: 1085.9580\n",
      "Epoch 00075: val_loss improved from 1929071.75000 to 1928457.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1907258.9301 - mean_squared_error: 1907259.0000 - mean_absolute_error: 1098.3591 - val_loss: 1928457.1250 - val_mean_squared_error: 1928457.1250 - val_mean_absolute_error: 1151.5225\n",
      "Epoch 76/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1562131.0000 - mean_squared_error: 1562131.0000 - mean_absolute_error: 984.0637\n",
      "Epoch 00076: val_loss improved from 1928457.12500 to 1927840.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1906668.2353 - mean_squared_error: 1906668.2500 - mean_absolute_error: 1098.0886 - val_loss: 1927840.8750 - val_mean_squared_error: 1927840.8750 - val_mean_absolute_error: 1151.2518\n",
      "Epoch 77/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1487411.0000 - mean_squared_error: 1487411.0000 - mean_absolute_error: 968.9401\n",
      "Epoch 00077: val_loss improved from 1927840.87500 to 1927202.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1906093.1029 - mean_squared_error: 1906093.0000 - mean_absolute_error: 1097.8159 - val_loss: 1927202.8750 - val_mean_squared_error: 1927202.8750 - val_mean_absolute_error: 1150.9708\n",
      "Epoch 78/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1908813.8750 - mean_squared_error: 1908813.8750 - mean_absolute_error: 1077.0023\n",
      "Epoch 00078: val_loss improved from 1927202.87500 to 1926554.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1905508.2868 - mean_squared_error: 1905508.2500 - mean_absolute_error: 1097.5327 - val_loss: 1926554.2500 - val_mean_squared_error: 1926554.2500 - val_mean_absolute_error: 1150.6854\n",
      "Epoch 79/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1398719.3750 - mean_squared_error: 1398719.3750 - mean_absolute_error: 939.9811\n",
      "Epoch 00079: val_loss improved from 1926554.25000 to 1925911.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1904892.3805 - mean_squared_error: 1904892.3750 - mean_absolute_error: 1097.2461 - val_loss: 1925911.1250 - val_mean_squared_error: 1925911.1250 - val_mean_absolute_error: 1150.4020\n",
      "Epoch 80/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1237844.5000 - mean_squared_error: 1237844.5000 - mean_absolute_error: 949.3441\n",
      "Epoch 00080: val_loss improved from 1925911.12500 to 1925265.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1904287.5588 - mean_squared_error: 1904287.5000 - mean_absolute_error: 1096.9626 - val_loss: 1925265.1250 - val_mean_squared_error: 1925265.1250 - val_mean_absolute_error: 1150.1178\n",
      "Epoch 81/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 2091521.7500 - mean_squared_error: 2091521.7500 - mean_absolute_error: 1174.9421\n",
      "Epoch 00081: val_loss improved from 1925265.12500 to 1924605.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1903703.2261 - mean_squared_error: 1903703.1250 - mean_absolute_error: 1096.6740 - val_loss: 1924605.1250 - val_mean_squared_error: 1924605.1250 - val_mean_absolute_error: 1149.8295\n",
      "Epoch 82/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1340449.0000 - mean_squared_error: 1340449.0000 - mean_absolute_error: 937.5583\n",
      "Epoch 00082: val_loss improved from 1924605.12500 to 1923954.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1903061.8272 - mean_squared_error: 1903061.8750 - mean_absolute_error: 1096.3868 - val_loss: 1923954.2500 - val_mean_squared_error: 1923954.2500 - val_mean_absolute_error: 1149.5458\n",
      "Epoch 83/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1934949.2500 - mean_squared_error: 1934949.2500 - mean_absolute_error: 1156.7349\n",
      "Epoch 00083: val_loss improved from 1923954.25000 to 1923279.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1902464.8235 - mean_squared_error: 1902464.8750 - mean_absolute_error: 1096.1006 - val_loss: 1923279.1250 - val_mean_squared_error: 1923279.1250 - val_mean_absolute_error: 1149.2522\n",
      "Epoch 84/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1267230.0000 - mean_squared_error: 1267230.0000 - mean_absolute_error: 960.6901\n",
      "Epoch 00084: val_loss improved from 1923279.12500 to 1922586.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1901810.4485 - mean_squared_error: 1901810.5000 - mean_absolute_error: 1095.8054 - val_loss: 1922586.2500 - val_mean_squared_error: 1922586.2500 - val_mean_absolute_error: 1148.9504\n",
      "Epoch 85/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2786157.5000 - mean_squared_error: 2786157.5000 - mean_absolute_error: 1390.7192\n",
      "Epoch 00085: val_loss improved from 1922586.25000 to 1921862.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1901195.6728 - mean_squared_error: 1901195.6250 - mean_absolute_error: 1095.4991 - val_loss: 1921862.2500 - val_mean_squared_error: 1921862.2500 - val_mean_absolute_error: 1148.6343\n",
      "Epoch 86/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1219364.6250 - mean_squared_error: 1219364.6250 - mean_absolute_error: 955.1097\n",
      "Epoch 00086: val_loss improved from 1921862.25000 to 1921126.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1900473.1912 - mean_squared_error: 1900473.2500 - mean_absolute_error: 1095.1832 - val_loss: 1921126.6250 - val_mean_squared_error: 1921126.6250 - val_mean_absolute_error: 1148.3134\n",
      "Epoch 87/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1999642.7500 - mean_squared_error: 1999642.7500 - mean_absolute_error: 1081.4478\n",
      "Epoch 00087: val_loss improved from 1921126.62500 to 1920355.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1899785.5956 - mean_squared_error: 1899785.6250 - mean_absolute_error: 1094.8578 - val_loss: 1920355.7500 - val_mean_squared_error: 1920355.7500 - val_mean_absolute_error: 1147.9788\n",
      "Epoch 88/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1573656.7500 - mean_squared_error: 1573656.7500 - mean_absolute_error: 1001.7605\n",
      "Epoch 00088: val_loss improved from 1920355.75000 to 1919540.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1899046.0000 - mean_squared_error: 1899046.0000 - mean_absolute_error: 1094.5211 - val_loss: 1919540.8750 - val_mean_squared_error: 1919540.8750 - val_mean_absolute_error: 1147.6249\n",
      "Epoch 89/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1745357.2500 - mean_squared_error: 1745357.2500 - mean_absolute_error: 1026.7456\n",
      "Epoch 00089: val_loss improved from 1919540.87500 to 1918645.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1898262.5294 - mean_squared_error: 1898262.6250 - mean_absolute_error: 1094.1564 - val_loss: 1918645.1250 - val_mean_squared_error: 1918645.1250 - val_mean_absolute_error: 1147.2418\n",
      "Epoch 90/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2241720.7500 - mean_squared_error: 2241720.7500 - mean_absolute_error: 1184.8923\n",
      "Epoch 00090: val_loss improved from 1918645.12500 to 1917713.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1897441.1471 - mean_squared_error: 1897441.1250 - mean_absolute_error: 1093.7695 - val_loss: 1917713.1250 - val_mean_squared_error: 1917713.1250 - val_mean_absolute_error: 1146.8466\n",
      "Epoch 91/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1169622.7500 - mean_squared_error: 1169622.7500 - mean_absolute_error: 876.5536\n",
      "Epoch 00091: val_loss improved from 1917713.12500 to 1916745.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1896535.0515 - mean_squared_error: 1896535.0000 - mean_absolute_error: 1093.3728 - val_loss: 1916745.3750 - val_mean_squared_error: 1916745.3750 - val_mean_absolute_error: 1146.4397\n",
      "Epoch 92/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2875585.0000 - mean_squared_error: 2875585.0000 - mean_absolute_error: 1365.2814\n",
      "Epoch 00092: val_loss improved from 1916745.37500 to 1915761.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1895700.8162 - mean_squared_error: 1895700.8750 - mean_absolute_error: 1092.9692 - val_loss: 1915761.5000 - val_mean_squared_error: 1915761.5000 - val_mean_absolute_error: 1146.0273\n",
      "Epoch 93/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2300235.5000 - mean_squared_error: 2300235.5000 - mean_absolute_error: 1235.1643\n",
      "Epoch 00093: val_loss improved from 1915761.50000 to 1914764.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1894784.5368 - mean_squared_error: 1894784.6250 - mean_absolute_error: 1092.5681 - val_loss: 1914764.6250 - val_mean_squared_error: 1914764.6250 - val_mean_absolute_error: 1145.6096\n",
      "Epoch 94/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1730322.2500 - mean_squared_error: 1730322.2500 - mean_absolute_error: 1049.1934\n",
      "Epoch 00094: val_loss improved from 1914764.62500 to 1913740.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1893846.5588 - mean_squared_error: 1893846.6250 - mean_absolute_error: 1092.1681 - val_loss: 1913740.0000 - val_mean_squared_error: 1913740.0000 - val_mean_absolute_error: 1145.1804\n",
      "Epoch 95/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1480609.0000 - mean_squared_error: 1480609.0000 - mean_absolute_error: 940.0840\n",
      "Epoch 00095: val_loss improved from 1913740.00000 to 1912683.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1892885.1618 - mean_squared_error: 1892885.1250 - mean_absolute_error: 1091.7472 - val_loss: 1912683.7500 - val_mean_squared_error: 1912683.7500 - val_mean_absolute_error: 1144.7357\n",
      "Epoch 96/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 851473.1875 - mean_squared_error: 851473.1875 - mean_absolute_error: 754.3364\n",
      "Epoch 00096: val_loss improved from 1912683.75000 to 1911575.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1891874.9706 - mean_squared_error: 1891875.0000 - mean_absolute_error: 1091.3250 - val_loss: 1911575.7500 - val_mean_squared_error: 1911575.7500 - val_mean_absolute_error: 1144.2698\n",
      "Epoch 97/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1388315.0000 - mean_squared_error: 1388315.0000 - mean_absolute_error: 968.6724\n",
      "Epoch 00097: val_loss improved from 1911575.75000 to 1910385.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1890879.7059 - mean_squared_error: 1890879.7500 - mean_absolute_error: 1090.8650 - val_loss: 1910385.7500 - val_mean_squared_error: 1910385.7500 - val_mean_absolute_error: 1143.7716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2425707.5000 - mean_squared_error: 2425707.5000 - mean_absolute_error: 1183.3552\n",
      "Epoch 00098: val_loss improved from 1910385.75000 to 1909164.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1889822.9559 - mean_squared_error: 1889823.0000 - mean_absolute_error: 1090.3900 - val_loss: 1909164.8750 - val_mean_squared_error: 1909164.8750 - val_mean_absolute_error: 1143.2620\n",
      "Epoch 99/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2051008.2500 - mean_squared_error: 2051008.2500 - mean_absolute_error: 1120.3511\n",
      "Epoch 00099: val_loss improved from 1909164.87500 to 1907931.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1888701.2721 - mean_squared_error: 1888701.2500 - mean_absolute_error: 1089.9014 - val_loss: 1907931.7500 - val_mean_squared_error: 1907931.7500 - val_mean_absolute_error: 1142.7466\n",
      "Epoch 100/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2299639.5000 - mean_squared_error: 2299639.5000 - mean_absolute_error: 1204.1433\n",
      "Epoch 00100: val_loss improved from 1907931.75000 to 1906688.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1887586.1471 - mean_squared_error: 1887586.1250 - mean_absolute_error: 1089.4146 - val_loss: 1906688.5000 - val_mean_squared_error: 1906688.5000 - val_mean_absolute_error: 1142.2249\n",
      "Epoch 101/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1534632.8750 - mean_squared_error: 1534632.8750 - mean_absolute_error: 961.6434\n",
      "Epoch 00101: val_loss improved from 1906688.50000 to 1905436.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1886411.5754 - mean_squared_error: 1886411.6250 - mean_absolute_error: 1088.9216 - val_loss: 1905436.2500 - val_mean_squared_error: 1905436.2500 - val_mean_absolute_error: 1141.6979\n",
      "Epoch 102/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1449689.0000 - mean_squared_error: 1449689.0000 - mean_absolute_error: 946.7538\n",
      "Epoch 00102: val_loss improved from 1905436.25000 to 1904184.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1885243.3824 - mean_squared_error: 1885243.3750 - mean_absolute_error: 1088.4232 - val_loss: 1904184.5000 - val_mean_squared_error: 1904184.5000 - val_mean_absolute_error: 1141.1732\n",
      "Epoch 103/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1636792.0000 - mean_squared_error: 1636792.0000 - mean_absolute_error: 1021.4341\n",
      "Epoch 00103: val_loss improved from 1904184.50000 to 1902881.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1884100.5000 - mean_squared_error: 1884100.5000 - mean_absolute_error: 1087.9302 - val_loss: 1902881.7500 - val_mean_squared_error: 1902881.7500 - val_mean_absolute_error: 1140.6289\n",
      "Epoch 104/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2261033.7500 - mean_squared_error: 2261033.7500 - mean_absolute_error: 1204.8064\n",
      "Epoch 00104: val_loss improved from 1902881.75000 to 1901511.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1882931.3088 - mean_squared_error: 1882931.2500 - mean_absolute_error: 1087.4117 - val_loss: 1901511.5000 - val_mean_squared_error: 1901511.5000 - val_mean_absolute_error: 1140.0579\n",
      "Epoch 105/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2058247.2500 - mean_squared_error: 2058247.2500 - mean_absolute_error: 1120.6638\n",
      "Epoch 00105: val_loss improved from 1901511.50000 to 1900112.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1881665.6471 - mean_squared_error: 1881665.6250 - mean_absolute_error: 1086.8828 - val_loss: 1900112.2500 - val_mean_squared_error: 1900112.2500 - val_mean_absolute_error: 1139.5093\n",
      "Epoch 106/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1782910.5000 - mean_squared_error: 1782910.5000 - mean_absolute_error: 1022.7379\n",
      "Epoch 00106: val_loss improved from 1900112.25000 to 1898700.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1880369.7500 - mean_squared_error: 1880369.7500 - mean_absolute_error: 1086.3301 - val_loss: 1898700.5000 - val_mean_squared_error: 1898700.5000 - val_mean_absolute_error: 1138.9714\n",
      "Epoch 107/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1539001.8750 - mean_squared_error: 1539001.8750 - mean_absolute_error: 1003.4052\n",
      "Epoch 00107: val_loss improved from 1898700.50000 to 1897267.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1879094.0735 - mean_squared_error: 1879094.0000 - mean_absolute_error: 1085.7739 - val_loss: 1897267.1250 - val_mean_squared_error: 1897267.1250 - val_mean_absolute_error: 1138.4258\n",
      "Epoch 108/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1913535.1250 - mean_squared_error: 1913535.1250 - mean_absolute_error: 1065.4150\n",
      "Epoch 00108: val_loss improved from 1897267.12500 to 1895848.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1877808.3824 - mean_squared_error: 1877808.5000 - mean_absolute_error: 1085.2238 - val_loss: 1895848.0000 - val_mean_squared_error: 1895848.0000 - val_mean_absolute_error: 1137.8838\n",
      "Epoch 109/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2137639.5000 - mean_squared_error: 2137639.5000 - mean_absolute_error: 1137.2554\n",
      "Epoch 00109: val_loss improved from 1895848.00000 to 1894430.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1876521.3897 - mean_squared_error: 1876521.3750 - mean_absolute_error: 1084.6647 - val_loss: 1894430.2500 - val_mean_squared_error: 1894430.2500 - val_mean_absolute_error: 1137.3370\n",
      "Epoch 110/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1638133.0000 - mean_squared_error: 1638133.0000 - mean_absolute_error: 1101.9182\n",
      "Epoch 00110: val_loss improved from 1894430.25000 to 1892987.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1875209.1838 - mean_squared_error: 1875209.1250 - mean_absolute_error: 1084.0967 - val_loss: 1892987.5000 - val_mean_squared_error: 1892987.5000 - val_mean_absolute_error: 1136.7792\n",
      "Epoch 111/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2441133.5000 - mean_squared_error: 2441133.5000 - mean_absolute_error: 1191.3754\n",
      "Epoch 00111: val_loss improved from 1892987.50000 to 1891500.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1873888.2500 - mean_squared_error: 1873888.2500 - mean_absolute_error: 1083.5132 - val_loss: 1891500.5000 - val_mean_squared_error: 1891500.5000 - val_mean_absolute_error: 1136.2036\n",
      "Epoch 112/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1365954.2500 - mean_squared_error: 1365954.2500 - mean_absolute_error: 887.3291\n",
      "Epoch 00112: val_loss improved from 1891500.50000 to 1890000.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1872482.4669 - mean_squared_error: 1872482.5000 - mean_absolute_error: 1082.9089 - val_loss: 1890000.6250 - val_mean_squared_error: 1890000.6250 - val_mean_absolute_error: 1135.6165\n",
      "Epoch 113/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1607078.7500 - mean_squared_error: 1607078.7500 - mean_absolute_error: 922.6068\n",
      "Epoch 00113: val_loss improved from 1890000.62500 to 1888489.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1871090.4706 - mean_squared_error: 1871090.5000 - mean_absolute_error: 1082.2916 - val_loss: 1888489.1250 - val_mean_squared_error: 1888489.1250 - val_mean_absolute_error: 1135.0242\n",
      "Epoch 114/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 2442511.7500 - mean_squared_error: 2442511.7500 - mean_absolute_error: 1210.5901\n",
      "Epoch 00114: val_loss improved from 1888489.12500 to 1886924.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1869746.5000 - mean_squared_error: 1869746.5000 - mean_absolute_error: 1081.6635 - val_loss: 1886924.2500 - val_mean_squared_error: 1886924.2500 - val_mean_absolute_error: 1134.4116\n",
      "Epoch 115/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1911685.1250 - mean_squared_error: 1911685.1250 - mean_absolute_error: 1108.5277\n",
      "Epoch 00115: val_loss improved from 1886924.25000 to 1885342.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1868277.6765 - mean_squared_error: 1868277.6250 - mean_absolute_error: 1081.0234 - val_loss: 1885342.2500 - val_mean_squared_error: 1885342.2500 - val_mean_absolute_error: 1133.7915\n",
      "Epoch 116/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2065030.0000 - mean_squared_error: 2065030.0000 - mean_absolute_error: 1091.9546\n",
      "Epoch 00116: val_loss improved from 1885342.25000 to 1883710.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1866791.9118 - mean_squared_error: 1866791.8750 - mean_absolute_error: 1080.3610 - val_loss: 1883710.5000 - val_mean_squared_error: 1883710.5000 - val_mean_absolute_error: 1133.1542\n",
      "Epoch 117/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1939545.7500 - mean_squared_error: 1939545.7500 - mean_absolute_error: 1120.4229\n",
      "Epoch 00117: val_loss improved from 1883710.50000 to 1882012.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1865306.4191 - mean_squared_error: 1865306.5000 - mean_absolute_error: 1079.6987 - val_loss: 1882012.5000 - val_mean_squared_error: 1882012.5000 - val_mean_absolute_error: 1132.4889\n",
      "Epoch 118/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1518671.0000 - mean_squared_error: 1518671.0000 - mean_absolute_error: 1013.7719\n",
      "Epoch 00118: val_loss improved from 1882012.50000 to 1880326.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1863719.0147 - mean_squared_error: 1863719.0000 - mean_absolute_error: 1078.9884 - val_loss: 1880326.0000 - val_mean_squared_error: 1880326.0000 - val_mean_absolute_error: 1131.8264\n",
      "Epoch 119/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2185340.5000 - mean_squared_error: 2185340.5000 - mean_absolute_error: 1168.8206\n",
      "Epoch 00119: val_loss improved from 1880326.00000 to 1878590.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1862192.7426 - mean_squared_error: 1862192.7500 - mean_absolute_error: 1078.3007 - val_loss: 1878590.8750 - val_mean_squared_error: 1878590.8750 - val_mean_absolute_error: 1131.1471\n",
      "Epoch 120/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2470470.2500 - mean_squared_error: 2470470.2500 - mean_absolute_error: 1203.2319\n",
      "Epoch 00120: val_loss improved from 1878590.87500 to 1876850.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1860638.5432 - mean_squared_error: 1860638.6250 - mean_absolute_error: 1077.6019 - val_loss: 1876850.2500 - val_mean_squared_error: 1876850.2500 - val_mean_absolute_error: 1130.4651\n",
      "Epoch 121/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2315213.0000 - mean_squared_error: 2315213.0000 - mean_absolute_error: 1204.5066\n",
      "Epoch 00121: val_loss improved from 1876850.25000 to 1875099.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1859036.9926 - mean_squared_error: 1859037.0000 - mean_absolute_error: 1076.8833 - val_loss: 1875099.7500 - val_mean_squared_error: 1875099.7500 - val_mean_absolute_error: 1129.7739\n",
      "Epoch 122/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2202035.0000 - mean_squared_error: 2202035.0000 - mean_absolute_error: 1173.8617\n",
      "Epoch 00122: val_loss improved from 1875099.75000 to 1873311.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1857421.0809 - mean_squared_error: 1857421.0000 - mean_absolute_error: 1076.1523 - val_loss: 1873311.5000 - val_mean_squared_error: 1873311.5000 - val_mean_absolute_error: 1129.0669\n",
      "Epoch 123/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2114639.2500 - mean_squared_error: 2114639.2500 - mean_absolute_error: 1115.6582\n",
      "Epoch 00123: val_loss improved from 1873311.50000 to 1871484.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1855755.0221 - mean_squared_error: 1855755.0000 - mean_absolute_error: 1075.4060 - val_loss: 1871484.6250 - val_mean_squared_error: 1871484.6250 - val_mean_absolute_error: 1128.3435\n",
      "Epoch 124/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1770404.1250 - mean_squared_error: 1770404.1250 - mean_absolute_error: 1072.9082\n",
      "Epoch 00124: val_loss improved from 1871484.62500 to 1869558.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1854030.5515 - mean_squared_error: 1854030.6250 - mean_absolute_error: 1074.6335 - val_loss: 1869558.2500 - val_mean_squared_error: 1869558.2500 - val_mean_absolute_error: 1127.5823\n",
      "Epoch 125/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1744904.0000 - mean_squared_error: 1744904.0000 - mean_absolute_error: 1100.1436\n",
      "Epoch 00125: val_loss improved from 1869558.25000 to 1867546.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1852246.8971 - mean_squared_error: 1852247.0000 - mean_absolute_error: 1073.8199 - val_loss: 1867546.0000 - val_mean_squared_error: 1867546.0000 - val_mean_absolute_error: 1126.7864\n",
      "Epoch 126/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2271469.0000 - mean_squared_error: 2271469.0000 - mean_absolute_error: 1122.3140\n",
      "Epoch 00126: val_loss improved from 1867546.00000 to 1865449.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1850378.6912 - mean_squared_error: 1850378.7500 - mean_absolute_error: 1072.9769 - val_loss: 1865449.1250 - val_mean_squared_error: 1865449.1250 - val_mean_absolute_error: 1125.9565\n",
      "Epoch 127/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1895344.5000 - mean_squared_error: 1895344.5000 - mean_absolute_error: 1054.2233\n",
      "Epoch 00127: val_loss improved from 1865449.12500 to 1863288.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1848433.0882 - mean_squared_error: 1848433.0000 - mean_absolute_error: 1072.0889 - val_loss: 1863288.6250 - val_mean_squared_error: 1863288.6250 - val_mean_absolute_error: 1125.1010\n",
      "Epoch 128/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2244674.7500 - mean_squared_error: 2244674.7500 - mean_absolute_error: 1165.8632\n",
      "Epoch 00128: val_loss improved from 1863288.62500 to 1861062.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1846463.9338 - mean_squared_error: 1846464.0000 - mean_absolute_error: 1071.1743 - val_loss: 1861062.6250 - val_mean_squared_error: 1861062.6250 - val_mean_absolute_error: 1124.2184\n",
      "Epoch 129/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1166564.0000 - mean_squared_error: 1166564.0000 - mean_absolute_error: 891.3027\n",
      "Epoch 00129: val_loss improved from 1861062.62500 to 1858833.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 484us/sample - loss: 1844374.3162 - mean_squared_error: 1844374.3750 - mean_absolute_error: 1070.2468 - val_loss: 1858833.5000 - val_mean_squared_error: 1858833.5000 - val_mean_absolute_error: 1123.3257\n",
      "Epoch 130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1680285.2500 - mean_squared_error: 1680285.2500 - mean_absolute_error: 976.3167\n",
      "Epoch 00130: val_loss improved from 1858833.50000 to 1856613.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1842317.4375 - mean_squared_error: 1842317.3750 - mean_absolute_error: 1069.2839 - val_loss: 1856613.5000 - val_mean_squared_error: 1856613.5000 - val_mean_absolute_error: 1122.4349\n",
      "Epoch 131/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1698931.7500 - mean_squared_error: 1698931.7500 - mean_absolute_error: 1046.8158\n",
      "Epoch 00131: val_loss improved from 1856613.50000 to 1854344.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1840260.4118 - mean_squared_error: 1840260.5000 - mean_absolute_error: 1068.3198 - val_loss: 1854344.2500 - val_mean_squared_error: 1854344.2500 - val_mean_absolute_error: 1121.5237\n",
      "Epoch 132/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2365132.0000 - mean_squared_error: 2365132.0000 - mean_absolute_error: 1163.7092\n",
      "Epoch 00132: val_loss improved from 1854344.25000 to 1851989.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1838178.5735 - mean_squared_error: 1838178.5000 - mean_absolute_error: 1067.3408 - val_loss: 1851989.1250 - val_mean_squared_error: 1851989.1250 - val_mean_absolute_error: 1120.5770\n",
      "Epoch 133/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1301713.1250 - mean_squared_error: 1301713.1250 - mean_absolute_error: 865.6949\n",
      "Epoch 00133: val_loss improved from 1851989.12500 to 1849597.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1835903.2794 - mean_squared_error: 1835903.1250 - mean_absolute_error: 1066.3287 - val_loss: 1849597.7500 - val_mean_squared_error: 1849597.7500 - val_mean_absolute_error: 1119.6135\n",
      "Epoch 134/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1323718.5000 - mean_squared_error: 1323718.5000 - mean_absolute_error: 924.8952\n",
      "Epoch 00134: val_loss improved from 1849597.75000 to 1847150.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1833725.3860 - mean_squared_error: 1833725.3750 - mean_absolute_error: 1065.3015 - val_loss: 1847150.2500 - val_mean_squared_error: 1847150.2500 - val_mean_absolute_error: 1118.6250\n",
      "Epoch 135/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1583230.7500 - mean_squared_error: 1583230.7500 - mean_absolute_error: 1043.7256\n",
      "Epoch 00135: val_loss improved from 1847150.25000 to 1844679.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1831481.8824 - mean_squared_error: 1831481.8750 - mean_absolute_error: 1064.2485 - val_loss: 1844679.8750 - val_mean_squared_error: 1844679.8750 - val_mean_absolute_error: 1117.7252\n",
      "Epoch 136/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2021220.3750 - mean_squared_error: 2021220.3750 - mean_absolute_error: 1153.6292\n",
      "Epoch 00136: val_loss improved from 1844679.87500 to 1842164.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1829248.7831 - mean_squared_error: 1829248.8750 - mean_absolute_error: 1063.1743 - val_loss: 1842164.2500 - val_mean_squared_error: 1842164.2500 - val_mean_absolute_error: 1116.8334\n",
      "Epoch 137/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1946463.8750 - mean_squared_error: 1946463.8750 - mean_absolute_error: 1043.4744\n",
      "Epoch 00137: val_loss improved from 1842164.25000 to 1839643.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1826852.3088 - mean_squared_error: 1826852.2500 - mean_absolute_error: 1062.0728 - val_loss: 1839643.3750 - val_mean_squared_error: 1839643.3750 - val_mean_absolute_error: 1115.9388\n",
      "Epoch 138/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2122733.2500 - mean_squared_error: 2122733.2500 - mean_absolute_error: 1138.9088\n",
      "Epoch 00138: val_loss improved from 1839643.37500 to 1837082.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1824562.3254 - mean_squared_error: 1824562.3750 - mean_absolute_error: 1060.9873 - val_loss: 1837082.0000 - val_mean_squared_error: 1837082.0000 - val_mean_absolute_error: 1115.0293\n",
      "Epoch 139/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2214986.0000 - mean_squared_error: 2214986.0000 - mean_absolute_error: 1099.0862\n",
      "Epoch 00139: val_loss improved from 1837082.00000 to 1834533.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1822186.8603 - mean_squared_error: 1822186.8750 - mean_absolute_error: 1059.8896 - val_loss: 1834533.2500 - val_mean_squared_error: 1834533.2500 - val_mean_absolute_error: 1114.1228\n",
      "Epoch 140/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1666829.2500 - mean_squared_error: 1666829.2500 - mean_absolute_error: 956.8676\n",
      "Epoch 00140: val_loss improved from 1834533.25000 to 1831915.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1819752.5000 - mean_squared_error: 1819752.5000 - mean_absolute_error: 1058.7797 - val_loss: 1831915.6250 - val_mean_squared_error: 1831915.6250 - val_mean_absolute_error: 1113.1902\n",
      "Epoch 141/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2026449.2500 - mean_squared_error: 2026449.2500 - mean_absolute_error: 1139.4496\n",
      "Epoch 00141: val_loss improved from 1831915.62500 to 1829205.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1817414.5919 - mean_squared_error: 1817414.6250 - mean_absolute_error: 1057.6531 - val_loss: 1829205.7500 - val_mean_squared_error: 1829205.7500 - val_mean_absolute_error: 1112.2241\n",
      "Epoch 142/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1645183.8750 - mean_squared_error: 1645183.8750 - mean_absolute_error: 994.1962\n",
      "Epoch 00142: val_loss improved from 1829205.75000 to 1826480.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1814851.1912 - mean_squared_error: 1814851.1250 - mean_absolute_error: 1056.4833 - val_loss: 1826480.5000 - val_mean_squared_error: 1826480.5000 - val_mean_absolute_error: 1111.2515\n",
      "Epoch 143/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1668324.2500 - mean_squared_error: 1668324.2500 - mean_absolute_error: 1033.8817\n",
      "Epoch 00143: val_loss improved from 1826480.50000 to 1823666.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1812318.3971 - mean_squared_error: 1812318.5000 - mean_absolute_error: 1055.2882 - val_loss: 1823666.5000 - val_mean_squared_error: 1823666.5000 - val_mean_absolute_error: 1110.2471\n",
      "Epoch 144/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1971826.6250 - mean_squared_error: 1971826.6250 - mean_absolute_error: 1080.3145\n",
      "Epoch 00144: val_loss improved from 1823666.50000 to 1820806.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1809768.1912 - mean_squared_error: 1809768.2500 - mean_absolute_error: 1054.0850 - val_loss: 1820806.5000 - val_mean_squared_error: 1820806.5000 - val_mean_absolute_error: 1109.2251\n",
      "Epoch 145/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2245611.5000 - mean_squared_error: 2245611.5000 - mean_absolute_error: 1141.2385\n",
      "Epoch 00145: val_loss improved from 1820806.50000 to 1817947.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1807111.7794 - mean_squared_error: 1807111.7500 - mean_absolute_error: 1052.8447 - val_loss: 1817947.7500 - val_mean_squared_error: 1817947.7500 - val_mean_absolute_error: 1108.2017\n",
      "Epoch 146/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1828065.6250 - mean_squared_error: 1828065.6250 - mean_absolute_error: 1128.1648\n",
      "Epoch 00146: val_loss improved from 1817947.75000 to 1815015.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1804477.1176 - mean_squared_error: 1804477.1250 - mean_absolute_error: 1051.6028 - val_loss: 1815015.7500 - val_mean_squared_error: 1815015.7500 - val_mean_absolute_error: 1107.1508\n",
      "Epoch 147/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1809742.5000 - mean_squared_error: 1809742.5000 - mean_absolute_error: 1091.3484\n",
      "Epoch 00147: val_loss improved from 1815015.75000 to 1812086.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1801786.4191 - mean_squared_error: 1801786.5000 - mean_absolute_error: 1050.3407 - val_loss: 1812086.5000 - val_mean_squared_error: 1812086.5000 - val_mean_absolute_error: 1106.0997\n",
      "Epoch 148/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1044766.9375 - mean_squared_error: 1044766.9375 - mean_absolute_error: 870.3755\n",
      "Epoch 00148: val_loss improved from 1812086.50000 to 1809169.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1799000.9485 - mean_squared_error: 1799001.0000 - mean_absolute_error: 1049.1079 - val_loss: 1809169.3750 - val_mean_squared_error: 1809169.3750 - val_mean_absolute_error: 1105.0513\n",
      "Epoch 149/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2631460.7500 - mean_squared_error: 2631460.7500 - mean_absolute_error: 1267.4667\n",
      "Epoch 00149: val_loss improved from 1809169.37500 to 1806188.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1796419.2776 - mean_squared_error: 1796419.2500 - mean_absolute_error: 1047.8591 - val_loss: 1806188.7500 - val_mean_squared_error: 1806188.7500 - val_mean_absolute_error: 1103.9785\n",
      "Epoch 150/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1887153.5000 - mean_squared_error: 1887153.5000 - mean_absolute_error: 1053.6421\n",
      "Epoch 00150: val_loss improved from 1806188.75000 to 1803213.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1793617.3235 - mean_squared_error: 1793617.2500 - mean_absolute_error: 1046.6176 - val_loss: 1803213.5000 - val_mean_squared_error: 1803213.5000 - val_mean_absolute_error: 1102.9050\n",
      "Epoch 151/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 694386.0625 - mean_squared_error: 694386.0625 - mean_absolute_error: 669.5627\n",
      "Epoch 00151: val_loss improved from 1803213.50000 to 1800173.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1790700.4926 - mean_squared_error: 1790700.5000 - mean_absolute_error: 1045.3159 - val_loss: 1800173.3750 - val_mean_squared_error: 1800173.3750 - val_mean_absolute_error: 1101.8060\n",
      "Epoch 152/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1375958.5000 - mean_squared_error: 1375958.5000 - mean_absolute_error: 904.5946\n",
      "Epoch 00152: val_loss improved from 1800173.37500 to 1797037.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1787996.3088 - mean_squared_error: 1787996.3750 - mean_absolute_error: 1044.0247 - val_loss: 1797037.8750 - val_mean_squared_error: 1797037.8750 - val_mean_absolute_error: 1100.6709\n",
      "Epoch 153/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1335709.7500 - mean_squared_error: 1335709.7500 - mean_absolute_error: 893.1425\n",
      "Epoch 00153: val_loss improved from 1797037.87500 to 1793864.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1785051.2647 - mean_squared_error: 1785051.2500 - mean_absolute_error: 1042.6641 - val_loss: 1793864.2500 - val_mean_squared_error: 1793864.2500 - val_mean_absolute_error: 1099.5216\n",
      "Epoch 154/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1827340.5000 - mean_squared_error: 1827340.5000 - mean_absolute_error: 1115.8451\n",
      "Epoch 00154: val_loss improved from 1793864.25000 to 1790601.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1782201.4154 - mean_squared_error: 1782201.3750 - mean_absolute_error: 1041.2910 - val_loss: 1790601.0000 - val_mean_squared_error: 1790601.0000 - val_mean_absolute_error: 1098.3385\n",
      "Epoch 155/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 926052.6875 - mean_squared_error: 926052.6875 - mean_absolute_error: 788.1437\n",
      "Epoch 00155: val_loss improved from 1790601.00000 to 1787368.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1779085.6397 - mean_squared_error: 1779085.6250 - mean_absolute_error: 1039.9324 - val_loss: 1787368.8750 - val_mean_squared_error: 1787368.8750 - val_mean_absolute_error: 1097.1647\n",
      "Epoch 156/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1247598.2500 - mean_squared_error: 1247598.2500 - mean_absolute_error: 842.0665\n",
      "Epoch 00156: val_loss improved from 1787368.87500 to 1784043.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1776072.3235 - mean_squared_error: 1776072.3750 - mean_absolute_error: 1038.5188 - val_loss: 1784043.3750 - val_mean_squared_error: 1784043.3750 - val_mean_absolute_error: 1095.9565\n",
      "Epoch 157/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1988506.3750 - mean_squared_error: 1988506.3750 - mean_absolute_error: 1140.5171\n",
      "Epoch 00157: val_loss improved from 1784043.37500 to 1780593.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1773154.2500 - mean_squared_error: 1773154.2500 - mean_absolute_error: 1037.0931 - val_loss: 1780593.1250 - val_mean_squared_error: 1780593.1250 - val_mean_absolute_error: 1094.7020\n",
      "Epoch 158/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2342995.0000 - mean_squared_error: 2342995.0000 - mean_absolute_error: 1214.6980\n",
      "Epoch 00158: val_loss improved from 1780593.12500 to 1777150.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1770004.3235 - mean_squared_error: 1770004.2500 - mean_absolute_error: 1035.6516 - val_loss: 1777150.0000 - val_mean_squared_error: 1777150.0000 - val_mean_absolute_error: 1093.4487\n",
      "Epoch 159/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1635491.2500 - mean_squared_error: 1635491.2500 - mean_absolute_error: 1053.7977\n",
      "Epoch 00159: val_loss improved from 1777150.00000 to 1773773.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1766812.0349 - mean_squared_error: 1766812.0000 - mean_absolute_error: 1034.1892 - val_loss: 1773773.8750 - val_mean_squared_error: 1773773.8750 - val_mean_absolute_error: 1092.2180\n",
      "Epoch 160/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1408253.5000 - mean_squared_error: 1408253.5000 - mean_absolute_error: 893.6004\n",
      "Epoch 00160: val_loss improved from 1773773.87500 to 1770494.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1763633.7059 - mean_squared_error: 1763633.6250 - mean_absolute_error: 1032.7483 - val_loss: 1770494.6250 - val_mean_squared_error: 1770494.6250 - val_mean_absolute_error: 1091.0204\n",
      "Epoch 161/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 925405.6250 - mean_squared_error: 925405.6250 - mean_absolute_error: 778.9669\n",
      "Epoch 00161: val_loss improved from 1770494.62500 to 1767186.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1760603.2757 - mean_squared_error: 1760603.1250 - mean_absolute_error: 1031.3505 - val_loss: 1767186.0000 - val_mean_squared_error: 1767186.0000 - val_mean_absolute_error: 1089.8098\n",
      "Epoch 162/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1107701.5000 - mean_squared_error: 1107701.5000 - mean_absolute_error: 868.0481\n",
      "Epoch 00162: val_loss improved from 1767186.00000 to 1763914.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1757621.6213 - mean_squared_error: 1757621.6250 - mean_absolute_error: 1029.9243 - val_loss: 1763914.1250 - val_mean_squared_error: 1763914.1250 - val_mean_absolute_error: 1088.6637\n",
      "Epoch 163/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2308053.2500 - mean_squared_error: 2308053.2500 - mean_absolute_error: 1156.5308\n",
      "Epoch 00163: val_loss improved from 1763914.12500 to 1760634.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1754683.0735 - mean_squared_error: 1754683.0000 - mean_absolute_error: 1028.5189 - val_loss: 1760634.0000 - val_mean_squared_error: 1760634.0000 - val_mean_absolute_error: 1087.6244\n",
      "Epoch 164/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1637189.8750 - mean_squared_error: 1637189.8750 - mean_absolute_error: 965.6777\n",
      "Epoch 00164: val_loss improved from 1760634.00000 to 1757265.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1751566.9853 - mean_squared_error: 1751567.0000 - mean_absolute_error: 1027.0857 - val_loss: 1757265.2500 - val_mean_squared_error: 1757265.2500 - val_mean_absolute_error: 1086.5555\n",
      "Epoch 165/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1475148.0000 - mean_squared_error: 1475148.0000 - mean_absolute_error: 969.0397\n",
      "Epoch 00165: val_loss improved from 1757265.25000 to 1753762.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1748445.3235 - mean_squared_error: 1748445.2500 - mean_absolute_error: 1025.6200 - val_loss: 1753762.8750 - val_mean_squared_error: 1753762.8750 - val_mean_absolute_error: 1085.4426\n",
      "Epoch 166/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2229684.0000 - mean_squared_error: 2229684.0000 - mean_absolute_error: 1167.2170\n",
      "Epoch 00166: val_loss improved from 1753762.87500 to 1750112.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1745252.1471 - mean_squared_error: 1745252.1250 - mean_absolute_error: 1024.0697 - val_loss: 1750112.8750 - val_mean_squared_error: 1750112.8750 - val_mean_absolute_error: 1084.2798\n",
      "Epoch 167/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2298673.0000 - mean_squared_error: 2298673.0000 - mean_absolute_error: 1125.7853\n",
      "Epoch 00167: val_loss improved from 1750112.87500 to 1746363.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1741845.3309 - mean_squared_error: 1741845.2500 - mean_absolute_error: 1022.4854 - val_loss: 1746363.0000 - val_mean_squared_error: 1746363.0000 - val_mean_absolute_error: 1083.0835\n",
      "Epoch 168/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1918234.2500 - mean_squared_error: 1918234.2500 - mean_absolute_error: 1065.9111\n",
      "Epoch 00168: val_loss improved from 1746363.00000 to 1742518.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1738363.8897 - mean_squared_error: 1738363.8750 - mean_absolute_error: 1020.8505 - val_loss: 1742518.3750 - val_mean_squared_error: 1742518.3750 - val_mean_absolute_error: 1081.8553\n",
      "Epoch 169/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1397025.7500 - mean_squared_error: 1397025.7500 - mean_absolute_error: 888.9459\n",
      "Epoch 00169: val_loss improved from 1742518.37500 to 1738682.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1734789.0956 - mean_squared_error: 1734789.0000 - mean_absolute_error: 1019.1473 - val_loss: 1738682.5000 - val_mean_squared_error: 1738682.5000 - val_mean_absolute_error: 1080.6279\n",
      "Epoch 170/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1687595.7500 - mean_squared_error: 1687595.7500 - mean_absolute_error: 1007.3489\n",
      "Epoch 00170: val_loss improved from 1738682.50000 to 1734846.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1731297.1103 - mean_squared_error: 1731297.1250 - mean_absolute_error: 1017.4581 - val_loss: 1734846.0000 - val_mean_squared_error: 1734846.0000 - val_mean_absolute_error: 1079.3981\n",
      "Epoch 171/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2420240.0000 - mean_squared_error: 2420240.0000 - mean_absolute_error: 1176.7463\n",
      "Epoch 00171: val_loss improved from 1734846.00000 to 1730941.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1727831.2647 - mean_squared_error: 1727831.2500 - mean_absolute_error: 1015.7672 - val_loss: 1730941.2500 - val_mean_squared_error: 1730941.2500 - val_mean_absolute_error: 1078.1438\n",
      "Epoch 172/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2044767.6250 - mean_squared_error: 2044767.6250 - mean_absolute_error: 1062.4142\n",
      "Epoch 00172: val_loss improved from 1730941.25000 to 1726988.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1724189.5735 - mean_squared_error: 1724189.6250 - mean_absolute_error: 1014.0465 - val_loss: 1726988.5000 - val_mean_squared_error: 1726988.5000 - val_mean_absolute_error: 1076.9219\n",
      "Epoch 173/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1686650.6250 - mean_squared_error: 1686650.6250 - mean_absolute_error: 1080.2825\n",
      "Epoch 00173: val_loss improved from 1726988.50000 to 1723026.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1720622.7721 - mean_squared_error: 1720622.8750 - mean_absolute_error: 1012.3511 - val_loss: 1723026.1250 - val_mean_squared_error: 1723026.1250 - val_mean_absolute_error: 1075.8467\n",
      "Epoch 174/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1862561.6250 - mean_squared_error: 1862561.6250 - mean_absolute_error: 1109.1316\n",
      "Epoch 00174: val_loss improved from 1723026.12500 to 1719048.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1716973.6618 - mean_squared_error: 1716973.7500 - mean_absolute_error: 1010.5854 - val_loss: 1719048.5000 - val_mean_squared_error: 1719048.5000 - val_mean_absolute_error: 1074.7633\n",
      "Epoch 175/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1052759.3750 - mean_squared_error: 1052759.3750 - mean_absolute_error: 833.3099\n",
      "Epoch 00175: val_loss improved from 1719048.50000 to 1715059.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1713195.4044 - mean_squared_error: 1713195.3750 - mean_absolute_error: 1008.8096 - val_loss: 1715059.5000 - val_mean_squared_error: 1715059.5000 - val_mean_absolute_error: 1073.6752\n",
      "Epoch 176/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1516561.0000 - mean_squared_error: 1516561.0000 - mean_absolute_error: 912.4436\n",
      "Epoch 00176: val_loss improved from 1715059.50000 to 1711084.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1709559.5588 - mean_squared_error: 1709559.6250 - mean_absolute_error: 1007.0397 - val_loss: 1711084.1250 - val_mean_squared_error: 1711084.1250 - val_mean_absolute_error: 1072.5908\n",
      "Epoch 177/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2138703.0000 - mean_squared_error: 2138703.0000 - mean_absolute_error: 1098.8459\n",
      "Epoch 00177: val_loss improved from 1711084.12500 to 1707081.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1706017.9154 - mean_squared_error: 1706017.8750 - mean_absolute_error: 1005.2819 - val_loss: 1707081.7500 - val_mean_squared_error: 1707081.7500 - val_mean_absolute_error: 1071.4956\n",
      "Epoch 178/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1867075.0000 - mean_squared_error: 1867075.0000 - mean_absolute_error: 1011.0518\n",
      "Epoch 00178: val_loss improved from 1707081.75000 to 1703100.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1702267.2206 - mean_squared_error: 1702267.1250 - mean_absolute_error: 1003.5284 - val_loss: 1703100.5000 - val_mean_squared_error: 1703100.5000 - val_mean_absolute_error: 1070.4043\n",
      "Epoch 179/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1684953.0000 - mean_squared_error: 1684953.0000 - mean_absolute_error: 1028.8379\n",
      "Epoch 00179: val_loss improved from 1703100.50000 to 1699062.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1698662.9044 - mean_squared_error: 1698663.0000 - mean_absolute_error: 1001.7791 - val_loss: 1699062.7500 - val_mean_squared_error: 1699062.7500 - val_mean_absolute_error: 1069.2977\n",
      "Epoch 180/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2145135.0000 - mean_squared_error: 2145135.0000 - mean_absolute_error: 1195.4160\n",
      "Epoch 00180: val_loss improved from 1699062.75000 to 1695005.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1694987.8235 - mean_squared_error: 1694987.8750 - mean_absolute_error: 999.9560 - val_loss: 1695005.2500 - val_mean_squared_error: 1695005.2500 - val_mean_absolute_error: 1068.1841\n",
      "Epoch 181/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 898255.0000 - mean_squared_error: 898255.0000 - mean_absolute_error: 774.4934\n",
      "Epoch 00181: val_loss improved from 1695005.25000 to 1690890.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1691146.4706 - mean_squared_error: 1691146.5000 - mean_absolute_error: 998.1470 - val_loss: 1690890.6250 - val_mean_squared_error: 1690890.6250 - val_mean_absolute_error: 1067.0524\n",
      "Epoch 182/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1545637.7500 - mean_squared_error: 1545637.7500 - mean_absolute_error: 1015.8877\n",
      "Epoch 00182: val_loss improved from 1690890.62500 to 1686790.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1687464.4559 - mean_squared_error: 1687464.5000 - mean_absolute_error: 996.3281 - val_loss: 1686790.6250 - val_mean_squared_error: 1686790.6250 - val_mean_absolute_error: 1065.9213\n",
      "Epoch 183/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1456391.2500 - mean_squared_error: 1456391.2500 - mean_absolute_error: 926.5963\n",
      "Epoch 00183: val_loss improved from 1686790.62500 to 1682669.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1683645.0000 - mean_squared_error: 1683645.0000 - mean_absolute_error: 994.4432 - val_loss: 1682669.5000 - val_mean_squared_error: 1682669.5000 - val_mean_absolute_error: 1064.7794\n",
      "Epoch 184/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1971079.7500 - mean_squared_error: 1971079.7500 - mean_absolute_error: 1036.1753\n",
      "Epoch 00184: val_loss improved from 1682669.50000 to 1678531.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1679891.6618 - mean_squared_error: 1679891.6250 - mean_absolute_error: 992.5751 - val_loss: 1678531.3750 - val_mean_squared_error: 1678531.3750 - val_mean_absolute_error: 1063.6318\n",
      "Epoch 185/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1639996.5000 - mean_squared_error: 1639996.5000 - mean_absolute_error: 954.2796\n",
      "Epoch 00185: val_loss improved from 1678531.37500 to 1674262.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1676026.4853 - mean_squared_error: 1676026.6250 - mean_absolute_error: 990.7587 - val_loss: 1674262.6250 - val_mean_squared_error: 1674262.6250 - val_mean_absolute_error: 1062.4435\n",
      "Epoch 186/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1615450.2500 - mean_squared_error: 1615450.2500 - mean_absolute_error: 988.6139\n",
      "Epoch 00186: val_loss improved from 1674262.62500 to 1669868.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1672166.5221 - mean_squared_error: 1672166.5000 - mean_absolute_error: 988.8034 - val_loss: 1669868.7500 - val_mean_squared_error: 1669868.7500 - val_mean_absolute_error: 1061.2156\n",
      "Epoch 187/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1532518.0000 - mean_squared_error: 1532518.0000 - mean_absolute_error: 952.5625\n",
      "Epoch 00187: val_loss improved from 1669868.75000 to 1665505.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1668111.3088 - mean_squared_error: 1668111.2500 - mean_absolute_error: 986.8395 - val_loss: 1665505.1250 - val_mean_squared_error: 1665505.1250 - val_mean_absolute_error: 1059.9927\n",
      "Epoch 188/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1484384.5000 - mean_squared_error: 1484384.5000 - mean_absolute_error: 948.5134\n",
      "Epoch 00188: val_loss improved from 1665505.12500 to 1661116.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1664120.9485 - mean_squared_error: 1664121.0000 - mean_absolute_error: 984.8923 - val_loss: 1661116.3750 - val_mean_squared_error: 1661116.3750 - val_mean_absolute_error: 1058.7622\n",
      "Epoch 189/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1733414.2500 - mean_squared_error: 1733414.2500 - mean_absolute_error: 975.2025\n",
      "Epoch 00189: val_loss improved from 1661116.37500 to 1656723.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1660112.2206 - mean_squared_error: 1660112.2500 - mean_absolute_error: 982.8764 - val_loss: 1656723.1250 - val_mean_squared_error: 1656723.1250 - val_mean_absolute_error: 1057.5295\n",
      "Epoch 190/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1266165.7500 - mean_squared_error: 1266165.7500 - mean_absolute_error: 920.1814\n",
      "Epoch 00190: val_loss improved from 1656723.12500 to 1652430.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1656114.6452 - mean_squared_error: 1656114.6250 - mean_absolute_error: 980.9302 - val_loss: 1652430.2500 - val_mean_squared_error: 1652430.2500 - val_mean_absolute_error: 1056.3260\n",
      "Epoch 191/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1369017.5000 - mean_squared_error: 1369017.5000 - mean_absolute_error: 876.4271\n",
      "Epoch 00191: val_loss improved from 1652430.25000 to 1648183.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1652152.7794 - mean_squared_error: 1652152.8750 - mean_absolute_error: 979.0073 - val_loss: 1648183.5000 - val_mean_squared_error: 1648183.5000 - val_mean_absolute_error: 1055.1327\n",
      "Epoch 192/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1605139.6250 - mean_squared_error: 1605139.6250 - mean_absolute_error: 899.7635\n",
      "Epoch 00192: val_loss improved from 1648183.50000 to 1643909.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1648292.1176 - mean_squared_error: 1648292.1250 - mean_absolute_error: 977.1277 - val_loss: 1643909.3750 - val_mean_squared_error: 1643909.3750 - val_mean_absolute_error: 1053.9260\n",
      "Epoch 193/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1310751.0000 - mean_squared_error: 1310751.0000 - mean_absolute_error: 870.3187\n",
      "Epoch 00193: val_loss improved from 1643909.37500 to 1639509.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1644329.5294 - mean_squared_error: 1644329.5000 - mean_absolute_error: 975.2600 - val_loss: 1639509.8750 - val_mean_squared_error: 1639509.8750 - val_mean_absolute_error: 1052.6805\n",
      "Epoch 194/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2329971.5000 - mean_squared_error: 2329971.5000 - mean_absolute_error: 1129.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00194: val_loss improved from 1639509.87500 to 1634892.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1640403.3529 - mean_squared_error: 1640403.3750 - mean_absolute_error: 973.2448 - val_loss: 1634892.0000 - val_mean_squared_error: 1634892.0000 - val_mean_absolute_error: 1051.3678\n",
      "Epoch 195/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1373950.7500 - mean_squared_error: 1373950.7500 - mean_absolute_error: 935.0703\n",
      "Epoch 00195: val_loss improved from 1634892.00000 to 1630232.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1636094.4412 - mean_squared_error: 1636094.5000 - mean_absolute_error: 971.1849 - val_loss: 1630232.2500 - val_mean_squared_error: 1630232.2500 - val_mean_absolute_error: 1050.0442\n",
      "Epoch 196/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1788273.0000 - mean_squared_error: 1788273.0000 - mean_absolute_error: 1003.1128\n",
      "Epoch 00196: val_loss improved from 1630232.25000 to 1625554.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1631886.8750 - mean_squared_error: 1631886.8750 - mean_absolute_error: 969.1173 - val_loss: 1625554.7500 - val_mean_squared_error: 1625554.7500 - val_mean_absolute_error: 1048.7103\n",
      "Epoch 197/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1752831.0000 - mean_squared_error: 1752831.0000 - mean_absolute_error: 1015.1299\n",
      "Epoch 00197: val_loss improved from 1625554.75000 to 1620933.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1627606.2206 - mean_squared_error: 1627606.2500 - mean_absolute_error: 967.0620 - val_loss: 1620933.7500 - val_mean_squared_error: 1620933.7500 - val_mean_absolute_error: 1047.3879\n",
      "Epoch 198/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2105897.5000 - mean_squared_error: 2105897.5000 - mean_absolute_error: 1087.6724\n",
      "Epoch 00198: val_loss improved from 1620933.75000 to 1616220.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1623434.8824 - mean_squared_error: 1623435.0000 - mean_absolute_error: 964.9921 - val_loss: 1616220.1250 - val_mean_squared_error: 1616220.1250 - val_mean_absolute_error: 1046.0331\n",
      "Epoch 199/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1847270.7500 - mean_squared_error: 1847270.7500 - mean_absolute_error: 1082.8230\n",
      "Epoch 00199: val_loss improved from 1616220.12500 to 1611580.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1619181.3382 - mean_squared_error: 1619181.2500 - mean_absolute_error: 962.9539 - val_loss: 1611580.0000 - val_mean_squared_error: 1611580.0000 - val_mean_absolute_error: 1044.6995\n",
      "Epoch 200/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2258823.5000 - mean_squared_error: 2258823.5000 - mean_absolute_error: 1129.5381\n",
      "Epoch 00200: val_loss improved from 1611580.00000 to 1606957.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1614935.9191 - mean_squared_error: 1614936.0000 - mean_absolute_error: 960.9309 - val_loss: 1606957.2500 - val_mean_squared_error: 1606957.2500 - val_mean_absolute_error: 1043.3699\n",
      "Epoch 201/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1132478.0000 - mean_squared_error: 1132478.0000 - mean_absolute_error: 835.0774\n",
      "Epoch 00201: val_loss improved from 1606957.25000 to 1602264.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1610541.9559 - mean_squared_error: 1610542.0000 - mean_absolute_error: 958.9086 - val_loss: 1602264.2500 - val_mean_squared_error: 1602264.2500 - val_mean_absolute_error: 1042.0156\n",
      "Epoch 202/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1747973.3750 - mean_squared_error: 1747973.3750 - mean_absolute_error: 1030.4680\n",
      "Epoch 00202: val_loss improved from 1602264.25000 to 1597502.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1606391.7794 - mean_squared_error: 1606391.7500 - mean_absolute_error: 956.8696 - val_loss: 1597502.0000 - val_mean_squared_error: 1597502.0000 - val_mean_absolute_error: 1040.6364\n",
      "Epoch 203/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1097899.2500 - mean_squared_error: 1097899.2500 - mean_absolute_error: 852.1732\n",
      "Epoch 00203: val_loss improved from 1597502.00000 to 1592765.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1601938.6618 - mean_squared_error: 1601938.7500 - mean_absolute_error: 954.7650 - val_loss: 1592765.3750 - val_mean_squared_error: 1592765.3750 - val_mean_absolute_error: 1039.2610\n",
      "Epoch 204/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1241571.5000 - mean_squared_error: 1241571.5000 - mean_absolute_error: 868.3456\n",
      "Epoch 00204: val_loss improved from 1592765.37500 to 1588068.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1597687.2426 - mean_squared_error: 1597687.1250 - mean_absolute_error: 952.7395 - val_loss: 1588068.5000 - val_mean_squared_error: 1588068.5000 - val_mean_absolute_error: 1037.8926\n",
      "Epoch 205/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1323654.7500 - mean_squared_error: 1323654.7500 - mean_absolute_error: 912.7476\n",
      "Epoch 00205: val_loss improved from 1588068.50000 to 1583474.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1593482.2279 - mean_squared_error: 1593482.1250 - mean_absolute_error: 950.6729 - val_loss: 1583474.8750 - val_mean_squared_error: 1583474.8750 - val_mean_absolute_error: 1036.5513\n",
      "Epoch 206/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1467311.2500 - mean_squared_error: 1467311.2500 - mean_absolute_error: 943.9761\n",
      "Epoch 00206: val_loss improved from 1583474.87500 to 1578976.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1589357.1664 - mean_squared_error: 1589357.0000 - mean_absolute_error: 948.7026 - val_loss: 1578976.7500 - val_mean_squared_error: 1578976.7500 - val_mean_absolute_error: 1035.2362\n",
      "Epoch 207/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1298441.5000 - mean_squared_error: 1298441.5000 - mean_absolute_error: 829.5333\n",
      "Epoch 00207: val_loss improved from 1578976.75000 to 1574620.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1585189.0846 - mean_squared_error: 1585189.1250 - mean_absolute_error: 946.6574 - val_loss: 1574620.2500 - val_mean_squared_error: 1574620.2500 - val_mean_absolute_error: 1033.9614\n",
      "Epoch 208/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1606706.0000 - mean_squared_error: 1606706.0000 - mean_absolute_error: 1015.9188\n",
      "Epoch 00208: val_loss improved from 1574620.25000 to 1570158.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1581303.4118 - mean_squared_error: 1581303.3750 - mean_absolute_error: 944.7325 - val_loss: 1570158.2500 - val_mean_squared_error: 1570158.2500 - val_mean_absolute_error: 1032.6526\n",
      "Epoch 209/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1712500.0000 - mean_squared_error: 1712500.0000 - mean_absolute_error: 1014.1207\n",
      "Epoch 00209: val_loss improved from 1570158.25000 to 1565608.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1577242.1801 - mean_squared_error: 1577242.2500 - mean_absolute_error: 942.7436 - val_loss: 1565608.0000 - val_mean_squared_error: 1565608.0000 - val_mean_absolute_error: 1031.3136\n",
      "Epoch 210/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1817647.7500 - mean_squared_error: 1817647.7500 - mean_absolute_error: 1072.2417\n",
      "Epoch 00210: val_loss improved from 1565608.00000 to 1560979.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1573067.0735 - mean_squared_error: 1573067.1250 - mean_absolute_error: 940.6998 - val_loss: 1560979.6250 - val_mean_squared_error: 1560979.6250 - val_mean_absolute_error: 1029.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 211/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2161600.0000 - mean_squared_error: 2161600.0000 - mean_absolute_error: 1051.1206\n",
      "Epoch 00211: val_loss improved from 1560979.62500 to 1556205.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1568839.4081 - mean_squared_error: 1568839.3750 - mean_absolute_error: 938.6411 - val_loss: 1556205.1250 - val_mean_squared_error: 1556205.1250 - val_mean_absolute_error: 1028.5333\n",
      "Epoch 212/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2022243.7500 - mean_squared_error: 2022243.7500 - mean_absolute_error: 1018.7386\n",
      "Epoch 00212: val_loss improved from 1556205.12500 to 1551387.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1564444.3088 - mean_squared_error: 1564444.3750 - mean_absolute_error: 936.4572 - val_loss: 1551387.7500 - val_mean_squared_error: 1551387.7500 - val_mean_absolute_error: 1027.1039\n",
      "Epoch 213/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1522706.0000 - mean_squared_error: 1522706.0000 - mean_absolute_error: 930.9258\n",
      "Epoch 00213: val_loss improved from 1551387.75000 to 1546444.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1560053.4890 - mean_squared_error: 1560053.5000 - mean_absolute_error: 934.3135 - val_loss: 1546444.7500 - val_mean_squared_error: 1546444.7500 - val_mean_absolute_error: 1025.6355\n",
      "Epoch 214/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1912871.5000 - mean_squared_error: 1912871.5000 - mean_absolute_error: 1039.9991\n",
      "Epoch 00214: val_loss improved from 1546444.75000 to 1541405.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1555499.8088 - mean_squared_error: 1555499.7500 - mean_absolute_error: 932.0402 - val_loss: 1541405.8750 - val_mean_squared_error: 1541405.8750 - val_mean_absolute_error: 1024.1353\n",
      "Epoch 215/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1668237.0000 - mean_squared_error: 1668237.0000 - mean_absolute_error: 1050.2471\n",
      "Epoch 00215: val_loss improved from 1541405.87500 to 1536106.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1550951.1912 - mean_squared_error: 1550951.1250 - mean_absolute_error: 929.7156 - val_loss: 1536106.1250 - val_mean_squared_error: 1536106.1250 - val_mean_absolute_error: 1022.5537\n",
      "Epoch 216/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1387361.0000 - mean_squared_error: 1387361.0000 - mean_absolute_error: 843.9589\n",
      "Epoch 00216: val_loss improved from 1536106.12500 to 1530820.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1546048.2206 - mean_squared_error: 1546048.2500 - mean_absolute_error: 927.3160 - val_loss: 1530820.2500 - val_mean_squared_error: 1530820.2500 - val_mean_absolute_error: 1020.9684\n",
      "Epoch 217/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1196227.1250 - mean_squared_error: 1196227.1250 - mean_absolute_error: 822.4453\n",
      "Epoch 00217: val_loss improved from 1530820.25000 to 1525527.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1541199.1618 - mean_squared_error: 1541199.0000 - mean_absolute_error: 924.9250 - val_loss: 1525527.0000 - val_mean_squared_error: 1525527.0000 - val_mean_absolute_error: 1019.3714\n",
      "Epoch 218/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 764129.5625 - mean_squared_error: 764129.5625 - mean_absolute_error: 662.0784\n",
      "Epoch 00218: val_loss improved from 1525527.00000 to 1520140.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1536264.2353 - mean_squared_error: 1536264.2500 - mean_absolute_error: 922.5233 - val_loss: 1520140.1250 - val_mean_squared_error: 1520140.1250 - val_mean_absolute_error: 1017.7387\n",
      "Epoch 219/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1273174.3750 - mean_squared_error: 1273174.3750 - mean_absolute_error: 843.2985\n",
      "Epoch 00219: val_loss improved from 1520140.12500 to 1514524.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1531460.1765 - mean_squared_error: 1531460.2500 - mean_absolute_error: 920.0092 - val_loss: 1514524.7500 - val_mean_squared_error: 1514524.7500 - val_mean_absolute_error: 1016.0304\n",
      "Epoch 220/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1695383.2500 - mean_squared_error: 1695383.2500 - mean_absolute_error: 962.4352\n",
      "Epoch 00220: val_loss improved from 1514524.75000 to 1508847.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1526463.4559 - mean_squared_error: 1526463.3750 - mean_absolute_error: 917.4952 - val_loss: 1508847.8750 - val_mean_squared_error: 1508847.8750 - val_mean_absolute_error: 1014.2986\n",
      "Epoch 221/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1577734.1250 - mean_squared_error: 1577734.1250 - mean_absolute_error: 912.2117\n",
      "Epoch 00221: val_loss improved from 1508847.87500 to 1503244.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1521340.9044 - mean_squared_error: 1521341.0000 - mean_absolute_error: 914.9373 - val_loss: 1503244.5000 - val_mean_squared_error: 1503244.5000 - val_mean_absolute_error: 1012.5839\n",
      "Epoch 222/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1248615.3750 - mean_squared_error: 1248615.3750 - mean_absolute_error: 815.6151\n",
      "Epoch 00222: val_loss improved from 1503244.50000 to 1497719.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1516151.3088 - mean_squared_error: 1516151.3750 - mean_absolute_error: 912.3564 - val_loss: 1497719.5000 - val_mean_squared_error: 1497719.5000 - val_mean_absolute_error: 1010.8880\n",
      "Epoch 223/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1798077.0000 - mean_squared_error: 1798077.0000 - mean_absolute_error: 990.9379\n",
      "Epoch 00223: val_loss improved from 1497719.50000 to 1492147.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1511366.6985 - mean_squared_error: 1511366.6250 - mean_absolute_error: 909.7954 - val_loss: 1492147.3750 - val_mean_squared_error: 1492147.3750 - val_mean_absolute_error: 1009.1700\n",
      "Epoch 224/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1238457.7500 - mean_squared_error: 1238457.7500 - mean_absolute_error: 791.8791\n",
      "Epoch 00224: val_loss improved from 1492147.37500 to 1486827.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1506227.6195 - mean_squared_error: 1506227.6250 - mean_absolute_error: 907.2441 - val_loss: 1486827.5000 - val_mean_squared_error: 1486827.5000 - val_mean_absolute_error: 1007.5262\n",
      "Epoch 225/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1594585.0000 - mean_squared_error: 1594585.0000 - mean_absolute_error: 867.5310\n",
      "Epoch 00225: val_loss improved from 1486827.50000 to 1481651.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 264us/sample - loss: 1501521.3879 - mean_squared_error: 1501521.3750 - mean_absolute_error: 904.8149 - val_loss: 1481651.5000 - val_mean_squared_error: 1481651.5000 - val_mean_absolute_error: 1005.9269\n",
      "Epoch 226/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1462860.0000 - mean_squared_error: 1462860.0000 - mean_absolute_error: 843.1315\n",
      "Epoch 00226: val_loss improved from 1481651.50000 to 1476568.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1496830.5662 - mean_squared_error: 1496830.6250 - mean_absolute_error: 902.3980 - val_loss: 1476568.1250 - val_mean_squared_error: 1476568.1250 - val_mean_absolute_error: 1004.3527\n",
      "Epoch 227/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 1796862.0000 - mean_squared_error: 1796862.0000 - mean_absolute_error: 956.4254\n",
      "Epoch 00227: val_loss improved from 1476568.12500 to 1471584.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1492366.6765 - mean_squared_error: 1492366.7500 - mean_absolute_error: 900.0703 - val_loss: 1471584.8750 - val_mean_squared_error: 1471584.8750 - val_mean_absolute_error: 1002.8036\n",
      "Epoch 228/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 919974.8750 - mean_squared_error: 919974.8750 - mean_absolute_error: 743.9556\n",
      "Epoch 00228: val_loss improved from 1471584.87500 to 1466799.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1487772.9890 - mean_squared_error: 1487773.0000 - mean_absolute_error: 897.9037 - val_loss: 1466799.3750 - val_mean_squared_error: 1466799.3750 - val_mean_absolute_error: 1001.3137\n",
      "Epoch 229/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1636284.5000 - mean_squared_error: 1636284.5000 - mean_absolute_error: 931.4113\n",
      "Epoch 00229: val_loss improved from 1466799.37500 to 1461985.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1483524.6011 - mean_squared_error: 1483524.6250 - mean_absolute_error: 895.5929 - val_loss: 1461985.5000 - val_mean_squared_error: 1461985.5000 - val_mean_absolute_error: 999.8108\n",
      "Epoch 230/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1662043.0000 - mean_squared_error: 1662043.0000 - mean_absolute_error: 928.8829\n",
      "Epoch 00230: val_loss improved from 1461985.50000 to 1457141.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1479174.3051 - mean_squared_error: 1479174.3750 - mean_absolute_error: 893.3901 - val_loss: 1457141.6250 - val_mean_squared_error: 1457141.6250 - val_mean_absolute_error: 998.2970\n",
      "Epoch 231/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1691007.3750 - mean_squared_error: 1691007.3750 - mean_absolute_error: 907.2289\n",
      "Epoch 00231: val_loss improved from 1457141.62500 to 1452190.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1474759.3456 - mean_squared_error: 1474759.2500 - mean_absolute_error: 891.1666 - val_loss: 1452190.5000 - val_mean_squared_error: 1452190.5000 - val_mean_absolute_error: 996.7458\n",
      "Epoch 232/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1758483.2500 - mean_squared_error: 1758483.2500 - mean_absolute_error: 940.3012\n",
      "Epoch 00232: val_loss improved from 1452190.50000 to 1447088.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1470290.3235 - mean_squared_error: 1470290.2500 - mean_absolute_error: 888.8718 - val_loss: 1447088.0000 - val_mean_squared_error: 1447088.0000 - val_mean_absolute_error: 995.1409\n",
      "Epoch 233/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1315765.5000 - mean_squared_error: 1315765.5000 - mean_absolute_error: 802.9575\n",
      "Epoch 00233: val_loss improved from 1447088.00000 to 1441951.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1465593.0074 - mean_squared_error: 1465593.0000 - mean_absolute_error: 886.5776 - val_loss: 1441951.0000 - val_mean_squared_error: 1441951.0000 - val_mean_absolute_error: 993.5187\n",
      "Epoch 234/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1523052.0000 - mean_squared_error: 1523052.0000 - mean_absolute_error: 859.4849\n",
      "Epoch 00234: val_loss improved from 1441951.00000 to 1436799.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1461035.1838 - mean_squared_error: 1461035.1250 - mean_absolute_error: 884.3819 - val_loss: 1436799.1250 - val_mean_squared_error: 1436799.1250 - val_mean_absolute_error: 991.8884\n",
      "Epoch 235/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1426957.1250 - mean_squared_error: 1426957.1250 - mean_absolute_error: 903.6973\n",
      "Epoch 00235: val_loss improved from 1436799.12500 to 1431546.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1456393.6324 - mean_squared_error: 1456393.6250 - mean_absolute_error: 882.0748 - val_loss: 1431546.5000 - val_mean_squared_error: 1431546.5000 - val_mean_absolute_error: 990.2170\n",
      "Epoch 236/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2181815.5000 - mean_squared_error: 2181815.5000 - mean_absolute_error: 1056.6494\n",
      "Epoch 00236: val_loss improved from 1431546.50000 to 1426152.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1451714.9559 - mean_squared_error: 1451715.0000 - mean_absolute_error: 879.5815 - val_loss: 1426152.6250 - val_mean_squared_error: 1426152.6250 - val_mean_absolute_error: 988.4913\n",
      "Epoch 237/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 2157644.2500 - mean_squared_error: 2157644.2500 - mean_absolute_error: 1075.0662\n",
      "Epoch 00237: val_loss improved from 1426152.62500 to 1420862.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1446931.6149 - mean_squared_error: 1446931.6250 - mean_absolute_error: 877.1726 - val_loss: 1420862.8750 - val_mean_squared_error: 1420862.8750 - val_mean_absolute_error: 986.7972\n",
      "Epoch 238/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1569699.1250 - mean_squared_error: 1569699.1250 - mean_absolute_error: 876.0356\n",
      "Epoch 00238: val_loss improved from 1420862.87500 to 1415793.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1442074.0956 - mean_squared_error: 1442074.1250 - mean_absolute_error: 874.8297 - val_loss: 1415793.0000 - val_mean_squared_error: 1415793.0000 - val_mean_absolute_error: 985.1707\n",
      "Epoch 239/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1180514.1250 - mean_squared_error: 1180514.1250 - mean_absolute_error: 763.3557\n",
      "Epoch 00239: val_loss improved from 1415793.00000 to 1410775.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 1437423.6029 - mean_squared_error: 1437423.6250 - mean_absolute_error: 872.4572 - val_loss: 1410775.5000 - val_mean_squared_error: 1410775.5000 - val_mean_absolute_error: 983.5534\n",
      "Epoch 240/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1349349.1250 - mean_squared_error: 1349349.1250 - mean_absolute_error: 764.4210\n",
      "Epoch 00240: val_loss improved from 1410775.50000 to 1405650.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1432848.0882 - mean_squared_error: 1432848.1250 - mean_absolute_error: 870.1382 - val_loss: 1405650.7500 - val_mean_squared_error: 1405650.7500 - val_mean_absolute_error: 981.8950\n",
      "Epoch 241/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1541157.7500 - mean_squared_error: 1541157.7500 - mean_absolute_error: 921.2161\n",
      "Epoch 00241: val_loss improved from 1405650.75000 to 1400354.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1428463.9522 - mean_squared_error: 1428464.0000 - mean_absolute_error: 867.9663 - val_loss: 1400354.7500 - val_mean_squared_error: 1400354.7500 - val_mean_absolute_error: 980.1766\n",
      "Epoch 242/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1547412.0000 - mean_squared_error: 1547412.0000 - mean_absolute_error: 867.0485\n",
      "Epoch 00242: val_loss improved from 1400354.75000 to 1395273.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1423680.2298 - mean_squared_error: 1423680.2500 - mean_absolute_error: 865.5410 - val_loss: 1395273.5000 - val_mean_squared_error: 1395273.5000 - val_mean_absolute_error: 978.5242\n",
      "Epoch 243/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1475263.0000 - mean_squared_error: 1475263.0000 - mean_absolute_error: 940.3104\n",
      "Epoch 00243: val_loss improved from 1395273.50000 to 1390283.12500, saving model to ./model_r_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 308us/sample - loss: 1419190.5588 - mean_squared_error: 1419190.5000 - mean_absolute_error: 863.3171 - val_loss: 1390283.1250 - val_mean_squared_error: 1390283.1250 - val_mean_absolute_error: 976.8948\n",
      "Epoch 244/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1566929.2500 - mean_squared_error: 1566929.2500 - mean_absolute_error: 952.0363\n",
      "Epoch 00244: val_loss improved from 1390283.12500 to 1385298.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1414705.1949 - mean_squared_error: 1414705.1250 - mean_absolute_error: 861.1053 - val_loss: 1385298.8750 - val_mean_squared_error: 1385298.8750 - val_mean_absolute_error: 975.2595\n",
      "Epoch 245/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1885535.7500 - mean_squared_error: 1885535.7500 - mean_absolute_error: 1012.3809\n",
      "Epoch 00245: val_loss improved from 1385298.87500 to 1380306.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1410245.1765 - mean_squared_error: 1410245.1250 - mean_absolute_error: 858.8745 - val_loss: 1380306.2500 - val_mean_squared_error: 1380306.2500 - val_mean_absolute_error: 973.6125\n",
      "Epoch 246/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1336910.5000 - mean_squared_error: 1336910.5000 - mean_absolute_error: 820.6599\n",
      "Epoch 00246: val_loss improved from 1380306.25000 to 1375319.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1405627.0726 - mean_squared_error: 1405627.0000 - mean_absolute_error: 856.4504 - val_loss: 1375319.5000 - val_mean_squared_error: 1375319.5000 - val_mean_absolute_error: 971.9598\n",
      "Epoch 247/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 786707.5000 - mean_squared_error: 786707.5000 - mean_absolute_error: 667.3656\n",
      "Epoch 00247: val_loss improved from 1375319.50000 to 1370380.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1401084.0864 - mean_squared_error: 1401084.1250 - mean_absolute_error: 854.3516 - val_loss: 1370380.2500 - val_mean_squared_error: 1370380.2500 - val_mean_absolute_error: 970.3215\n",
      "Epoch 248/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1388796.0000 - mean_squared_error: 1388796.0000 - mean_absolute_error: 808.0840\n",
      "Epoch 00248: val_loss improved from 1370380.25000 to 1365351.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1396765.9559 - mean_squared_error: 1396766.0000 - mean_absolute_error: 852.0521 - val_loss: 1365351.7500 - val_mean_squared_error: 1365351.7500 - val_mean_absolute_error: 968.6506\n",
      "Epoch 249/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1467748.2500 - mean_squared_error: 1467748.2500 - mean_absolute_error: 831.0686\n",
      "Epoch 00249: val_loss improved from 1365351.75000 to 1360374.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1392302.9067 - mean_squared_error: 1392303.0000 - mean_absolute_error: 849.8623 - val_loss: 1360374.5000 - val_mean_squared_error: 1360374.5000 - val_mean_absolute_error: 966.9893\n",
      "Epoch 250/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1911075.5000 - mean_squared_error: 1911075.5000 - mean_absolute_error: 946.7030\n",
      "Epoch 00250: val_loss improved from 1360374.50000 to 1355532.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1387866.2243 - mean_squared_error: 1387866.2500 - mean_absolute_error: 847.5170 - val_loss: 1355532.3750 - val_mean_squared_error: 1355532.3750 - val_mean_absolute_error: 965.3682\n",
      "Epoch 251/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 843863.1250 - mean_squared_error: 843863.1250 - mean_absolute_error: 716.6052\n",
      "Epoch 00251: val_loss improved from 1355532.37500 to 1350632.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1383503.5193 - mean_squared_error: 1383503.5000 - mean_absolute_error: 845.3159 - val_loss: 1350632.2500 - val_mean_squared_error: 1350632.2500 - val_mean_absolute_error: 963.7266\n",
      "Epoch 252/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1049807.5000 - mean_squared_error: 1049807.5000 - mean_absolute_error: 855.5327\n",
      "Epoch 00252: val_loss improved from 1350632.25000 to 1345727.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1379176.9559 - mean_squared_error: 1379177.0000 - mean_absolute_error: 843.1248 - val_loss: 1345727.5000 - val_mean_squared_error: 1345727.5000 - val_mean_absolute_error: 962.0766\n",
      "Epoch 253/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1547393.5000 - mean_squared_error: 1547393.5000 - mean_absolute_error: 929.4088\n",
      "Epoch 00253: val_loss improved from 1345727.50000 to 1340714.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1374841.5156 - mean_squared_error: 1374841.3750 - mean_absolute_error: 840.7900 - val_loss: 1340714.6250 - val_mean_squared_error: 1340714.6250 - val_mean_absolute_error: 960.3817\n",
      "Epoch 254/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1827457.7500 - mean_squared_error: 1827457.7500 - mean_absolute_error: 1024.6299\n",
      "Epoch 00254: val_loss improved from 1340714.62500 to 1335774.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1370412.2776 - mean_squared_error: 1370412.2500 - mean_absolute_error: 838.4793 - val_loss: 1335774.5000 - val_mean_squared_error: 1335774.5000 - val_mean_absolute_error: 958.7061\n",
      "Epoch 255/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1577375.0000 - mean_squared_error: 1577375.0000 - mean_absolute_error: 893.2179\n",
      "Epoch 00255: val_loss improved from 1335774.50000 to 1330819.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1365868.8456 - mean_squared_error: 1365868.8750 - mean_absolute_error: 836.1863 - val_loss: 1330819.2500 - val_mean_squared_error: 1330819.2500 - val_mean_absolute_error: 957.0201\n",
      "Epoch 256/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1498937.8750 - mean_squared_error: 1498937.8750 - mean_absolute_error: 883.8112\n",
      "Epoch 00256: val_loss improved from 1330819.25000 to 1325841.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1361512.5122 - mean_squared_error: 1361512.5000 - mean_absolute_error: 833.8817 - val_loss: 1325841.8750 - val_mean_squared_error: 1325841.8750 - val_mean_absolute_error: 955.3224\n",
      "Epoch 257/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1674589.8750 - mean_squared_error: 1674589.8750 - mean_absolute_error: 880.4152\n",
      "Epoch 00257: val_loss improved from 1325841.87500 to 1320940.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1356977.8235 - mean_squared_error: 1356977.7500 - mean_absolute_error: 831.5540 - val_loss: 1320940.8750 - val_mean_squared_error: 1320940.8750 - val_mean_absolute_error: 953.6412\n",
      "Epoch 258/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1667429.2500 - mean_squared_error: 1667429.2500 - mean_absolute_error: 937.4706\n",
      "Epoch 00258: val_loss improved from 1320940.87500 to 1315652.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1352633.0882 - mean_squared_error: 1352633.0000 - mean_absolute_error: 829.3860 - val_loss: 1315652.7500 - val_mean_squared_error: 1315652.7500 - val_mean_absolute_error: 951.8163\n",
      "Epoch 259/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1167683.3750 - mean_squared_error: 1167683.3750 - mean_absolute_error: 751.9285\n",
      "Epoch 00259: val_loss improved from 1315652.75000 to 1310110.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1347706.8456 - mean_squared_error: 1347707.0000 - mean_absolute_error: 826.8466 - val_loss: 1310110.5000 - val_mean_squared_error: 1310110.5000 - val_mean_absolute_error: 949.8967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1217428.2500 - mean_squared_error: 1217428.2500 - mean_absolute_error: 831.0781\n",
      "Epoch 00260: val_loss improved from 1310110.50000 to 1304519.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1342897.4926 - mean_squared_error: 1342897.5000 - mean_absolute_error: 824.3565 - val_loss: 1304519.5000 - val_mean_squared_error: 1304519.5000 - val_mean_absolute_error: 947.9519\n",
      "Epoch 261/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 910325.2500 - mean_squared_error: 910325.2500 - mean_absolute_error: 767.5343\n",
      "Epoch 00261: val_loss improved from 1304519.50000 to 1298924.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1337863.6618 - mean_squared_error: 1337863.6250 - mean_absolute_error: 821.8218 - val_loss: 1298924.2500 - val_mean_squared_error: 1298924.2500 - val_mean_absolute_error: 945.9944\n",
      "Epoch 262/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1376676.0000 - mean_squared_error: 1376676.0000 - mean_absolute_error: 792.7906\n",
      "Epoch 00262: val_loss improved from 1298924.25000 to 1293377.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1332907.9338 - mean_squared_error: 1332907.8750 - mean_absolute_error: 819.2338 - val_loss: 1293377.3750 - val_mean_squared_error: 1293377.3750 - val_mean_absolute_error: 944.0458\n",
      "Epoch 263/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1736849.0000 - mean_squared_error: 1736849.0000 - mean_absolute_error: 946.6707\n",
      "Epoch 00263: val_loss improved from 1293377.37500 to 1287953.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1328072.5772 - mean_squared_error: 1328072.5000 - mean_absolute_error: 816.6399 - val_loss: 1287953.7500 - val_mean_squared_error: 1287953.7500 - val_mean_absolute_error: 942.1352\n",
      "Epoch 264/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1039241.0000 - mean_squared_error: 1039241.0000 - mean_absolute_error: 718.0228\n",
      "Epoch 00264: val_loss improved from 1287953.75000 to 1282504.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1323127.7059 - mean_squared_error: 1323127.6250 - mean_absolute_error: 814.2220 - val_loss: 1282504.5000 - val_mean_squared_error: 1282504.5000 - val_mean_absolute_error: 940.2097\n",
      "Epoch 265/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 856738.5625 - mean_squared_error: 856738.5625 - mean_absolute_error: 747.2832\n",
      "Epoch 00265: val_loss improved from 1282504.50000 to 1276896.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1318300.5882 - mean_squared_error: 1318300.6250 - mean_absolute_error: 811.7697 - val_loss: 1276896.3750 - val_mean_squared_error: 1276896.3750 - val_mean_absolute_error: 938.2165\n",
      "Epoch 266/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1751140.2500 - mean_squared_error: 1751140.2500 - mean_absolute_error: 964.4183\n",
      "Epoch 00266: val_loss improved from 1276896.37500 to 1271057.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1313427.2243 - mean_squared_error: 1313427.1250 - mean_absolute_error: 808.9981 - val_loss: 1271057.2500 - val_mean_squared_error: 1271057.2500 - val_mean_absolute_error: 936.1276\n",
      "Epoch 267/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 688002.1875 - mean_squared_error: 688002.1875 - mean_absolute_error: 658.0484\n",
      "Epoch 00267: val_loss improved from 1271057.25000 to 1265346.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1308029.8824 - mean_squared_error: 1308029.8750 - mean_absolute_error: 806.3825 - val_loss: 1265346.7500 - val_mean_squared_error: 1265346.7500 - val_mean_absolute_error: 934.0798\n",
      "Epoch 268/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1047009.3750 - mean_squared_error: 1047009.3750 - mean_absolute_error: 792.6937\n",
      "Epoch 00268: val_loss improved from 1265346.75000 to 1259645.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1303095.8640 - mean_squared_error: 1303095.7500 - mean_absolute_error: 803.6703 - val_loss: 1259645.8750 - val_mean_squared_error: 1259645.8750 - val_mean_absolute_error: 932.0239\n",
      "Epoch 269/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1345114.5000 - mean_squared_error: 1345114.5000 - mean_absolute_error: 729.4718\n",
      "Epoch 00269: val_loss improved from 1259645.87500 to 1254002.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1298022.2243 - mean_squared_error: 1298022.2500 - mean_absolute_error: 800.9428 - val_loss: 1254002.2500 - val_mean_squared_error: 1254002.2500 - val_mean_absolute_error: 929.9827\n",
      "Epoch 270/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1465704.5000 - mean_squared_error: 1465704.5000 - mean_absolute_error: 809.5115\n",
      "Epoch 00270: val_loss improved from 1254002.25000 to 1248452.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1293091.7500 - mean_squared_error: 1293091.7500 - mean_absolute_error: 798.4866 - val_loss: 1248452.7500 - val_mean_squared_error: 1248452.7500 - val_mean_absolute_error: 927.9669\n",
      "Epoch 271/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1274260.7500 - mean_squared_error: 1274260.7500 - mean_absolute_error: 802.6946\n",
      "Epoch 00271: val_loss improved from 1248452.75000 to 1242929.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 499us/sample - loss: 1288169.5000 - mean_squared_error: 1288169.5000 - mean_absolute_error: 795.8840 - val_loss: 1242929.7500 - val_mean_squared_error: 1242929.7500 - val_mean_absolute_error: 925.9479\n",
      "Epoch 272/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1340868.7500 - mean_squared_error: 1340868.7500 - mean_absolute_error: 797.8857\n",
      "Epoch 00272: val_loss improved from 1242929.75000 to 1237271.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1283268.8676 - mean_squared_error: 1283268.8750 - mean_absolute_error: 793.3983 - val_loss: 1237271.7500 - val_mean_squared_error: 1237271.7500 - val_mean_absolute_error: 923.8718\n",
      "Epoch 273/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 578234.3750 - mean_squared_error: 578234.3750 - mean_absolute_error: 576.4982\n",
      "Epoch 00273: val_loss improved from 1237271.75000 to 1231350.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1277939.6471 - mean_squared_error: 1277939.6250 - mean_absolute_error: 790.8628 - val_loss: 1231350.5000 - val_mean_squared_error: 1231350.5000 - val_mean_absolute_error: 921.6886\n",
      "Epoch 274/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1147334.8750 - mean_squared_error: 1147334.8750 - mean_absolute_error: 737.2491\n",
      "Epoch 00274: val_loss improved from 1231350.50000 to 1225157.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 1272928.4329 - mean_squared_error: 1272928.5000 - mean_absolute_error: 788.0856 - val_loss: 1225157.5000 - val_mean_squared_error: 1225157.5000 - val_mean_absolute_error: 919.3909\n",
      "Epoch 275/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1010127.1875 - mean_squared_error: 1010127.1875 - mean_absolute_error: 791.3153\n",
      "Epoch 00275: val_loss improved from 1225157.50000 to 1219394.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 1267664.4485 - mean_squared_error: 1267664.5000 - mean_absolute_error: 785.4811 - val_loss: 1219394.5000 - val_mean_squared_error: 1219394.5000 - val_mean_absolute_error: 917.2455\n",
      "Epoch 276/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 914830.5000 - mean_squared_error: 914830.5000 - mean_absolute_error: 738.9446\n",
      "Epoch 00276: val_loss improved from 1219394.50000 to 1213829.37500, saving model to ./model_r_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 367us/sample - loss: 1262545.1029 - mean_squared_error: 1262545.0000 - mean_absolute_error: 783.0178 - val_loss: 1213829.3750 - val_mean_squared_error: 1213829.3750 - val_mean_absolute_error: 915.1656\n",
      "Epoch 277/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1330052.7500 - mean_squared_error: 1330052.7500 - mean_absolute_error: 800.6702\n",
      "Epoch 00277: val_loss improved from 1213829.37500 to 1208181.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1257663.6857 - mean_squared_error: 1257663.6250 - mean_absolute_error: 780.2900 - val_loss: 1208181.5000 - val_mean_squared_error: 1208181.5000 - val_mean_absolute_error: 913.0431\n",
      "Epoch 278/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1041164.0000 - mean_squared_error: 1041164.0000 - mean_absolute_error: 731.9799\n",
      "Epoch 00278: val_loss improved from 1208181.50000 to 1202728.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1252694.9853 - mean_squared_error: 1252695.0000 - mean_absolute_error: 777.9750 - val_loss: 1202728.8750 - val_mean_squared_error: 1202728.8750 - val_mean_absolute_error: 910.9836\n",
      "Epoch 279/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1742322.6250 - mean_squared_error: 1742322.6250 - mean_absolute_error: 1000.9137\n",
      "Epoch 00279: val_loss improved from 1202728.87500 to 1197414.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1248218.6749 - mean_squared_error: 1248218.7500 - mean_absolute_error: 775.5730 - val_loss: 1197414.2500 - val_mean_squared_error: 1197414.2500 - val_mean_absolute_error: 909.1624\n",
      "Epoch 280/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 912236.6250 - mean_squared_error: 912236.6250 - mean_absolute_error: 699.6474\n",
      "Epoch 00280: val_loss improved from 1197414.25000 to 1192309.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1243247.9706 - mean_squared_error: 1243248.0000 - mean_absolute_error: 773.2350 - val_loss: 1192309.3750 - val_mean_squared_error: 1192309.3750 - val_mean_absolute_error: 907.6601\n",
      "Epoch 281/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1032714.6250 - mean_squared_error: 1032714.6250 - mean_absolute_error: 686.4190\n",
      "Epoch 00281: val_loss improved from 1192309.37500 to 1186857.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1238644.6618 - mean_squared_error: 1238644.7500 - mean_absolute_error: 770.9695 - val_loss: 1186857.3750 - val_mean_squared_error: 1186857.3750 - val_mean_absolute_error: 906.0434\n",
      "Epoch 282/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1011387.6875 - mean_squared_error: 1011387.6875 - mean_absolute_error: 733.0498\n",
      "Epoch 00282: val_loss improved from 1186857.37500 to 1181407.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1233952.0074 - mean_squared_error: 1233952.0000 - mean_absolute_error: 768.7719 - val_loss: 1181407.7500 - val_mean_squared_error: 1181407.7500 - val_mean_absolute_error: 904.4197\n",
      "Epoch 283/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 701536.3750 - mean_squared_error: 701536.3750 - mean_absolute_error: 639.1852\n",
      "Epoch 00283: val_loss improved from 1181407.75000 to 1176029.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1229052.5441 - mean_squared_error: 1229052.6250 - mean_absolute_error: 766.5530 - val_loss: 1176029.6250 - val_mean_squared_error: 1176029.6250 - val_mean_absolute_error: 902.8057\n",
      "Epoch 284/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1038079.2500 - mean_squared_error: 1038079.2500 - mean_absolute_error: 708.9753\n",
      "Epoch 00284: val_loss improved from 1176029.62500 to 1170501.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1224501.8015 - mean_squared_error: 1224501.7500 - mean_absolute_error: 764.2948 - val_loss: 1170501.3750 - val_mean_squared_error: 1170501.3750 - val_mean_absolute_error: 901.1365\n",
      "Epoch 285/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1202910.8750 - mean_squared_error: 1202910.8750 - mean_absolute_error: 767.0355\n",
      "Epoch 00285: val_loss improved from 1170501.37500 to 1165213.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1219695.1029 - mean_squared_error: 1219695.0000 - mean_absolute_error: 761.9308 - val_loss: 1165213.6250 - val_mean_squared_error: 1165213.6250 - val_mean_absolute_error: 899.5386\n",
      "Epoch 286/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1476238.1250 - mean_squared_error: 1476238.1250 - mean_absolute_error: 806.2410\n",
      "Epoch 00286: val_loss improved from 1165213.62500 to 1159960.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1215160.2132 - mean_squared_error: 1215160.2500 - mean_absolute_error: 759.7466 - val_loss: 1159960.1250 - val_mean_squared_error: 1159960.1250 - val_mean_absolute_error: 897.9427\n",
      "Epoch 287/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1231591.2500 - mean_squared_error: 1231591.2500 - mean_absolute_error: 830.3540\n",
      "Epoch 00287: val_loss improved from 1159960.12500 to 1154783.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1210564.6783 - mean_squared_error: 1210564.7500 - mean_absolute_error: 757.4663 - val_loss: 1154783.5000 - val_mean_squared_error: 1154783.5000 - val_mean_absolute_error: 896.3594\n",
      "Epoch 288/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 581098.6250 - mean_squared_error: 581098.6250 - mean_absolute_error: 568.7205\n",
      "Epoch 00288: val_loss improved from 1154783.50000 to 1149737.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1205817.7941 - mean_squared_error: 1205817.7500 - mean_absolute_error: 755.1343 - val_loss: 1149737.1250 - val_mean_squared_error: 1149737.1250 - val_mean_absolute_error: 894.8129\n",
      "Epoch 289/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 932280.5000 - mean_squared_error: 932280.5000 - mean_absolute_error: 630.0288\n",
      "Epoch 00289: val_loss improved from 1149737.12500 to 1144701.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1201535.8419 - mean_squared_error: 1201535.7500 - mean_absolute_error: 753.0478 - val_loss: 1144701.5000 - val_mean_squared_error: 1144701.5000 - val_mean_absolute_error: 893.2593\n",
      "Epoch 290/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1092795.7500 - mean_squared_error: 1092795.7500 - mean_absolute_error: 720.2637\n",
      "Epoch 00290: val_loss improved from 1144701.50000 to 1139792.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1197219.2132 - mean_squared_error: 1197219.1250 - mean_absolute_error: 750.8466 - val_loss: 1139792.8750 - val_mean_squared_error: 1139792.8750 - val_mean_absolute_error: 891.7365\n",
      "Epoch 291/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1461063.0000 - mean_squared_error: 1461063.0000 - mean_absolute_error: 822.0989\n",
      "Epoch 00291: val_loss improved from 1139792.87500 to 1134860.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1192923.3971 - mean_squared_error: 1192923.3750 - mean_absolute_error: 748.6752 - val_loss: 1134860.3750 - val_mean_squared_error: 1134860.3750 - val_mean_absolute_error: 890.2028\n",
      "Epoch 292/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1347084.5000 - mean_squared_error: 1347084.5000 - mean_absolute_error: 853.7018\n",
      "Epoch 00292: val_loss improved from 1134860.37500 to 1129746.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1188788.2879 - mean_squared_error: 1188788.2500 - mean_absolute_error: 746.5874 - val_loss: 1129746.0000 - val_mean_squared_error: 1129746.0000 - val_mean_absolute_error: 888.6135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1573453.5000 - mean_squared_error: 1573453.5000 - mean_absolute_error: 848.4196\n",
      "Epoch 00293: val_loss improved from 1129746.00000 to 1124929.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1184327.4301 - mean_squared_error: 1184327.5000 - mean_absolute_error: 744.3610 - val_loss: 1124929.8750 - val_mean_squared_error: 1124929.8750 - val_mean_absolute_error: 887.1061\n",
      "Epoch 294/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1078275.1250 - mean_squared_error: 1078275.1250 - mean_absolute_error: 780.3729\n",
      "Epoch 00294: val_loss improved from 1124929.87500 to 1120253.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1180176.9472 - mean_squared_error: 1180177.0000 - mean_absolute_error: 742.1687 - val_loss: 1120253.1250 - val_mean_squared_error: 1120253.1250 - val_mean_absolute_error: 885.6321\n",
      "Epoch 295/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1144011.8750 - mean_squared_error: 1144011.8750 - mean_absolute_error: 755.2787\n",
      "Epoch 00295: val_loss improved from 1120253.12500 to 1115721.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1176106.7169 - mean_squared_error: 1176106.8750 - mean_absolute_error: 740.1713 - val_loss: 1115721.0000 - val_mean_squared_error: 1115721.0000 - val_mean_absolute_error: 884.1946\n",
      "Epoch 296/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1392589.3750 - mean_squared_error: 1392589.3750 - mean_absolute_error: 796.7081\n",
      "Epoch 00296: val_loss improved from 1115721.00000 to 1111193.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1172132.8824 - mean_squared_error: 1172132.8750 - mean_absolute_error: 738.1218 - val_loss: 1111193.8750 - val_mean_squared_error: 1111193.8750 - val_mean_absolute_error: 882.7471\n",
      "Epoch 297/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1274559.3750 - mean_squared_error: 1274559.3750 - mean_absolute_error: 757.1572\n",
      "Epoch 00297: val_loss improved from 1111193.87500 to 1106522.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1168168.9669 - mean_squared_error: 1168169.0000 - mean_absolute_error: 736.1477 - val_loss: 1106522.1250 - val_mean_squared_error: 1106522.1250 - val_mean_absolute_error: 881.2509\n",
      "Epoch 298/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1405223.8750 - mean_squared_error: 1405223.8750 - mean_absolute_error: 824.6183\n",
      "Epoch 00298: val_loss improved from 1106522.12500 to 1101816.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1164127.1140 - mean_squared_error: 1164127.0000 - mean_absolute_error: 734.2397 - val_loss: 1101816.8750 - val_mean_squared_error: 1101816.8750 - val_mean_absolute_error: 879.7397\n",
      "Epoch 299/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1495863.0000 - mean_squared_error: 1495863.0000 - mean_absolute_error: 855.5361\n",
      "Epoch 00299: val_loss improved from 1101816.87500 to 1097201.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1160210.5299 - mean_squared_error: 1160210.6250 - mean_absolute_error: 732.5703 - val_loss: 1097201.7500 - val_mean_squared_error: 1097201.7500 - val_mean_absolute_error: 878.2548\n",
      "Epoch 300/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1353058.0000 - mean_squared_error: 1353058.0000 - mean_absolute_error: 805.0576\n",
      "Epoch 00300: val_loss improved from 1097201.75000 to 1092752.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1156149.0735 - mean_squared_error: 1156149.0000 - mean_absolute_error: 730.8571 - val_loss: 1092752.7500 - val_mean_squared_error: 1092752.7500 - val_mean_absolute_error: 876.8127\n",
      "Epoch 301/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 585758.3125 - mean_squared_error: 585758.3125 - mean_absolute_error: 602.8701\n",
      "Epoch 00301: val_loss improved from 1092752.75000 to 1088345.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1152195.0846 - mean_squared_error: 1152195.0000 - mean_absolute_error: 729.2117 - val_loss: 1088345.6250 - val_mean_squared_error: 1088345.6250 - val_mean_absolute_error: 875.3761\n",
      "Epoch 302/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 991513.2500 - mean_squared_error: 991513.2500 - mean_absolute_error: 685.0102\n",
      "Epoch 00302: val_loss improved from 1088345.62500 to 1083957.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1148426.5037 - mean_squared_error: 1148426.5000 - mean_absolute_error: 727.6277 - val_loss: 1083957.6250 - val_mean_squared_error: 1083957.6250 - val_mean_absolute_error: 873.9423\n",
      "Epoch 303/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1303484.7500 - mean_squared_error: 1303484.7500 - mean_absolute_error: 850.3776\n",
      "Epoch 00303: val_loss improved from 1083957.62500 to 1079449.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1144772.7059 - mean_squared_error: 1144772.7500 - mean_absolute_error: 725.9912 - val_loss: 1079449.5000 - val_mean_squared_error: 1079449.5000 - val_mean_absolute_error: 872.4605\n",
      "Epoch 304/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 904661.3750 - mean_squared_error: 904661.3750 - mean_absolute_error: 676.1362\n",
      "Epoch 00304: val_loss improved from 1079449.50000 to 1074825.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1140716.6471 - mean_squared_error: 1140716.6250 - mean_absolute_error: 724.2294 - val_loss: 1074825.1250 - val_mean_squared_error: 1074825.1250 - val_mean_absolute_error: 870.9233\n",
      "Epoch 305/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 977530.3125 - mean_squared_error: 977530.3125 - mean_absolute_error: 712.6129\n",
      "Epoch 00305: val_loss improved from 1074825.12500 to 1070284.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1136863.8713 - mean_squared_error: 1136863.8750 - mean_absolute_error: 722.8145 - val_loss: 1070284.2500 - val_mean_squared_error: 1070284.2500 - val_mean_absolute_error: 869.4029\n",
      "Epoch 306/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1050587.7500 - mean_squared_error: 1050587.7500 - mean_absolute_error: 712.3325\n",
      "Epoch 00306: val_loss improved from 1070284.25000 to 1065998.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1132954.7868 - mean_squared_error: 1132954.8750 - mean_absolute_error: 721.1054 - val_loss: 1065998.2500 - val_mean_squared_error: 1065998.2500 - val_mean_absolute_error: 867.9587\n",
      "Epoch 307/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1550568.0000 - mean_squared_error: 1550568.0000 - mean_absolute_error: 785.3064\n",
      "Epoch 00307: val_loss improved from 1065998.25000 to 1061893.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1129348.8346 - mean_squared_error: 1129348.8750 - mean_absolute_error: 719.7618 - val_loss: 1061893.8750 - val_mean_squared_error: 1061893.8750 - val_mean_absolute_error: 866.5698\n",
      "Epoch 308/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1358755.2500 - mean_squared_error: 1358755.2500 - mean_absolute_error: 805.8203\n",
      "Epoch 00308: val_loss improved from 1061893.87500 to 1057739.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1125868.5515 - mean_squared_error: 1125868.6250 - mean_absolute_error: 718.3998 - val_loss: 1057739.3750 - val_mean_squared_error: 1057739.3750 - val_mean_absolute_error: 865.1618\n",
      "Epoch 309/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1443826.3750 - mean_squared_error: 1443826.3750 - mean_absolute_error: 721.9481\n",
      "Epoch 00309: val_loss improved from 1057739.37500 to 1053610.12500, saving model to ./model_r_weights.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/68 [==============================] - 0s 323us/sample - loss: 1122180.1471 - mean_squared_error: 1122180.1250 - mean_absolute_error: 717.0077 - val_loss: 1053610.1250 - val_mean_squared_error: 1053610.1250 - val_mean_absolute_error: 863.9202\n",
      "Epoch 310/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1006531.3750 - mean_squared_error: 1006531.3750 - mean_absolute_error: 636.8561\n",
      "Epoch 00310: val_loss improved from 1053610.12500 to 1049351.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 1118531.1471 - mean_squared_error: 1118531.1250 - mean_absolute_error: 715.5216 - val_loss: 1049351.1250 - val_mean_squared_error: 1049351.1250 - val_mean_absolute_error: 862.8734\n",
      "Epoch 311/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1268899.8750 - mean_squared_error: 1268899.8750 - mean_absolute_error: 739.8731\n",
      "Epoch 00311: val_loss improved from 1049351.12500 to 1044960.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1114966.8401 - mean_squared_error: 1114966.8750 - mean_absolute_error: 714.2269 - val_loss: 1044960.2500 - val_mean_squared_error: 1044960.2500 - val_mean_absolute_error: 861.7869\n",
      "Epoch 312/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 558258.7500 - mean_squared_error: 558258.7500 - mean_absolute_error: 551.7353\n",
      "Epoch 00312: val_loss improved from 1044960.25000 to 1040584.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1111001.1820 - mean_squared_error: 1111001.2500 - mean_absolute_error: 712.5362 - val_loss: 1040584.4375 - val_mean_squared_error: 1040584.4375 - val_mean_absolute_error: 860.7145\n",
      "Epoch 313/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 899389.2500 - mean_squared_error: 899389.2500 - mean_absolute_error: 638.3298\n",
      "Epoch 00313: val_loss improved from 1040584.43750 to 1036078.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1107339.9522 - mean_squared_error: 1107340.0000 - mean_absolute_error: 711.1593 - val_loss: 1036078.2500 - val_mean_squared_error: 1036078.2500 - val_mean_absolute_error: 859.6188\n",
      "Epoch 314/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1578004.1250 - mean_squared_error: 1578004.1250 - mean_absolute_error: 934.1661\n",
      "Epoch 00314: val_loss improved from 1036078.25000 to 1031653.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1103865.8290 - mean_squared_error: 1103865.8750 - mean_absolute_error: 709.8138 - val_loss: 1031653.1250 - val_mean_squared_error: 1031653.1250 - val_mean_absolute_error: 858.5332\n",
      "Epoch 315/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1201361.3750 - mean_squared_error: 1201361.3750 - mean_absolute_error: 816.3125\n",
      "Epoch 00315: val_loss improved from 1031653.12500 to 1027641.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1100026.0211 - mean_squared_error: 1100026.1250 - mean_absolute_error: 708.3040 - val_loss: 1027641.6875 - val_mean_squared_error: 1027641.6875 - val_mean_absolute_error: 857.5335\n",
      "Epoch 316/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1316105.7500 - mean_squared_error: 1316105.7500 - mean_absolute_error: 741.5663\n",
      "Epoch 00316: val_loss improved from 1027641.68750 to 1023765.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1096479.1305 - mean_squared_error: 1096479.1250 - mean_absolute_error: 706.7430 - val_loss: 1023765.4375 - val_mean_squared_error: 1023765.4375 - val_mean_absolute_error: 856.5633\n",
      "Epoch 317/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1417008.3750 - mean_squared_error: 1417008.3750 - mean_absolute_error: 805.3879\n",
      "Epoch 00317: val_loss improved from 1023765.43750 to 1019672.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 1093233.1489 - mean_squared_error: 1093233.1250 - mean_absolute_error: 705.4941 - val_loss: 1019672.4375 - val_mean_squared_error: 1019672.4375 - val_mean_absolute_error: 855.5466\n",
      "Epoch 318/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 787195.3125 - mean_squared_error: 787195.3125 - mean_absolute_error: 665.0506\n",
      "Epoch 00318: val_loss improved from 1019672.43750 to 1015525.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1089560.7059 - mean_squared_error: 1089560.7500 - mean_absolute_error: 703.9603 - val_loss: 1015525.7500 - val_mean_squared_error: 1015525.7500 - val_mean_absolute_error: 854.5021\n",
      "Epoch 319/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1414960.0000 - mean_squared_error: 1414960.0000 - mean_absolute_error: 846.3635\n",
      "Epoch 00319: val_loss improved from 1015525.75000 to 1011213.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1086195.8529 - mean_squared_error: 1086195.7500 - mean_absolute_error: 702.4600 - val_loss: 1011213.7500 - val_mean_squared_error: 1011213.7500 - val_mean_absolute_error: 853.4022\n",
      "Epoch 320/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1023150.2500 - mean_squared_error: 1023150.2500 - mean_absolute_error: 749.6506\n",
      "Epoch 00320: val_loss improved from 1011213.75000 to 1006728.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1082475.7353 - mean_squared_error: 1082475.7500 - mean_absolute_error: 701.0942 - val_loss: 1006728.1250 - val_mean_squared_error: 1006728.1250 - val_mean_absolute_error: 852.2490\n",
      "Epoch 321/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1303366.7500 - mean_squared_error: 1303366.7500 - mean_absolute_error: 746.8628\n",
      "Epoch 00321: val_loss improved from 1006728.12500 to 1002014.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1078614.5515 - mean_squared_error: 1078614.5000 - mean_absolute_error: 699.3848 - val_loss: 1002014.0000 - val_mean_squared_error: 1002014.0000 - val_mean_absolute_error: 851.0226\n",
      "Epoch 322/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1509544.2500 - mean_squared_error: 1509544.2500 - mean_absolute_error: 802.8534\n",
      "Epoch 00322: val_loss improved from 1002014.00000 to 997412.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1074790.0588 - mean_squared_error: 1074790.1250 - mean_absolute_error: 697.9136 - val_loss: 997412.5625 - val_mean_squared_error: 997412.5625 - val_mean_absolute_error: 849.8257\n",
      "Epoch 323/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 998982.7500 - mean_squared_error: 998982.7500 - mean_absolute_error: 667.9183\n",
      "Epoch 00323: val_loss improved from 997412.56250 to 993055.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 1070614.7206 - mean_squared_error: 1070614.7500 - mean_absolute_error: 695.9836 - val_loss: 993055.6875 - val_mean_squared_error: 993055.6875 - val_mean_absolute_error: 848.6783\n",
      "Epoch 324/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1010635.6250 - mean_squared_error: 1010635.6250 - mean_absolute_error: 688.9796\n",
      "Epoch 00324: val_loss improved from 993055.68750 to 988495.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1067045.1471 - mean_squared_error: 1067045.0000 - mean_absolute_error: 694.5509 - val_loss: 988495.3125 - val_mean_squared_error: 988495.3125 - val_mean_absolute_error: 847.4692\n",
      "Epoch 325/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1071433.7500 - mean_squared_error: 1071433.7500 - mean_absolute_error: 717.6483\n",
      "Epoch 00325: val_loss improved from 988495.31250 to 984078.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1063166.8199 - mean_squared_error: 1063166.8750 - mean_absolute_error: 692.8957 - val_loss: 984078.8750 - val_mean_squared_error: 984078.8750 - val_mean_absolute_error: 846.2888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 326/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 946056.6875 - mean_squared_error: 946056.6875 - mean_absolute_error: 679.5649\n",
      "Epoch 00326: val_loss improved from 984078.87500 to 979596.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1059333.8897 - mean_squared_error: 1059333.8750 - mean_absolute_error: 691.3171 - val_loss: 979596.0000 - val_mean_squared_error: 979596.0000 - val_mean_absolute_error: 845.0885\n",
      "Epoch 327/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1160891.8750 - mean_squared_error: 1160891.8750 - mean_absolute_error: 662.2410\n",
      "Epoch 00327: val_loss improved from 979596.00000 to 974971.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1055567.1949 - mean_squared_error: 1055567.2500 - mean_absolute_error: 689.7204 - val_loss: 974971.2500 - val_mean_squared_error: 974971.2500 - val_mean_absolute_error: 843.8610\n",
      "Epoch 328/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 618792.1250 - mean_squared_error: 618792.1250 - mean_absolute_error: 585.6969\n",
      "Epoch 00328: val_loss improved from 974971.25000 to 970484.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1051706.8897 - mean_squared_error: 1051707.0000 - mean_absolute_error: 688.3513 - val_loss: 970484.5625 - val_mean_squared_error: 970484.5625 - val_mean_absolute_error: 842.6705\n",
      "Epoch 329/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1081474.7500 - mean_squared_error: 1081474.7500 - mean_absolute_error: 744.7593\n",
      "Epoch 00329: val_loss improved from 970484.56250 to 966130.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1048034.3382 - mean_squared_error: 1048034.3750 - mean_absolute_error: 687.1661 - val_loss: 966130.6875 - val_mean_squared_error: 966130.6875 - val_mean_absolute_error: 841.4988\n",
      "Epoch 330/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 896196.8750 - mean_squared_error: 896196.8750 - mean_absolute_error: 616.6363\n",
      "Epoch 00330: val_loss improved from 966130.68750 to 961675.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1044216.3309 - mean_squared_error: 1044216.3750 - mean_absolute_error: 685.7546 - val_loss: 961675.7500 - val_mean_squared_error: 961675.7500 - val_mean_absolute_error: 840.2776\n",
      "Epoch 331/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 909462.2500 - mean_squared_error: 909462.2500 - mean_absolute_error: 670.7936\n",
      "Epoch 00331: val_loss improved from 961675.75000 to 957089.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1040522.0956 - mean_squared_error: 1040522.1250 - mean_absolute_error: 684.4438 - val_loss: 957089.4375 - val_mean_squared_error: 957089.4375 - val_mean_absolute_error: 838.9998\n",
      "Epoch 332/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1803686.5000 - mean_squared_error: 1803686.5000 - mean_absolute_error: 941.5361\n",
      "Epoch 00332: val_loss improved from 957089.43750 to 952486.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 1037090.3323 - mean_squared_error: 1037090.3750 - mean_absolute_error: 682.9616 - val_loss: 952486.2500 - val_mean_squared_error: 952486.2500 - val_mean_absolute_error: 837.7063\n",
      "Epoch 333/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 860914.0000 - mean_squared_error: 860914.0000 - mean_absolute_error: 661.2704\n",
      "Epoch 00333: val_loss improved from 952486.25000 to 948283.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1032842.0744 - mean_squared_error: 1032842.1250 - mean_absolute_error: 681.5447 - val_loss: 948283.2500 - val_mean_squared_error: 948283.2500 - val_mean_absolute_error: 836.5204\n",
      "Epoch 334/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1054041.0000 - mean_squared_error: 1054041.0000 - mean_absolute_error: 645.1829\n",
      "Epoch 00334: val_loss improved from 948283.25000 to 944388.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 1029504.8024 - mean_squared_error: 1029504.8125 - mean_absolute_error: 680.5988 - val_loss: 944388.0000 - val_mean_squared_error: 944388.0000 - val_mean_absolute_error: 835.4131\n",
      "Epoch 335/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1078860.5000 - mean_squared_error: 1078860.5000 - mean_absolute_error: 737.6636\n",
      "Epoch 00335: val_loss improved from 944388.00000 to 940707.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 1026218.0147 - mean_squared_error: 1026218.0000 - mean_absolute_error: 679.4564 - val_loss: 940707.7500 - val_mean_squared_error: 940707.7500 - val_mean_absolute_error: 834.3508\n",
      "Epoch 336/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1007811.8750 - mean_squared_error: 1007811.8750 - mean_absolute_error: 629.6989\n",
      "Epoch 00336: val_loss improved from 940707.75000 to 936872.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 1023104.2132 - mean_squared_error: 1023104.2500 - mean_absolute_error: 678.3169 - val_loss: 936872.6875 - val_mean_squared_error: 936872.6875 - val_mean_absolute_error: 833.2352\n",
      "Epoch 337/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1035407.8750 - mean_squared_error: 1035407.8750 - mean_absolute_error: 665.5829\n",
      "Epoch 00337: val_loss improved from 936872.68750 to 933018.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1019821.8309 - mean_squared_error: 1019821.8750 - mean_absolute_error: 677.0345 - val_loss: 933018.4375 - val_mean_squared_error: 933018.4375 - val_mean_absolute_error: 832.1041\n",
      "Epoch 338/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1126736.5000 - mean_squared_error: 1126736.5000 - mean_absolute_error: 745.8277\n",
      "Epoch 00338: val_loss improved from 933018.43750 to 929061.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1016819.7022 - mean_squared_error: 1016819.7500 - mean_absolute_error: 676.1340 - val_loss: 929061.2500 - val_mean_squared_error: 929061.2500 - val_mean_absolute_error: 830.9422\n",
      "Epoch 339/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 886478.7500 - mean_squared_error: 886478.7500 - mean_absolute_error: 664.4197\n",
      "Epoch 00339: val_loss improved from 929061.25000 to 925174.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1013380.8791 - mean_squared_error: 1013380.8125 - mean_absolute_error: 674.8270 - val_loss: 925174.6875 - val_mean_squared_error: 925174.6875 - val_mean_absolute_error: 829.7953\n",
      "Epoch 340/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1503212.5000 - mean_squared_error: 1503212.5000 - mean_absolute_error: 753.5767\n",
      "Epoch 00340: val_loss improved from 925174.68750 to 921435.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 1010305.1264 - mean_squared_error: 1010305.0625 - mean_absolute_error: 673.8969 - val_loss: 921435.0625 - val_mean_squared_error: 921435.0625 - val_mean_absolute_error: 828.6898\n",
      "Epoch 341/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1520865.0000 - mean_squared_error: 1520865.0000 - mean_absolute_error: 793.5855\n",
      "Epoch 00341: val_loss improved from 921435.06250 to 917942.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1007214.6654 - mean_squared_error: 1007214.6875 - mean_absolute_error: 672.9031 - val_loss: 917942.2500 - val_mean_squared_error: 917942.2500 - val_mean_absolute_error: 827.6407\n",
      "Epoch 342/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 985102.5000 - mean_squared_error: 985102.5000 - mean_absolute_error: 740.8805\n",
      "Epoch 00342: val_loss improved from 917942.25000 to 914454.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 1004304.3768 - mean_squared_error: 1004304.3750 - mean_absolute_error: 671.9827 - val_loss: 914454.1250 - val_mean_squared_error: 914454.1250 - val_mean_absolute_error: 826.5840\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 834202.3125 - mean_squared_error: 834202.3125 - mean_absolute_error: 609.9382\n",
      "Epoch 00343: val_loss improved from 914454.12500 to 910662.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 1001089.9412 - mean_squared_error: 1001089.8750 - mean_absolute_error: 670.9495 - val_loss: 910662.8750 - val_mean_squared_error: 910662.8750 - val_mean_absolute_error: 825.4304\n",
      "Epoch 344/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 883937.8125 - mean_squared_error: 883937.8125 - mean_absolute_error: 665.1882\n",
      "Epoch 00344: val_loss improved from 910662.87500 to 906270.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 997954.2941 - mean_squared_error: 997954.2500 - mean_absolute_error: 669.7509 - val_loss: 906270.6875 - val_mean_squared_error: 906270.6875 - val_mean_absolute_error: 824.0853\n",
      "Epoch 345/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1249061.1250 - mean_squared_error: 1249061.1250 - mean_absolute_error: 744.9617\n",
      "Epoch 00345: val_loss improved from 906270.68750 to 902079.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 994495.9284 - mean_squared_error: 994495.8750 - mean_absolute_error: 668.6951 - val_loss: 902079.4375 - val_mean_squared_error: 902079.4375 - val_mean_absolute_error: 822.7947\n",
      "Epoch 346/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 514387.0625 - mean_squared_error: 514387.0625 - mean_absolute_error: 565.4324\n",
      "Epoch 00346: val_loss improved from 902079.43750 to 898234.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 990956.9412 - mean_squared_error: 990956.9375 - mean_absolute_error: 667.6461 - val_loss: 898234.8750 - val_mean_squared_error: 898234.8750 - val_mean_absolute_error: 821.6027\n",
      "Epoch 347/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1017609.2500 - mean_squared_error: 1017609.2500 - mean_absolute_error: 736.3706\n",
      "Epoch 00347: val_loss improved from 898234.87500 to 894392.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 987891.9412 - mean_squared_error: 987892.0000 - mean_absolute_error: 666.5844 - val_loss: 894392.9375 - val_mean_squared_error: 894392.9375 - val_mean_absolute_error: 820.3949\n",
      "Epoch 348/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1291680.5000 - mean_squared_error: 1291680.5000 - mean_absolute_error: 799.8612\n",
      "Epoch 00348: val_loss improved from 894392.93750 to 890470.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 984767.8824 - mean_squared_error: 984767.8750 - mean_absolute_error: 665.6487 - val_loss: 890470.3125 - val_mean_squared_error: 890470.3125 - val_mean_absolute_error: 819.1454\n",
      "Epoch 349/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 604228.2500 - mean_squared_error: 604228.2500 - mean_absolute_error: 560.6754\n",
      "Epoch 00349: val_loss improved from 890470.31250 to 886587.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 981346.6250 - mean_squared_error: 981346.6250 - mean_absolute_error: 664.6765 - val_loss: 886587.8750 - val_mean_squared_error: 886587.8750 - val_mean_absolute_error: 817.9023\n",
      "Epoch 350/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 878665.3750 - mean_squared_error: 878665.3750 - mean_absolute_error: 661.9670\n",
      "Epoch 00350: val_loss improved from 886587.87500 to 882777.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 978296.2794 - mean_squared_error: 978296.3125 - mean_absolute_error: 663.7009 - val_loss: 882777.6250 - val_mean_squared_error: 882777.6250 - val_mean_absolute_error: 816.6857\n",
      "Epoch 351/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1255645.2500 - mean_squared_error: 1255645.2500 - mean_absolute_error: 751.6516\n",
      "Epoch 00351: val_loss improved from 882777.62500 to 879128.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 975194.2647 - mean_squared_error: 975194.2500 - mean_absolute_error: 662.9009 - val_loss: 879128.6250 - val_mean_squared_error: 879128.6250 - val_mean_absolute_error: 815.5048\n",
      "Epoch 352/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 848992.3750 - mean_squared_error: 848992.3750 - mean_absolute_error: 577.1172\n",
      "Epoch 00352: val_loss improved from 879128.62500 to 875519.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 972099.2794 - mean_squared_error: 972099.3125 - mean_absolute_error: 662.0016 - val_loss: 875519.7500 - val_mean_squared_error: 875519.7500 - val_mean_absolute_error: 814.3365\n",
      "Epoch 353/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1208460.3750 - mean_squared_error: 1208460.3750 - mean_absolute_error: 710.0319\n",
      "Epoch 00353: val_loss improved from 875519.75000 to 872094.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 807us/sample - loss: 969365.8051 - mean_squared_error: 969365.8125 - mean_absolute_error: 661.4913 - val_loss: 872094.1250 - val_mean_squared_error: 872094.1250 - val_mean_absolute_error: 813.2192\n",
      "Epoch 354/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 953426.1250 - mean_squared_error: 953426.1250 - mean_absolute_error: 668.1591\n",
      "Epoch 00354: val_loss improved from 872094.12500 to 868902.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 966467.0790 - mean_squared_error: 966467.0625 - mean_absolute_error: 660.6243 - val_loss: 868902.2500 - val_mean_squared_error: 868902.2500 - val_mean_absolute_error: 812.1680\n",
      "Epoch 355/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 845572.3750 - mean_squared_error: 845572.3750 - mean_absolute_error: 675.7872\n",
      "Epoch 00355: val_loss improved from 868902.25000 to 865664.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 963845.4154 - mean_squared_error: 963845.4375 - mean_absolute_error: 660.0009 - val_loss: 865664.1250 - val_mean_squared_error: 865664.1250 - val_mean_absolute_error: 811.0963\n",
      "Epoch 356/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 990972.1875 - mean_squared_error: 990972.1875 - mean_absolute_error: 715.3942\n",
      "Epoch 00356: val_loss improved from 865664.12500 to 862309.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 961286.4779 - mean_squared_error: 961286.5000 - mean_absolute_error: 659.4771 - val_loss: 862309.5000 - val_mean_squared_error: 862309.5000 - val_mean_absolute_error: 809.9744\n",
      "Epoch 357/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1141011.0000 - mean_squared_error: 1141011.0000 - mean_absolute_error: 753.6514\n",
      "Epoch 00357: val_loss improved from 862309.50000 to 859050.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 958612.0515 - mean_squared_error: 958612.0625 - mean_absolute_error: 658.8010 - val_loss: 859050.3125 - val_mean_squared_error: 859050.3125 - val_mean_absolute_error: 808.8668\n",
      "Epoch 358/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1119260.6250 - mean_squared_error: 1119260.6250 - mean_absolute_error: 712.2670\n",
      "Epoch 00358: val_loss improved from 859050.31250 to 855975.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 955927.1365 - mean_squared_error: 955927.1250 - mean_absolute_error: 657.9735 - val_loss: 855975.9375 - val_mean_squared_error: 855975.9375 - val_mean_absolute_error: 807.8030\n",
      "Epoch 359/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 475125.9062 - mean_squared_error: 475125.9062 - mean_absolute_error: 524.2367\n",
      "Epoch 00359: val_loss improved from 855975.93750 to 853034.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 953196.1618 - mean_squared_error: 953196.1250 - mean_absolute_error: 657.2342 - val_loss: 853034.5000 - val_mean_squared_error: 853034.5000 - val_mean_absolute_error: 806.7744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 568066.3750 - mean_squared_error: 568066.3750 - mean_absolute_error: 567.5765\n",
      "Epoch 00360: val_loss improved from 853034.50000 to 849805.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 950859.1544 - mean_squared_error: 950859.1875 - mean_absolute_error: 656.7213 - val_loss: 849805.7500 - val_mean_squared_error: 849805.7500 - val_mean_absolute_error: 805.6414\n",
      "Epoch 361/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1126437.0000 - mean_squared_error: 1126437.0000 - mean_absolute_error: 709.7328\n",
      "Epoch 00361: val_loss improved from 849805.75000 to 846698.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 948322.0074 - mean_squared_error: 948322.0625 - mean_absolute_error: 656.0301 - val_loss: 846698.8125 - val_mean_squared_error: 846698.8125 - val_mean_absolute_error: 804.5369\n",
      "Epoch 362/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1015414.4375 - mean_squared_error: 1015414.4375 - mean_absolute_error: 675.4827\n",
      "Epoch 00362: val_loss improved from 846698.81250 to 843642.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 945857.8824 - mean_squared_error: 945857.8750 - mean_absolute_error: 655.3845 - val_loss: 843642.6250 - val_mean_squared_error: 843642.6250 - val_mean_absolute_error: 803.4472\n",
      "Epoch 363/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 782881.1875 - mean_squared_error: 782881.1875 - mean_absolute_error: 630.7246\n",
      "Epoch 00363: val_loss improved from 843642.62500 to 840695.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 943290.0487 - mean_squared_error: 943290.0625 - mean_absolute_error: 654.6035 - val_loss: 840695.0000 - val_mean_squared_error: 840695.0000 - val_mean_absolute_error: 802.3875\n",
      "Epoch 364/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1198560.1250 - mean_squared_error: 1198560.1250 - mean_absolute_error: 716.8694\n",
      "Epoch 00364: val_loss improved from 840695.00000 to 837851.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 940940.4485 - mean_squared_error: 940940.5000 - mean_absolute_error: 653.9199 - val_loss: 837851.6875 - val_mean_squared_error: 837851.6875 - val_mean_absolute_error: 801.3600\n",
      "Epoch 365/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1200521.3750 - mean_squared_error: 1200521.3750 - mean_absolute_error: 689.9441\n",
      "Epoch 00365: val_loss improved from 837851.68750 to 835131.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 938662.4559 - mean_squared_error: 938662.5000 - mean_absolute_error: 653.4030 - val_loss: 835131.5000 - val_mean_squared_error: 835131.5000 - val_mean_absolute_error: 800.3737\n",
      "Epoch 366/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 759409.8750 - mean_squared_error: 759409.8750 - mean_absolute_error: 681.6219\n",
      "Epoch 00366: val_loss improved from 835131.50000 to 832485.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 936428.9007 - mean_squared_error: 936428.8750 - mean_absolute_error: 652.8298 - val_loss: 832485.6250 - val_mean_squared_error: 832485.6250 - val_mean_absolute_error: 799.4142\n",
      "Epoch 367/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 734868.8750 - mean_squared_error: 734868.8750 - mean_absolute_error: 563.2031\n",
      "Epoch 00367: val_loss improved from 832485.62500 to 829711.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 934158.4706 - mean_squared_error: 934158.5000 - mean_absolute_error: 652.2406 - val_loss: 829711.9375 - val_mean_squared_error: 829711.9375 - val_mean_absolute_error: 798.4095\n",
      "Epoch 368/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 658131.6250 - mean_squared_error: 658131.6250 - mean_absolute_error: 531.3908\n",
      "Epoch 00368: val_loss improved from 829711.93750 to 826628.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 931833.5331 - mean_squared_error: 931833.5000 - mean_absolute_error: 651.7130 - val_loss: 826628.4375 - val_mean_squared_error: 826628.4375 - val_mean_absolute_error: 797.2869\n",
      "Epoch 369/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 956610.8750 - mean_squared_error: 956610.8750 - mean_absolute_error: 646.2148\n",
      "Epoch 00369: val_loss improved from 826628.43750 to 823603.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 929457.2500 - mean_squared_error: 929457.2500 - mean_absolute_error: 651.0818 - val_loss: 823603.4375 - val_mean_squared_error: 823603.4375 - val_mean_absolute_error: 796.1722\n",
      "Epoch 370/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 893039.6250 - mean_squared_error: 893039.6250 - mean_absolute_error: 612.4373\n",
      "Epoch 00370: val_loss improved from 823603.43750 to 820652.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 927031.9412 - mean_squared_error: 927031.8750 - mean_absolute_error: 650.5114 - val_loss: 820652.1875 - val_mean_squared_error: 820652.1875 - val_mean_absolute_error: 795.0726\n",
      "Epoch 371/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1259608.5000 - mean_squared_error: 1259608.5000 - mean_absolute_error: 813.6338\n",
      "Epoch 00371: val_loss improved from 820652.18750 to 817707.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 924788.7206 - mean_squared_error: 924788.6875 - mean_absolute_error: 649.9305 - val_loss: 817707.3125 - val_mean_squared_error: 817707.3125 - val_mean_absolute_error: 793.9633\n",
      "Epoch 372/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1262492.5000 - mean_squared_error: 1262492.5000 - mean_absolute_error: 743.2740\n",
      "Epoch 00372: val_loss improved from 817707.31250 to 814582.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 922373.7978 - mean_squared_error: 922373.8125 - mean_absolute_error: 649.2852 - val_loss: 814582.5000 - val_mean_squared_error: 814582.5000 - val_mean_absolute_error: 792.7700\n",
      "Epoch 373/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 589666.2500 - mean_squared_error: 589666.2500 - mean_absolute_error: 562.9832\n",
      "Epoch 00373: val_loss improved from 814582.50000 to 811448.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 919518.5294 - mean_squared_error: 919518.5625 - mean_absolute_error: 648.4732 - val_loss: 811448.3125 - val_mean_squared_error: 811448.3125 - val_mean_absolute_error: 791.5616\n",
      "Epoch 374/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1081467.1250 - mean_squared_error: 1081467.1250 - mean_absolute_error: 709.9080\n",
      "Epoch 00374: val_loss improved from 811448.31250 to 807865.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 917187.6691 - mean_squared_error: 917187.6250 - mean_absolute_error: 647.9344 - val_loss: 807865.6875 - val_mean_squared_error: 807865.6875 - val_mean_absolute_error: 790.1946\n",
      "Epoch 375/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1568157.5000 - mean_squared_error: 1568157.5000 - mean_absolute_error: 849.5328\n",
      "Epoch 00375: val_loss improved from 807865.68750 to 804348.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 914557.3212 - mean_squared_error: 914557.3750 - mean_absolute_error: 647.1051 - val_loss: 804348.3125 - val_mean_squared_error: 804348.3125 - val_mean_absolute_error: 788.8525\n",
      "Epoch 376/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 831532.8750 - mean_squared_error: 831532.8750 - mean_absolute_error: 670.2637\n",
      "Epoch 00376: val_loss improved from 804348.31250 to 801183.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 911637.8727 - mean_squared_error: 911637.8750 - mean_absolute_error: 646.4431 - val_loss: 801183.7500 - val_mean_squared_error: 801183.7500 - val_mean_absolute_error: 787.6369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 377/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1120122.0000 - mean_squared_error: 1120122.0000 - mean_absolute_error: 690.7422\n",
      "Epoch 00377: val_loss improved from 801183.75000 to 798284.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 909170.1884 - mean_squared_error: 909170.1875 - mean_absolute_error: 645.7450 - val_loss: 798284.3750 - val_mean_squared_error: 798284.3750 - val_mean_absolute_error: 786.5098\n",
      "Epoch 378/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1036548.6250 - mean_squared_error: 1036548.6250 - mean_absolute_error: 655.7417\n",
      "Epoch 00378: val_loss improved from 798284.37500 to 795492.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 906685.8676 - mean_squared_error: 906685.8750 - mean_absolute_error: 645.0046 - val_loss: 795492.7500 - val_mean_squared_error: 795492.7500 - val_mean_absolute_error: 785.4135\n",
      "Epoch 379/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 980644.3750 - mean_squared_error: 980644.3750 - mean_absolute_error: 698.8105\n",
      "Epoch 00379: val_loss improved from 795492.75000 to 792424.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 904536.1618 - mean_squared_error: 904536.1875 - mean_absolute_error: 644.4533 - val_loss: 792424.5000 - val_mean_squared_error: 792424.5000 - val_mean_absolute_error: 784.2048\n",
      "Epoch 380/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 785911.8750 - mean_squared_error: 785911.8750 - mean_absolute_error: 605.2978\n",
      "Epoch 00380: val_loss improved from 792424.50000 to 789168.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 901936.3529 - mean_squared_error: 901936.3750 - mean_absolute_error: 643.7890 - val_loss: 789168.8750 - val_mean_squared_error: 789168.8750 - val_mean_absolute_error: 782.9060\n",
      "Epoch 381/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 640748.0000 - mean_squared_error: 640748.0000 - mean_absolute_error: 560.8588\n",
      "Epoch 00381: val_loss improved from 789168.87500 to 785887.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 899360.4265 - mean_squared_error: 899360.4375 - mean_absolute_error: 643.0912 - val_loss: 785887.5000 - val_mean_squared_error: 785887.5000 - val_mean_absolute_error: 781.5790\n",
      "Epoch 382/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 937278.3750 - mean_squared_error: 937278.3750 - mean_absolute_error: 628.7200\n",
      "Epoch 00382: val_loss improved from 785887.50000 to 782776.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 896835.7206 - mean_squared_error: 896835.6875 - mean_absolute_error: 642.4766 - val_loss: 782776.0000 - val_mean_squared_error: 782776.0000 - val_mean_absolute_error: 780.3036\n",
      "Epoch 383/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 823474.0000 - mean_squared_error: 823474.0000 - mean_absolute_error: 647.6995\n",
      "Epoch 00383: val_loss improved from 782776.00000 to 779702.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 894441.5441 - mean_squared_error: 894441.5000 - mean_absolute_error: 642.0246 - val_loss: 779702.4375 - val_mean_squared_error: 779702.4375 - val_mean_absolute_error: 779.0309\n",
      "Epoch 384/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 662451.6875 - mean_squared_error: 662451.6875 - mean_absolute_error: 572.2871\n",
      "Epoch 00384: val_loss improved from 779702.43750 to 776547.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 891763.7353 - mean_squared_error: 891763.6875 - mean_absolute_error: 641.2061 - val_loss: 776547.7500 - val_mean_squared_error: 776547.7500 - val_mean_absolute_error: 777.7154\n",
      "Epoch 385/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1147445.5000 - mean_squared_error: 1147445.5000 - mean_absolute_error: 768.7451\n",
      "Epoch 00385: val_loss improved from 776547.75000 to 773219.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 889563.8971 - mean_squared_error: 889563.8750 - mean_absolute_error: 640.6896 - val_loss: 773219.1250 - val_mean_squared_error: 773219.1250 - val_mean_absolute_error: 776.3184\n",
      "Epoch 386/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 922689.3750 - mean_squared_error: 922689.3750 - mean_absolute_error: 644.9363\n",
      "Epoch 00386: val_loss improved from 773219.12500 to 769981.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 886768.5515 - mean_squared_error: 886768.5000 - mean_absolute_error: 639.9446 - val_loss: 769981.1875 - val_mean_squared_error: 769981.1875 - val_mean_absolute_error: 774.9454\n",
      "Epoch 387/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 782237.7500 - mean_squared_error: 782237.7500 - mean_absolute_error: 648.6913\n",
      "Epoch 00387: val_loss improved from 769981.18750 to 766929.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 884318.1912 - mean_squared_error: 884318.1875 - mean_absolute_error: 639.4627 - val_loss: 766929.6875 - val_mean_squared_error: 766929.6875 - val_mean_absolute_error: 773.6427\n",
      "Epoch 388/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1078464.0000 - mean_squared_error: 1078464.0000 - mean_absolute_error: 668.8964\n",
      "Epoch 00388: val_loss improved from 766929.68750 to 764009.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 881993.3217 - mean_squared_error: 881993.3125 - mean_absolute_error: 638.8655 - val_loss: 764009.7500 - val_mean_squared_error: 764009.7500 - val_mean_absolute_error: 772.3765\n",
      "Epoch 389/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 581185.4375 - mean_squared_error: 581185.4375 - mean_absolute_error: 526.9048\n",
      "Epoch 00389: val_loss improved from 764009.75000 to 761433.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 879524.5037 - mean_squared_error: 879524.5000 - mean_absolute_error: 638.3588 - val_loss: 761433.2500 - val_mean_squared_error: 761433.2500 - val_mean_absolute_error: 771.2425\n",
      "Epoch 390/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 354073.0000 - mean_squared_error: 354073.0000 - mean_absolute_error: 428.9748\n",
      "Epoch 00390: val_loss improved from 761433.25000 to 758840.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 877405.7206 - mean_squared_error: 877405.6875 - mean_absolute_error: 637.8813 - val_loss: 758840.1875 - val_mean_squared_error: 758840.1875 - val_mean_absolute_error: 770.0933\n",
      "Epoch 391/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 531101.8125 - mean_squared_error: 531101.8125 - mean_absolute_error: 535.2722\n",
      "Epoch 00391: val_loss improved from 758840.18750 to 755864.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 875317.3529 - mean_squared_error: 875317.4375 - mean_absolute_error: 637.3658 - val_loss: 755864.2500 - val_mean_squared_error: 755864.2500 - val_mean_absolute_error: 768.7727\n",
      "Epoch 392/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 795004.6250 - mean_squared_error: 795004.6250 - mean_absolute_error: 644.3270\n",
      "Epoch 00392: val_loss improved from 755864.25000 to 752742.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 873226.1195 - mean_squared_error: 873226.1250 - mean_absolute_error: 636.9524 - val_loss: 752742.1875 - val_mean_squared_error: 752742.1875 - val_mean_absolute_error: 767.3754\n",
      "Epoch 393/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 496230.5625 - mean_squared_error: 496230.5625 - mean_absolute_error: 535.7040\n",
      "Epoch 00393: val_loss improved from 752742.18750 to 749977.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 870636.5441 - mean_squared_error: 870636.5000 - mean_absolute_error: 636.4282 - val_loss: 749977.4375 - val_mean_squared_error: 749977.4375 - val_mean_absolute_error: 766.1201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 394/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 469175.5938 - mean_squared_error: 469175.5938 - mean_absolute_error: 495.3589\n",
      "Epoch 00394: val_loss improved from 749977.43750 to 747291.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 868497.8971 - mean_squared_error: 868497.8750 - mean_absolute_error: 635.8813 - val_loss: 747291.6250 - val_mean_squared_error: 747291.6250 - val_mean_absolute_error: 764.8842\n",
      "Epoch 395/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 932300.4375 - mean_squared_error: 932300.4375 - mean_absolute_error: 617.3643\n",
      "Epoch 00395: val_loss improved from 747291.62500 to 744691.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 866358.9412 - mean_squared_error: 866358.9375 - mean_absolute_error: 635.2031 - val_loss: 744691.7500 - val_mean_squared_error: 744691.7500 - val_mean_absolute_error: 763.6777\n",
      "Epoch 396/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 542698.8750 - mean_squared_error: 542698.8750 - mean_absolute_error: 547.3188\n",
      "Epoch 00396: val_loss improved from 744691.75000 to 741893.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 864194.8529 - mean_squared_error: 864194.8125 - mean_absolute_error: 634.7224 - val_loss: 741893.6875 - val_mean_squared_error: 741893.6875 - val_mean_absolute_error: 762.3806\n",
      "Epoch 397/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 920178.6250 - mean_squared_error: 920178.6250 - mean_absolute_error: 664.2484\n",
      "Epoch 00397: val_loss improved from 741893.68750 to 739008.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 862112.2849 - mean_squared_error: 862112.3125 - mean_absolute_error: 634.4071 - val_loss: 739008.0625 - val_mean_squared_error: 739008.0625 - val_mean_absolute_error: 761.0354\n",
      "Epoch 398/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1207215.8750 - mean_squared_error: 1207215.8750 - mean_absolute_error: 767.4083\n",
      "Epoch 00398: val_loss improved from 739008.06250 to 736385.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 860135.7721 - mean_squared_error: 860135.7500 - mean_absolute_error: 634.0401 - val_loss: 736385.2500 - val_mean_squared_error: 736385.2500 - val_mean_absolute_error: 759.7957\n",
      "Epoch 399/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 855699.5000 - mean_squared_error: 855699.5000 - mean_absolute_error: 660.3332\n",
      "Epoch 00399: val_loss improved from 736385.25000 to 734177.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 858049.0965 - mean_squared_error: 858049.1250 - mean_absolute_error: 633.6816 - val_loss: 734177.5000 - val_mean_squared_error: 734177.5000 - val_mean_absolute_error: 758.7270\n",
      "Epoch 400/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 667098.7500 - mean_squared_error: 667098.7500 - mean_absolute_error: 592.4955\n",
      "Epoch 00400: val_loss improved from 734177.50000 to 732232.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 856206.9081 - mean_squared_error: 856206.9375 - mean_absolute_error: 633.1914 - val_loss: 732232.8750 - val_mean_squared_error: 732232.8750 - val_mean_absolute_error: 757.7703\n",
      "Epoch 401/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 854348.5625 - mean_squared_error: 854348.5625 - mean_absolute_error: 704.5748\n",
      "Epoch 00401: val_loss improved from 732232.87500 to 730130.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 854675.4926 - mean_squared_error: 854675.5000 - mean_absolute_error: 632.8256 - val_loss: 730130.7500 - val_mean_squared_error: 730130.7500 - val_mean_absolute_error: 756.7439\n",
      "Epoch 402/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1312820.0000 - mean_squared_error: 1312820.0000 - mean_absolute_error: 838.1429\n",
      "Epoch 00402: val_loss improved from 730130.75000 to 727990.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 853177.1935 - mean_squared_error: 853177.1875 - mean_absolute_error: 632.4708 - val_loss: 727990.8750 - val_mean_squared_error: 727990.8750 - val_mean_absolute_error: 755.7005\n",
      "Epoch 403/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1122024.0000 - mean_squared_error: 1122024.0000 - mean_absolute_error: 713.1995\n",
      "Epoch 00403: val_loss improved from 727990.87500 to 726028.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 851423.4816 - mean_squared_error: 851423.5000 - mean_absolute_error: 632.1749 - val_loss: 726028.5000 - val_mean_squared_error: 726028.5000 - val_mean_absolute_error: 754.7345\n",
      "Epoch 404/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1201137.7500 - mean_squared_error: 1201137.7500 - mean_absolute_error: 750.8730\n",
      "Epoch 00404: val_loss improved from 726028.50000 to 724084.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 849840.9926 - mean_squared_error: 849841.0000 - mean_absolute_error: 631.7642 - val_loss: 724084.5000 - val_mean_squared_error: 724084.5000 - val_mean_absolute_error: 753.7664\n",
      "Epoch 405/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1274062.5000 - mean_squared_error: 1274062.5000 - mean_absolute_error: 763.8935\n",
      "Epoch 00405: val_loss improved from 724084.50000 to 721987.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 848366.6765 - mean_squared_error: 848366.6250 - mean_absolute_error: 631.4310 - val_loss: 721987.3750 - val_mean_squared_error: 721987.3750 - val_mean_absolute_error: 752.7175\n",
      "Epoch 406/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 945213.2500 - mean_squared_error: 945213.2500 - mean_absolute_error: 600.5675\n",
      "Epoch 00406: val_loss improved from 721987.37500 to 719921.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 846609.5892 - mean_squared_error: 846609.5625 - mean_absolute_error: 631.0261 - val_loss: 719921.7500 - val_mean_squared_error: 719921.7500 - val_mean_absolute_error: 751.6755\n",
      "Epoch 407/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1142169.2500 - mean_squared_error: 1142169.2500 - mean_absolute_error: 743.4806\n",
      "Epoch 00407: val_loss improved from 719921.75000 to 717832.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 845043.1176 - mean_squared_error: 845043.1250 - mean_absolute_error: 630.7024 - val_loss: 717832.6250 - val_mean_squared_error: 717832.6250 - val_mean_absolute_error: 750.6199\n",
      "Epoch 408/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1009712.6875 - mean_squared_error: 1009712.6875 - mean_absolute_error: 669.5212\n",
      "Epoch 00408: val_loss improved from 717832.62500 to 715726.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 843419.1360 - mean_squared_error: 843419.1875 - mean_absolute_error: 630.3732 - val_loss: 715726.6875 - val_mean_squared_error: 715726.6875 - val_mean_absolute_error: 749.5451\n",
      "Epoch 409/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1145944.7500 - mean_squared_error: 1145944.7500 - mean_absolute_error: 716.9656\n",
      "Epoch 00409: val_loss improved from 715726.68750 to 713673.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 841892.0938 - mean_squared_error: 841892.1250 - mean_absolute_error: 630.1545 - val_loss: 713673.8125 - val_mean_squared_error: 713673.8125 - val_mean_absolute_error: 748.6540\n",
      "Epoch 410/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1330776.0000 - mean_squared_error: 1330776.0000 - mean_absolute_error: 767.2329\n",
      "Epoch 00410: val_loss improved from 713673.81250 to 711750.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 840277.4729 - mean_squared_error: 840277.5000 - mean_absolute_error: 629.8521 - val_loss: 711750.2500 - val_mean_squared_error: 711750.2500 - val_mean_absolute_error: 747.9610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 978914.2500 - mean_squared_error: 978914.2500 - mean_absolute_error: 677.6128\n",
      "Epoch 00411: val_loss improved from 711750.25000 to 710112.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 838721.5588 - mean_squared_error: 838721.5000 - mean_absolute_error: 629.5278 - val_loss: 710112.1250 - val_mean_squared_error: 710112.1250 - val_mean_absolute_error: 747.3297\n",
      "Epoch 412/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 538551.1875 - mean_squared_error: 538551.1875 - mean_absolute_error: 477.5369\n",
      "Epoch 00412: val_loss improved from 710112.12500 to 708512.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 837294.6029 - mean_squared_error: 837294.6250 - mean_absolute_error: 629.2643 - val_loss: 708512.6875 - val_mean_squared_error: 708512.6875 - val_mean_absolute_error: 746.7021\n",
      "Epoch 413/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 761402.1250 - mean_squared_error: 761402.1250 - mean_absolute_error: 612.5638\n",
      "Epoch 00413: val_loss improved from 708512.68750 to 706801.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 836071.5947 - mean_squared_error: 836071.6250 - mean_absolute_error: 629.1351 - val_loss: 706801.1250 - val_mean_squared_error: 706801.1250 - val_mean_absolute_error: 746.0393\n",
      "Epoch 414/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1144414.8750 - mean_squared_error: 1144414.8750 - mean_absolute_error: 713.4651\n",
      "Epoch 00414: val_loss improved from 706801.12500 to 705070.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 834756.7390 - mean_squared_error: 834756.7500 - mean_absolute_error: 628.9943 - val_loss: 705070.7500 - val_mean_squared_error: 705070.7500 - val_mean_absolute_error: 745.3813\n",
      "Epoch 415/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 681777.3125 - mean_squared_error: 681777.3125 - mean_absolute_error: 591.5298\n",
      "Epoch 00415: val_loss improved from 705070.75000 to 703371.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 833293.1526 - mean_squared_error: 833293.1875 - mean_absolute_error: 628.8525 - val_loss: 703371.0000 - val_mean_squared_error: 703371.0000 - val_mean_absolute_error: 744.7209\n",
      "Epoch 416/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1128591.2500 - mean_squared_error: 1128591.2500 - mean_absolute_error: 740.2175\n",
      "Epoch 00416: val_loss improved from 703371.00000 to 701626.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 832050.7206 - mean_squared_error: 832050.6875 - mean_absolute_error: 628.6646 - val_loss: 701626.5000 - val_mean_squared_error: 701626.5000 - val_mean_absolute_error: 744.0206\n",
      "Epoch 417/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 410474.3125 - mean_squared_error: 410474.3125 - mean_absolute_error: 506.9060\n",
      "Epoch 00417: val_loss improved from 701626.50000 to 699664.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 830432.2500 - mean_squared_error: 830432.2500 - mean_absolute_error: 628.4769 - val_loss: 699664.0000 - val_mean_squared_error: 699664.0000 - val_mean_absolute_error: 743.2380\n",
      "Epoch 418/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 906145.4375 - mean_squared_error: 906145.4375 - mean_absolute_error: 647.2460\n",
      "Epoch 00418: val_loss improved from 699664.00000 to 697450.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 829015.8732 - mean_squared_error: 829015.8750 - mean_absolute_error: 628.3092 - val_loss: 697450.3125 - val_mean_squared_error: 697450.3125 - val_mean_absolute_error: 742.3828\n",
      "Epoch 419/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1128384.5000 - mean_squared_error: 1128384.5000 - mean_absolute_error: 733.5664\n",
      "Epoch 00419: val_loss improved from 697450.31250 to 695445.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 827384.9623 - mean_squared_error: 827384.9375 - mean_absolute_error: 628.2002 - val_loss: 695445.8750 - val_mean_squared_error: 695445.8750 - val_mean_absolute_error: 741.5989\n",
      "Epoch 420/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 816794.1250 - mean_squared_error: 816794.1250 - mean_absolute_error: 644.6891\n",
      "Epoch 00420: val_loss improved from 695445.87500 to 693465.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 825683.9118 - mean_squared_error: 825683.9375 - mean_absolute_error: 627.9669 - val_loss: 693465.5000 - val_mean_squared_error: 693465.5000 - val_mean_absolute_error: 740.8337\n",
      "Epoch 421/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 452219.8750 - mean_squared_error: 452219.8750 - mean_absolute_error: 529.6901\n",
      "Epoch 00421: val_loss improved from 693465.50000 to 691342.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 824086.9596 - mean_squared_error: 824086.9375 - mean_absolute_error: 627.9205 - val_loss: 691342.2500 - val_mean_squared_error: 691342.2500 - val_mean_absolute_error: 740.0251\n",
      "Epoch 422/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1430749.6250 - mean_squared_error: 1430749.6250 - mean_absolute_error: 824.7694\n",
      "Epoch 00422: val_loss improved from 691342.25000 to 689302.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 822795.3566 - mean_squared_error: 822795.3750 - mean_absolute_error: 627.9479 - val_loss: 689302.8750 - val_mean_squared_error: 689302.8750 - val_mean_absolute_error: 739.2366\n",
      "Epoch 423/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 690252.5000 - mean_squared_error: 690252.5000 - mean_absolute_error: 581.7667\n",
      "Epoch 00423: val_loss improved from 689302.87500 to 687519.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 821039.7721 - mean_squared_error: 821039.7500 - mean_absolute_error: 627.8380 - val_loss: 687519.7500 - val_mean_squared_error: 687519.7500 - val_mean_absolute_error: 738.5128\n",
      "Epoch 424/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 954133.6875 - mean_squared_error: 954133.6875 - mean_absolute_error: 685.7711\n",
      "Epoch 00424: val_loss improved from 687519.75000 to 685797.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 819633.6287 - mean_squared_error: 819633.6250 - mean_absolute_error: 627.7565 - val_loss: 685797.2500 - val_mean_squared_error: 685797.2500 - val_mean_absolute_error: 737.7928\n",
      "Epoch 425/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 788701.8125 - mean_squared_error: 788701.8125 - mean_absolute_error: 658.4976\n",
      "Epoch 00425: val_loss improved from 685797.25000 to 683982.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 818345.5809 - mean_squared_error: 818345.5625 - mean_absolute_error: 627.7241 - val_loss: 683982.1250 - val_mean_squared_error: 683982.1250 - val_mean_absolute_error: 737.0446\n",
      "Epoch 426/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 577818.6875 - mean_squared_error: 577818.6875 - mean_absolute_error: 558.2021\n",
      "Epoch 00426: val_loss improved from 683982.12500 to 682287.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 816851.3290 - mean_squared_error: 816851.3125 - mean_absolute_error: 627.5674 - val_loss: 682287.5625 - val_mean_squared_error: 682287.5625 - val_mean_absolute_error: 736.3215\n",
      "Epoch 427/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 783147.3750 - mean_squared_error: 783147.3750 - mean_absolute_error: 651.2981\n",
      "Epoch 00427: val_loss improved from 682287.56250 to 680650.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 815575.3107 - mean_squared_error: 815575.3125 - mean_absolute_error: 627.4581 - val_loss: 680650.5625 - val_mean_squared_error: 680650.5625 - val_mean_absolute_error: 735.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 428/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 970484.8750 - mean_squared_error: 970484.8750 - mean_absolute_error: 630.4806\n",
      "Epoch 00428: val_loss improved from 680650.56250 to 678945.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 814313.3364 - mean_squared_error: 814313.3125 - mean_absolute_error: 627.3578 - val_loss: 678945.6250 - val_mean_squared_error: 678945.6250 - val_mean_absolute_error: 734.8882\n",
      "Epoch 429/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 345971.8438 - mean_squared_error: 345971.8438 - mean_absolute_error: 469.4302\n",
      "Epoch 00429: val_loss improved from 678945.62500 to 677189.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 812713.4118 - mean_squared_error: 812713.4375 - mean_absolute_error: 627.1362 - val_loss: 677189.8750 - val_mean_squared_error: 677189.8750 - val_mean_absolute_error: 734.1307\n",
      "Epoch 430/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 594979.3750 - mean_squared_error: 594979.3750 - mean_absolute_error: 555.4412\n",
      "Epoch 00430: val_loss improved from 677189.87500 to 675220.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 811461.5855 - mean_squared_error: 811461.5625 - mean_absolute_error: 627.0751 - val_loss: 675220.3750 - val_mean_squared_error: 675220.3750 - val_mean_absolute_error: 733.2874\n",
      "Epoch 431/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 403560.0312 - mean_squared_error: 403560.0312 - mean_absolute_error: 525.7944\n",
      "Epoch 00431: val_loss improved from 675220.37500 to 673382.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 809858.7895 - mean_squared_error: 809858.7500 - mean_absolute_error: 626.9398 - val_loss: 673382.4375 - val_mean_squared_error: 673382.4375 - val_mean_absolute_error: 732.4958\n",
      "Epoch 432/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 958149.6250 - mean_squared_error: 958149.6250 - mean_absolute_error: 693.3586\n",
      "Epoch 00432: val_loss improved from 673382.43750 to 671583.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 808637.4798 - mean_squared_error: 808637.5000 - mean_absolute_error: 626.8970 - val_loss: 671583.4375 - val_mean_squared_error: 671583.4375 - val_mean_absolute_error: 731.7136\n",
      "Epoch 433/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 791103.2500 - mean_squared_error: 791103.2500 - mean_absolute_error: 592.9978\n",
      "Epoch 00433: val_loss improved from 671583.43750 to 669799.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 807147.1691 - mean_squared_error: 807147.1875 - mean_absolute_error: 626.6989 - val_loss: 669799.7500 - val_mean_squared_error: 669799.7500 - val_mean_absolute_error: 730.9335\n",
      "Epoch 434/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 892030.5625 - mean_squared_error: 892030.5625 - mean_absolute_error: 673.5439\n",
      "Epoch 00434: val_loss improved from 669799.75000 to 667987.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 805846.2436 - mean_squared_error: 805846.3125 - mean_absolute_error: 626.6509 - val_loss: 667987.8125 - val_mean_squared_error: 667987.8125 - val_mean_absolute_error: 730.1511\n",
      "Epoch 435/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 641339.6250 - mean_squared_error: 641339.6250 - mean_absolute_error: 580.9963\n",
      "Epoch 00435: val_loss improved from 667987.81250 to 666391.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 804420.5404 - mean_squared_error: 804420.5000 - mean_absolute_error: 626.5320 - val_loss: 666391.9375 - val_mean_squared_error: 666391.9375 - val_mean_absolute_error: 729.4374\n",
      "Epoch 436/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 644597.4375 - mean_squared_error: 644597.4375 - mean_absolute_error: 569.4017\n",
      "Epoch 00436: val_loss improved from 666391.93750 to 664693.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 802979.3529 - mean_squared_error: 802979.3125 - mean_absolute_error: 626.3279 - val_loss: 664693.5625 - val_mean_squared_error: 664693.5625 - val_mean_absolute_error: 728.6772\n",
      "Epoch 437/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1276636.2500 - mean_squared_error: 1276636.2500 - mean_absolute_error: 776.7723\n",
      "Epoch 00437: val_loss improved from 664693.56250 to 662427.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 801912.1618 - mean_squared_error: 801912.1875 - mean_absolute_error: 626.3439 - val_loss: 662427.0000 - val_mean_squared_error: 662427.0000 - val_mean_absolute_error: 727.6997\n",
      "Epoch 438/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 413037.5000 - mean_squared_error: 413037.5000 - mean_absolute_error: 526.6261\n",
      "Epoch 00438: val_loss improved from 662427.00000 to 660379.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 800001.7381 - mean_squared_error: 800001.7500 - mean_absolute_error: 626.2946 - val_loss: 660379.4375 - val_mean_squared_error: 660379.4375 - val_mean_absolute_error: 726.7719\n",
      "Epoch 439/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1259051.6250 - mean_squared_error: 1259051.6250 - mean_absolute_error: 766.4335\n",
      "Epoch 00439: val_loss improved from 660379.43750 to 658692.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 798709.7371 - mean_squared_error: 798709.7500 - mean_absolute_error: 626.1568 - val_loss: 658692.9375 - val_mean_squared_error: 658692.9375 - val_mean_absolute_error: 725.9569\n",
      "Epoch 440/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 909298.2500 - mean_squared_error: 909298.2500 - mean_absolute_error: 626.5839\n",
      "Epoch 00440: val_loss improved from 658692.93750 to 657222.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 797295.1544 - mean_squared_error: 797295.1875 - mean_absolute_error: 625.9610 - val_loss: 657222.2500 - val_mean_squared_error: 657222.2500 - val_mean_absolute_error: 725.2188\n",
      "Epoch 441/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 926688.5000 - mean_squared_error: 926688.5000 - mean_absolute_error: 675.0602\n",
      "Epoch 00441: val_loss improved from 657222.25000 to 655851.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 796059.3180 - mean_squared_error: 796059.3125 - mean_absolute_error: 625.6284 - val_loss: 655851.3125 - val_mean_squared_error: 655851.3125 - val_mean_absolute_error: 724.5085\n",
      "Epoch 442/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 727398.4375 - mean_squared_error: 727398.4375 - mean_absolute_error: 581.5321\n",
      "Epoch 00442: val_loss improved from 655851.31250 to 654611.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 794882.2721 - mean_squared_error: 794882.2500 - mean_absolute_error: 625.3882 - val_loss: 654611.1250 - val_mean_squared_error: 654611.1250 - val_mean_absolute_error: 723.8542\n",
      "Epoch 443/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 924799.2500 - mean_squared_error: 924799.2500 - mean_absolute_error: 668.0410\n",
      "Epoch 00443: val_loss improved from 654611.12500 to 653446.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 793940.5708 - mean_squared_error: 793940.5625 - mean_absolute_error: 625.2274 - val_loss: 653446.4375 - val_mean_squared_error: 653446.4375 - val_mean_absolute_error: 723.2324\n",
      "Epoch 444/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 763841.3125 - mean_squared_error: 763841.3125 - mean_absolute_error: 658.9846\n",
      "Epoch 00444: val_loss improved from 653446.43750 to 652327.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 792896.0882 - mean_squared_error: 792896.1250 - mean_absolute_error: 624.9074 - val_loss: 652327.2500 - val_mean_squared_error: 652327.2500 - val_mean_absolute_error: 722.6194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 445/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 899928.2500 - mean_squared_error: 899928.2500 - mean_absolute_error: 712.2781\n",
      "Epoch 00445: val_loss improved from 652327.25000 to 650987.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 791922.6471 - mean_squared_error: 791922.5625 - mean_absolute_error: 624.6569 - val_loss: 650987.2500 - val_mean_squared_error: 650987.2500 - val_mean_absolute_error: 721.9082\n",
      "Epoch 446/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 613647.0625 - mean_squared_error: 613647.0625 - mean_absolute_error: 555.2416\n",
      "Epoch 00446: val_loss improved from 650987.25000 to 649580.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 790731.1140 - mean_squared_error: 790731.1250 - mean_absolute_error: 624.3771 - val_loss: 649580.0000 - val_mean_squared_error: 649580.0000 - val_mean_absolute_error: 721.1634\n",
      "Epoch 447/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1217570.3750 - mean_squared_error: 1217570.3750 - mean_absolute_error: 758.2849\n",
      "Epoch 00447: val_loss improved from 649580.00000 to 648395.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 789677.7206 - mean_squared_error: 789677.6875 - mean_absolute_error: 624.1180 - val_loss: 648395.0625 - val_mean_squared_error: 648395.0625 - val_mean_absolute_error: 720.4758\n",
      "Epoch 448/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 892181.7500 - mean_squared_error: 892181.7500 - mean_absolute_error: 651.3170\n",
      "Epoch 00448: val_loss improved from 648395.06250 to 647417.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 788541.7794 - mean_squared_error: 788541.7500 - mean_absolute_error: 623.7031 - val_loss: 647417.3750 - val_mean_squared_error: 647417.3750 - val_mean_absolute_error: 719.8508\n",
      "Epoch 449/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 837259.1250 - mean_squared_error: 837259.1250 - mean_absolute_error: 666.0132\n",
      "Epoch 00449: val_loss improved from 647417.37500 to 646435.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 787592.9779 - mean_squared_error: 787593.0000 - mean_absolute_error: 623.2928 - val_loss: 646435.8125 - val_mean_squared_error: 646435.8125 - val_mean_absolute_error: 719.2313\n",
      "Epoch 450/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 799541.0625 - mean_squared_error: 799541.0625 - mean_absolute_error: 580.4706\n",
      "Epoch 00450: val_loss improved from 646435.81250 to 645444.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 786607.6471 - mean_squared_error: 786607.6250 - mean_absolute_error: 622.8727 - val_loss: 645444.6875 - val_mean_squared_error: 645444.6875 - val_mean_absolute_error: 718.6101\n",
      "Epoch 451/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 893029.1250 - mean_squared_error: 893029.1250 - mean_absolute_error: 651.7901\n",
      "Epoch 00451: val_loss improved from 645444.68750 to 644302.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 785700.2610 - mean_squared_error: 785700.2500 - mean_absolute_error: 622.5226 - val_loss: 644302.0000 - val_mean_squared_error: 644302.0000 - val_mean_absolute_error: 717.9291\n",
      "Epoch 452/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 828934.9375 - mean_squared_error: 828934.9375 - mean_absolute_error: 590.7730\n",
      "Epoch 00452: val_loss improved from 644302.00000 to 643336.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 784638.3842 - mean_squared_error: 784638.3750 - mean_absolute_error: 622.1131 - val_loss: 643336.8750 - val_mean_squared_error: 643336.8750 - val_mean_absolute_error: 717.3185\n",
      "Epoch 453/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 647112.1250 - mean_squared_error: 647112.1250 - mean_absolute_error: 576.7569\n",
      "Epoch 00453: val_loss improved from 643336.87500 to 642293.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 783642.3088 - mean_squared_error: 783642.3750 - mean_absolute_error: 621.6766 - val_loss: 642293.1250 - val_mean_squared_error: 642293.1250 - val_mean_absolute_error: 716.6718\n",
      "Epoch 454/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 666512.0625 - mean_squared_error: 666512.0625 - mean_absolute_error: 576.9726\n",
      "Epoch 00454: val_loss improved from 642293.12500 to 640820.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 782570.3382 - mean_squared_error: 782570.3125 - mean_absolute_error: 621.2951 - val_loss: 640820.9375 - val_mean_squared_error: 640820.9375 - val_mean_absolute_error: 715.8547\n",
      "Epoch 455/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1117125.5000 - mean_squared_error: 1117125.5000 - mean_absolute_error: 678.9791\n",
      "Epoch 00455: val_loss improved from 640820.93750 to 639289.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 781477.6434 - mean_squared_error: 781477.6250 - mean_absolute_error: 621.0351 - val_loss: 639289.0000 - val_mean_squared_error: 639289.0000 - val_mean_absolute_error: 715.0212\n",
      "Epoch 456/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 622650.5625 - mean_squared_error: 622650.5625 - mean_absolute_error: 523.5629\n",
      "Epoch 00456: val_loss improved from 639289.00000 to 637980.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 780111.2096 - mean_squared_error: 780111.1875 - mean_absolute_error: 620.6959 - val_loss: 637980.6875 - val_mean_squared_error: 637980.6875 - val_mean_absolute_error: 714.2757\n",
      "Epoch 457/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1250736.8750 - mean_squared_error: 1250736.8750 - mean_absolute_error: 742.1722\n",
      "Epoch 00457: val_loss improved from 637980.68750 to 636796.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 779064.4596 - mean_squared_error: 779064.5000 - mean_absolute_error: 620.3199 - val_loss: 636796.6250 - val_mean_squared_error: 636796.6250 - val_mean_absolute_error: 713.5805\n",
      "Epoch 458/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 782518.8750 - mean_squared_error: 782518.8750 - mean_absolute_error: 649.9508\n",
      "Epoch 00458: val_loss improved from 636796.62500 to 635685.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 777934.9035 - mean_squared_error: 777934.8750 - mean_absolute_error: 619.9910 - val_loss: 635685.0625 - val_mean_squared_error: 635685.0625 - val_mean_absolute_error: 712.9313\n",
      "Epoch 459/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 664386.0000 - mean_squared_error: 664386.0000 - mean_absolute_error: 593.8011\n",
      "Epoch 00459: val_loss improved from 635685.06250 to 634484.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 776860.6912 - mean_squared_error: 776860.6875 - mean_absolute_error: 619.6511 - val_loss: 634484.1250 - val_mean_squared_error: 634484.1250 - val_mean_absolute_error: 712.2565\n",
      "Epoch 460/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 558430.8750 - mean_squared_error: 558430.8750 - mean_absolute_error: 526.5906\n",
      "Epoch 00460: val_loss improved from 634484.12500 to 633137.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 775844.2904 - mean_squared_error: 775844.3125 - mean_absolute_error: 619.4404 - val_loss: 633137.2500 - val_mean_squared_error: 633137.2500 - val_mean_absolute_error: 711.5173\n",
      "Epoch 461/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 943163.7500 - mean_squared_error: 943163.7500 - mean_absolute_error: 691.9962\n",
      "Epoch 00461: val_loss improved from 633137.25000 to 631853.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 774819.2647 - mean_squared_error: 774819.3125 - mean_absolute_error: 619.1747 - val_loss: 631853.1250 - val_mean_squared_error: 631853.1250 - val_mean_absolute_error: 710.7991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 462/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 393051.5938 - mean_squared_error: 393051.5938 - mean_absolute_error: 524.0140\n",
      "Epoch 00462: val_loss improved from 631853.12500 to 630566.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 773580.8364 - mean_squared_error: 773580.8125 - mean_absolute_error: 618.8300 - val_loss: 630566.9375 - val_mean_squared_error: 630566.9375 - val_mean_absolute_error: 710.0701\n",
      "Epoch 463/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 919072.0000 - mean_squared_error: 919072.0000 - mean_absolute_error: 661.5640\n",
      "Epoch 00463: val_loss improved from 630566.93750 to 629419.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 772588.8401 - mean_squared_error: 772588.8125 - mean_absolute_error: 618.5208 - val_loss: 629419.6875 - val_mean_squared_error: 629419.6875 - val_mean_absolute_error: 709.3859\n",
      "Epoch 464/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 602223.6875 - mean_squared_error: 602223.6875 - mean_absolute_error: 573.9103\n",
      "Epoch 00464: val_loss improved from 629419.68750 to 628300.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 771492.0882 - mean_squared_error: 771492.0625 - mean_absolute_error: 618.1547 - val_loss: 628300.4375 - val_mean_squared_error: 628300.4375 - val_mean_absolute_error: 708.7073\n",
      "Epoch 465/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 879002.7500 - mean_squared_error: 879002.7500 - mean_absolute_error: 616.0394\n",
      "Epoch 00465: val_loss improved from 628300.43750 to 626992.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 770479.9688 - mean_squared_error: 770479.9375 - mean_absolute_error: 617.8121 - val_loss: 626992.2500 - val_mean_squared_error: 626992.2500 - val_mean_absolute_error: 707.9550\n",
      "Epoch 466/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 629451.7500 - mean_squared_error: 629451.7500 - mean_absolute_error: 569.7932\n",
      "Epoch 00466: val_loss improved from 626992.25000 to 625875.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 769383.2610 - mean_squared_error: 769383.2500 - mean_absolute_error: 617.5178 - val_loss: 625875.6250 - val_mean_squared_error: 625875.6250 - val_mean_absolute_error: 707.2831\n",
      "Epoch 467/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 374482.9688 - mean_squared_error: 374482.9688 - mean_absolute_error: 484.3247\n",
      "Epoch 00467: val_loss improved from 625875.62500 to 624852.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 768345.9669 - mean_squared_error: 768346.0000 - mean_absolute_error: 617.1353 - val_loss: 624852.6875 - val_mean_squared_error: 624852.6875 - val_mean_absolute_error: 706.6593\n",
      "Epoch 468/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1186261.1250 - mean_squared_error: 1186261.1250 - mean_absolute_error: 743.5894\n",
      "Epoch 00468: val_loss improved from 624852.68750 to 623749.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 767498.7849 - mean_squared_error: 767498.7500 - mean_absolute_error: 616.8106 - val_loss: 623749.0625 - val_mean_squared_error: 623749.0625 - val_mean_absolute_error: 706.0211\n",
      "Epoch 469/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 493319.1250 - mean_squared_error: 493319.1250 - mean_absolute_error: 536.8696\n",
      "Epoch 00469: val_loss improved from 623749.06250 to 622779.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 766514.6195 - mean_squared_error: 766514.6250 - mean_absolute_error: 616.5721 - val_loss: 622779.5000 - val_mean_squared_error: 622779.5000 - val_mean_absolute_error: 705.4309\n",
      "Epoch 470/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 826399.3750 - mean_squared_error: 826399.3750 - mean_absolute_error: 639.8849\n",
      "Epoch 00470: val_loss improved from 622779.50000 to 621772.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 765632.7941 - mean_squared_error: 765632.7500 - mean_absolute_error: 616.2608 - val_loss: 621772.7500 - val_mean_squared_error: 621772.7500 - val_mean_absolute_error: 704.8169\n",
      "Epoch 471/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 904868.5000 - mean_squared_error: 904868.5000 - mean_absolute_error: 659.5691\n",
      "Epoch 00471: val_loss improved from 621772.75000 to 620664.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 764753.9228 - mean_squared_error: 764753.9375 - mean_absolute_error: 615.9633 - val_loss: 620664.6250 - val_mean_squared_error: 620664.6250 - val_mean_absolute_error: 704.1504\n",
      "Epoch 472/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 404639.6562 - mean_squared_error: 404639.6562 - mean_absolute_error: 507.5240\n",
      "Epoch 00472: val_loss improved from 620664.62500 to 619576.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 763644.5294 - mean_squared_error: 763644.5000 - mean_absolute_error: 615.6079 - val_loss: 619576.2500 - val_mean_squared_error: 619576.2500 - val_mean_absolute_error: 703.4785\n",
      "Epoch 473/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 456848.4062 - mean_squared_error: 456848.4062 - mean_absolute_error: 526.4288\n",
      "Epoch 00473: val_loss improved from 619576.25000 to 618263.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 762633.0000 - mean_squared_error: 762633.0000 - mean_absolute_error: 615.2394 - val_loss: 618263.6875 - val_mean_squared_error: 618263.6875 - val_mean_absolute_error: 702.6959\n",
      "Epoch 474/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 424837.9688 - mean_squared_error: 424837.9688 - mean_absolute_error: 511.7861\n",
      "Epoch 00474: val_loss improved from 618263.68750 to 617046.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 761504.1654 - mean_squared_error: 761504.1875 - mean_absolute_error: 614.9121 - val_loss: 617046.1875 - val_mean_squared_error: 617046.1875 - val_mean_absolute_error: 701.9540\n",
      "Epoch 475/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 904474.2500 - mean_squared_error: 904474.2500 - mean_absolute_error: 610.5677\n",
      "Epoch 00475: val_loss improved from 617046.18750 to 615919.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 760454.8824 - mean_squared_error: 760454.8750 - mean_absolute_error: 614.5095 - val_loss: 615919.0625 - val_mean_squared_error: 615919.0625 - val_mean_absolute_error: 701.2417\n",
      "Epoch 476/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1033497.1875 - mean_squared_error: 1033497.1875 - mean_absolute_error: 720.4195\n",
      "Epoch 00476: val_loss improved from 615919.06250 to 614791.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 759528.2941 - mean_squared_error: 759528.2500 - mean_absolute_error: 614.2292 - val_loss: 614791.5000 - val_mean_squared_error: 614791.5000 - val_mean_absolute_error: 700.5391\n",
      "Epoch 477/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 757793.1875 - mean_squared_error: 757793.1875 - mean_absolute_error: 660.0039\n",
      "Epoch 00477: val_loss improved from 614791.50000 to 613859.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 758443.9504 - mean_squared_error: 758443.9375 - mean_absolute_error: 613.7897 - val_loss: 613859.3750 - val_mean_squared_error: 613859.3750 - val_mean_absolute_error: 699.9226\n",
      "Epoch 478/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 933130.7500 - mean_squared_error: 933130.7500 - mean_absolute_error: 699.0132\n",
      "Epoch 00478: val_loss improved from 613859.37500 to 613034.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 757566.7096 - mean_squared_error: 757566.6875 - mean_absolute_error: 613.3893 - val_loss: 613034.9375 - val_mean_squared_error: 613034.9375 - val_mean_absolute_error: 699.3484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 479/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 977769.5000 - mean_squared_error: 977769.5000 - mean_absolute_error: 678.3363\n",
      "Epoch 00479: val_loss improved from 613034.93750 to 612283.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 756723.6121 - mean_squared_error: 756723.5625 - mean_absolute_error: 612.9673 - val_loss: 612283.0000 - val_mean_squared_error: 612283.0000 - val_mean_absolute_error: 698.8058\n",
      "Epoch 480/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 610375.5000 - mean_squared_error: 610375.5000 - mean_absolute_error: 554.6033\n",
      "Epoch 00480: val_loss improved from 612283.00000 to 611457.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 755888.3015 - mean_squared_error: 755888.3125 - mean_absolute_error: 612.5554 - val_loss: 611457.3125 - val_mean_squared_error: 611457.3125 - val_mean_absolute_error: 698.2476\n",
      "Epoch 481/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1146512.8750 - mean_squared_error: 1146512.8750 - mean_absolute_error: 746.2767\n",
      "Epoch 00481: val_loss improved from 611457.31250 to 610518.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 755089.8419 - mean_squared_error: 755089.8750 - mean_absolute_error: 612.2081 - val_loss: 610518.8750 - val_mean_squared_error: 610518.8750 - val_mean_absolute_error: 697.6361\n",
      "Epoch 482/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 606958.5000 - mean_squared_error: 606958.5000 - mean_absolute_error: 569.6497\n",
      "Epoch 00482: val_loss improved from 610518.87500 to 609414.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 754105.3824 - mean_squared_error: 754105.4375 - mean_absolute_error: 611.9071 - val_loss: 609414.2500 - val_mean_squared_error: 609414.2500 - val_mean_absolute_error: 696.9565\n",
      "Epoch 483/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 909284.8125 - mean_squared_error: 909284.8125 - mean_absolute_error: 664.4673\n",
      "Epoch 00483: val_loss improved from 609414.25000 to 608147.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 753213.5846 - mean_squared_error: 753213.5625 - mean_absolute_error: 611.6851 - val_loss: 608147.8125 - val_mean_squared_error: 608147.8125 - val_mean_absolute_error: 696.1911\n",
      "Epoch 484/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 555358.3750 - mean_squared_error: 555358.3750 - mean_absolute_error: 522.3096\n",
      "Epoch 00484: val_loss improved from 608147.81250 to 606918.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 751939.8088 - mean_squared_error: 751939.8125 - mean_absolute_error: 611.3113 - val_loss: 606918.6250 - val_mean_squared_error: 606918.6250 - val_mean_absolute_error: 695.4289\n",
      "Epoch 485/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 949833.1875 - mean_squared_error: 949833.1875 - mean_absolute_error: 682.1036\n",
      "Epoch 00485: val_loss improved from 606918.62500 to 605506.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 469us/sample - loss: 751014.5239 - mean_squared_error: 751014.5000 - mean_absolute_error: 611.1000 - val_loss: 605506.0000 - val_mean_squared_error: 605506.0000 - val_mean_absolute_error: 694.5659\n",
      "Epoch 486/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1112460.2500 - mean_squared_error: 1112460.2500 - mean_absolute_error: 724.5177\n",
      "Epoch 00486: val_loss improved from 605506.00000 to 604338.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 749720.1029 - mean_squared_error: 749720.0625 - mean_absolute_error: 610.6760 - val_loss: 604338.8750 - val_mean_squared_error: 604338.8750 - val_mean_absolute_error: 693.8055\n",
      "Epoch 487/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1234956.1250 - mean_squared_error: 1234956.1250 - mean_absolute_error: 788.8431\n",
      "Epoch 00487: val_loss improved from 604338.87500 to 603191.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 748702.6693 - mean_squared_error: 748702.6875 - mean_absolute_error: 610.3518 - val_loss: 603191.3750 - val_mean_squared_error: 603191.3750 - val_mean_absolute_error: 693.0657\n",
      "Epoch 488/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 847381.4375 - mean_squared_error: 847381.4375 - mean_absolute_error: 614.8173\n",
      "Epoch 00488: val_loss improved from 603191.37500 to 602089.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 747510.7574 - mean_squared_error: 747510.6875 - mean_absolute_error: 609.9333 - val_loss: 602089.0625 - val_mean_squared_error: 602089.0625 - val_mean_absolute_error: 692.3626\n",
      "Epoch 489/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 892939.3750 - mean_squared_error: 892939.3750 - mean_absolute_error: 680.0272\n",
      "Epoch 00489: val_loss improved from 602089.06250 to 600889.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 746573.2132 - mean_squared_error: 746573.2500 - mean_absolute_error: 609.6598 - val_loss: 600889.0000 - val_mean_squared_error: 600889.0000 - val_mean_absolute_error: 691.6147\n",
      "Epoch 490/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1067266.2500 - mean_squared_error: 1067266.2500 - mean_absolute_error: 684.4619\n",
      "Epoch 00490: val_loss improved from 600889.00000 to 599800.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 745538.9200 - mean_squared_error: 745538.9375 - mean_absolute_error: 609.3780 - val_loss: 599800.8750 - val_mean_squared_error: 599800.8750 - val_mean_absolute_error: 690.9119\n",
      "Epoch 491/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 712211.7500 - mean_squared_error: 712211.7500 - mean_absolute_error: 655.5593\n",
      "Epoch 00491: val_loss improved from 599800.87500 to 598812.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 744475.2215 - mean_squared_error: 744475.2500 - mean_absolute_error: 609.0333 - val_loss: 598812.1250 - val_mean_squared_error: 598812.1250 - val_mean_absolute_error: 690.2499\n",
      "Epoch 492/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 717678.8750 - mean_squared_error: 717678.8750 - mean_absolute_error: 599.9427\n",
      "Epoch 00492: val_loss improved from 598812.12500 to 597924.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 743541.8199 - mean_squared_error: 743541.8125 - mean_absolute_error: 608.6782 - val_loss: 597924.8125 - val_mean_squared_error: 597924.8125 - val_mean_absolute_error: 689.6285\n",
      "Epoch 493/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1006507.8125 - mean_squared_error: 1006507.8125 - mean_absolute_error: 701.2729\n",
      "Epoch 00493: val_loss improved from 597924.81250 to 597200.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 742665.9798 - mean_squared_error: 742665.9375 - mean_absolute_error: 608.2247 - val_loss: 597200.3750 - val_mean_squared_error: 597200.3750 - val_mean_absolute_error: 689.0710\n",
      "Epoch 494/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 534457.6875 - mean_squared_error: 534457.6875 - mean_absolute_error: 481.8509\n",
      "Epoch 00494: val_loss improved from 597200.37500 to 596493.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 741834.4007 - mean_squared_error: 741834.4375 - mean_absolute_error: 607.7726 - val_loss: 596493.6875 - val_mean_squared_error: 596493.6875 - val_mean_absolute_error: 688.5195\n",
      "Epoch 495/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 760580.0625 - mean_squared_error: 760580.0625 - mean_absolute_error: 641.4701\n",
      "Epoch 00495: val_loss improved from 596493.68750 to 595625.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 741039.7399 - mean_squared_error: 741039.6875 - mean_absolute_error: 607.3369 - val_loss: 595625.2500 - val_mean_squared_error: 595625.2500 - val_mean_absolute_error: 687.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1029253.8750 - mean_squared_error: 1029253.8750 - mean_absolute_error: 744.4391\n",
      "Epoch 00496: val_loss improved from 595625.25000 to 594741.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 740192.9504 - mean_squared_error: 740192.9375 - mean_absolute_error: 606.9502 - val_loss: 594741.1250 - val_mean_squared_error: 594741.1250 - val_mean_absolute_error: 687.2948\n",
      "Epoch 497/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 907983.6250 - mean_squared_error: 907983.6250 - mean_absolute_error: 700.6310\n",
      "Epoch 00497: val_loss improved from 594741.12500 to 593856.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 739319.9890 - mean_squared_error: 739320.0000 - mean_absolute_error: 606.5909 - val_loss: 593856.6250 - val_mean_squared_error: 593856.6250 - val_mean_absolute_error: 686.6917\n",
      "Epoch 498/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 740035.4375 - mean_squared_error: 740035.4375 - mean_absolute_error: 620.0062\n",
      "Epoch 00498: val_loss improved from 593856.62500 to 593109.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 738459.6360 - mean_squared_error: 738459.6250 - mean_absolute_error: 606.2267 - val_loss: 593109.3125 - val_mean_squared_error: 593109.3125 - val_mean_absolute_error: 686.1492\n",
      "Epoch 499/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 341037.5938 - mean_squared_error: 341037.5938 - mean_absolute_error: 485.5447\n",
      "Epoch 00499: val_loss improved from 593109.31250 to 592239.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 737569.5441 - mean_squared_error: 737569.5000 - mean_absolute_error: 605.8250 - val_loss: 592239.1875 - val_mean_squared_error: 592239.1875 - val_mean_absolute_error: 685.5387\n",
      "Epoch 500/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 672411.0625 - mean_squared_error: 672411.0625 - mean_absolute_error: 587.2133\n",
      "Epoch 00500: val_loss improved from 592239.18750 to 590986.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 736717.5827 - mean_squared_error: 736717.5625 - mean_absolute_error: 605.4594 - val_loss: 590986.2500 - val_mean_squared_error: 590986.2500 - val_mean_absolute_error: 684.7201\n",
      "Epoch 501/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 904335.1250 - mean_squared_error: 904335.1250 - mean_absolute_error: 660.0547\n",
      "Epoch 00501: val_loss improved from 590986.25000 to 589742.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 735576.2537 - mean_squared_error: 735576.2500 - mean_absolute_error: 605.0797 - val_loss: 589742.6875 - val_mean_squared_error: 589742.6875 - val_mean_absolute_error: 683.9185\n",
      "Epoch 502/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 606955.9375 - mean_squared_error: 606955.9375 - mean_absolute_error: 575.8417\n",
      "Epoch 00502: val_loss improved from 589742.68750 to 588476.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 499us/sample - loss: 734439.3603 - mean_squared_error: 734439.4375 - mean_absolute_error: 604.7897 - val_loss: 588476.2500 - val_mean_squared_error: 588476.2500 - val_mean_absolute_error: 683.1197\n",
      "Epoch 503/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 711321.5000 - mean_squared_error: 711321.5000 - mean_absolute_error: 545.3718\n",
      "Epoch 00503: val_loss improved from 588476.25000 to 587145.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 733319.0294 - mean_squared_error: 733319.0625 - mean_absolute_error: 604.4808 - val_loss: 587145.8750 - val_mean_squared_error: 587145.8750 - val_mean_absolute_error: 682.2935\n",
      "Epoch 504/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 551893.2500 - mean_squared_error: 551893.2500 - mean_absolute_error: 506.2206\n",
      "Epoch 00504: val_loss improved from 587145.87500 to 585731.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 732084.5257 - mean_squared_error: 732084.5000 - mean_absolute_error: 604.1667 - val_loss: 585731.8750 - val_mean_squared_error: 585731.8750 - val_mean_absolute_error: 681.4235\n",
      "Epoch 505/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 358338.0938 - mean_squared_error: 358338.0938 - mean_absolute_error: 461.3423\n",
      "Epoch 00505: val_loss improved from 585731.87500 to 584427.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 730928.4899 - mean_squared_error: 730928.5000 - mean_absolute_error: 604.0151 - val_loss: 584427.4375 - val_mean_squared_error: 584427.4375 - val_mean_absolute_error: 680.6075\n",
      "Epoch 506/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 767817.8750 - mean_squared_error: 767817.8750 - mean_absolute_error: 621.4850\n",
      "Epoch 00506: val_loss improved from 584427.43750 to 583303.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 729900.9540 - mean_squared_error: 729900.9375 - mean_absolute_error: 603.6737 - val_loss: 583303.0000 - val_mean_squared_error: 583303.0000 - val_mean_absolute_error: 679.8658\n",
      "Epoch 507/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 303988.1250 - mean_squared_error: 303988.1250 - mean_absolute_error: 456.3770\n",
      "Epoch 00507: val_loss improved from 583303.00000 to 582216.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 728806.2298 - mean_squared_error: 728806.2500 - mean_absolute_error: 603.3704 - val_loss: 582216.0625 - val_mean_squared_error: 582216.0625 - val_mean_absolute_error: 679.1469\n",
      "Epoch 508/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 822534.3125 - mean_squared_error: 822534.3125 - mean_absolute_error: 645.1041\n",
      "Epoch 00508: val_loss improved from 582216.06250 to 581030.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 727888.8971 - mean_squared_error: 727888.8750 - mean_absolute_error: 603.0798 - val_loss: 581030.2500 - val_mean_squared_error: 581030.2500 - val_mean_absolute_error: 678.3893\n",
      "Epoch 509/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 901211.1875 - mean_squared_error: 901211.1875 - mean_absolute_error: 682.8036\n",
      "Epoch 00509: val_loss improved from 581030.25000 to 579801.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 726863.9173 - mean_squared_error: 726863.8750 - mean_absolute_error: 602.8231 - val_loss: 579801.9375 - val_mean_squared_error: 579801.9375 - val_mean_absolute_error: 677.5994\n",
      "Epoch 510/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 579321.1250 - mean_squared_error: 579321.1250 - mean_absolute_error: 565.0728\n",
      "Epoch 00510: val_loss improved from 579801.93750 to 578662.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 725761.4228 - mean_squared_error: 725761.4375 - mean_absolute_error: 602.5461 - val_loss: 578662.7500 - val_mean_squared_error: 578662.7500 - val_mean_absolute_error: 676.8441\n",
      "Epoch 511/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 626540.1250 - mean_squared_error: 626540.1250 - mean_absolute_error: 568.6673\n",
      "Epoch 00511: val_loss improved from 578662.75000 to 577519.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 724709.0414 - mean_squared_error: 724709.0625 - mean_absolute_error: 602.2028 - val_loss: 577519.3125 - val_mean_squared_error: 577519.3125 - val_mean_absolute_error: 676.0916\n",
      "Epoch 512/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 636908.2500 - mean_squared_error: 636908.2500 - mean_absolute_error: 550.3724\n",
      "Epoch 00512: val_loss improved from 577519.31250 to 576412.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 723758.7371 - mean_squared_error: 723758.7500 - mean_absolute_error: 601.9521 - val_loss: 576412.9375 - val_mean_squared_error: 576412.9375 - val_mean_absolute_error: 675.3567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 513/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 634986.6250 - mean_squared_error: 634986.6250 - mean_absolute_error: 541.8057\n",
      "Epoch 00513: val_loss improved from 576412.93750 to 575438.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 722788.5110 - mean_squared_error: 722788.5000 - mean_absolute_error: 601.6582 - val_loss: 575438.6875 - val_mean_squared_error: 575438.6875 - val_mean_absolute_error: 674.6812\n",
      "Epoch 514/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 388805.4688 - mean_squared_error: 388805.4688 - mean_absolute_error: 515.8649\n",
      "Epoch 00514: val_loss improved from 575438.68750 to 574510.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 721821.9265 - mean_squared_error: 721821.9375 - mean_absolute_error: 601.3047 - val_loss: 574510.8125 - val_mean_squared_error: 574510.8125 - val_mean_absolute_error: 674.0243\n",
      "Epoch 515/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 691724.5625 - mean_squared_error: 691724.5625 - mean_absolute_error: 593.0753\n",
      "Epoch 00515: val_loss improved from 574510.81250 to 573466.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 720963.1397 - mean_squared_error: 720963.1875 - mean_absolute_error: 600.9552 - val_loss: 573466.4375 - val_mean_squared_error: 573466.4375 - val_mean_absolute_error: 673.3015\n",
      "Epoch 516/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 432168.4375 - mean_squared_error: 432168.4375 - mean_absolute_error: 525.6913\n",
      "Epoch 00516: val_loss improved from 573466.43750 to 572260.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 719862.6618 - mean_squared_error: 719862.6875 - mean_absolute_error: 600.5897 - val_loss: 572260.5625 - val_mean_squared_error: 572260.5625 - val_mean_absolute_error: 672.4894\n",
      "Epoch 517/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 609644.3750 - mean_squared_error: 609644.3750 - mean_absolute_error: 565.4094\n",
      "Epoch 00517: val_loss improved from 572260.56250 to 570912.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 718899.6291 - mean_squared_error: 718899.6250 - mean_absolute_error: 600.3515 - val_loss: 570912.5625 - val_mean_squared_error: 570912.5625 - val_mean_absolute_error: 671.5935\n",
      "Epoch 518/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 871120.3750 - mean_squared_error: 871120.3750 - mean_absolute_error: 616.3114\n",
      "Epoch 00518: val_loss improved from 570912.56250 to 569739.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 717724.0956 - mean_squared_error: 717724.1250 - mean_absolute_error: 599.9794 - val_loss: 569739.6875 - val_mean_squared_error: 569739.6875 - val_mean_absolute_error: 670.7924\n",
      "Epoch 519/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1099723.0000 - mean_squared_error: 1099723.0000 - mean_absolute_error: 707.2754\n",
      "Epoch 00519: val_loss improved from 569739.68750 to 568566.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 716747.8382 - mean_squared_error: 716747.8125 - mean_absolute_error: 599.6859 - val_loss: 568566.3750 - val_mean_squared_error: 568566.3750 - val_mean_absolute_error: 669.9926\n",
      "Epoch 520/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1102215.5000 - mean_squared_error: 1102215.5000 - mean_absolute_error: 698.3411\n",
      "Epoch 00520: val_loss improved from 568566.37500 to 567394.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 715587.5074 - mean_squared_error: 715587.5000 - mean_absolute_error: 599.2622 - val_loss: 567394.0000 - val_mean_squared_error: 567394.0000 - val_mean_absolute_error: 669.1892\n",
      "Epoch 521/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 336630.6562 - mean_squared_error: 336630.6562 - mean_absolute_error: 474.9960\n",
      "Epoch 00521: val_loss improved from 567394.00000 to 566164.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 714400.2941 - mean_squared_error: 714400.3125 - mean_absolute_error: 598.9364 - val_loss: 566164.7500 - val_mean_squared_error: 566164.7500 - val_mean_absolute_error: 668.3550\n",
      "Epoch 522/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 572985.2500 - mean_squared_error: 572985.2500 - mean_absolute_error: 521.3477\n",
      "Epoch 00522: val_loss improved from 566164.75000 to 564892.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 713287.1250 - mean_squared_error: 713287.1250 - mean_absolute_error: 598.5787 - val_loss: 564892.8125 - val_mean_squared_error: 564892.8125 - val_mean_absolute_error: 667.4900\n",
      "Epoch 523/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 610254.5000 - mean_squared_error: 610254.5000 - mean_absolute_error: 599.7361\n",
      "Epoch 00523: val_loss improved from 564892.81250 to 563633.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 712184.0551 - mean_squared_error: 712184.0625 - mean_absolute_error: 598.2603 - val_loss: 563633.5625 - val_mean_squared_error: 563633.5625 - val_mean_absolute_error: 666.6204\n",
      "Epoch 524/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 630282.8750 - mean_squared_error: 630282.8750 - mean_absolute_error: 591.0288\n",
      "Epoch 00524: val_loss improved from 563633.56250 to 562455.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 711124.8162 - mean_squared_error: 711124.8125 - mean_absolute_error: 597.9503 - val_loss: 562455.6875 - val_mean_squared_error: 562455.6875 - val_mean_absolute_error: 665.7977\n",
      "Epoch 525/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 391442.5000 - mean_squared_error: 391442.5000 - mean_absolute_error: 505.6852\n",
      "Epoch 00525: val_loss improved from 562455.68750 to 561367.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 709991.3713 - mean_squared_error: 709991.3750 - mean_absolute_error: 597.5748 - val_loss: 561367.3125 - val_mean_squared_error: 561367.3125 - val_mean_absolute_error: 665.0286\n",
      "Epoch 526/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 853357.8750 - mean_squared_error: 853357.8750 - mean_absolute_error: 653.4416\n",
      "Epoch 00526: val_loss improved from 561367.31250 to 560169.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 709066.5993 - mean_squared_error: 709066.5625 - mean_absolute_error: 597.2421 - val_loss: 560169.2500 - val_mean_squared_error: 560169.2500 - val_mean_absolute_error: 664.1907\n",
      "Epoch 527/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 867610.3125 - mean_squared_error: 867610.3125 - mean_absolute_error: 625.5138\n",
      "Epoch 00527: val_loss improved from 560169.25000 to 558962.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 707978.3419 - mean_squared_error: 707978.3125 - mean_absolute_error: 596.8855 - val_loss: 558962.2500 - val_mean_squared_error: 558962.2500 - val_mean_absolute_error: 663.3537\n",
      "Epoch 528/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 881310.2500 - mean_squared_error: 881310.2500 - mean_absolute_error: 677.9481\n",
      "Epoch 00528: val_loss improved from 558962.25000 to 557871.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 706926.6020 - mean_squared_error: 706926.5625 - mean_absolute_error: 596.5726 - val_loss: 557871.1250 - val_mean_squared_error: 557871.1250 - val_mean_absolute_error: 662.5827\n",
      "Epoch 529/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 662924.8750 - mean_squared_error: 662924.8750 - mean_absolute_error: 578.0251\n",
      "Epoch 00529: val_loss improved from 557871.12500 to 556804.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 705862.0184 - mean_squared_error: 705862.0625 - mean_absolute_error: 596.2364 - val_loss: 556804.9375 - val_mean_squared_error: 556804.9375 - val_mean_absolute_error: 661.8177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 836382.0000 - mean_squared_error: 836382.0000 - mean_absolute_error: 660.6025\n",
      "Epoch 00530: val_loss improved from 556804.93750 to 555711.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 704980.7436 - mean_squared_error: 704980.7500 - mean_absolute_error: 595.9412 - val_loss: 555711.8750 - val_mean_squared_error: 555711.8750 - val_mean_absolute_error: 661.0251\n",
      "Epoch 531/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 670836.6875 - mean_squared_error: 670836.6875 - mean_absolute_error: 548.4565\n",
      "Epoch 00531: val_loss improved from 555711.87500 to 554755.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 703851.9540 - mean_squared_error: 703852.0000 - mean_absolute_error: 595.5049 - val_loss: 554755.9375 - val_mean_squared_error: 554755.9375 - val_mean_absolute_error: 660.4750\n",
      "Epoch 532/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 812951.8125 - mean_squared_error: 812951.8125 - mean_absolute_error: 607.9906\n",
      "Epoch 00532: val_loss improved from 554755.93750 to 553831.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 702954.8222 - mean_squared_error: 702954.8125 - mean_absolute_error: 595.1108 - val_loss: 553831.3750 - val_mean_squared_error: 553831.3750 - val_mean_absolute_error: 659.9294\n",
      "Epoch 533/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 658193.9375 - mean_squared_error: 658193.9375 - mean_absolute_error: 580.3022\n",
      "Epoch 00533: val_loss improved from 553831.37500 to 552892.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 702000.4779 - mean_squared_error: 702000.5000 - mean_absolute_error: 594.6940 - val_loss: 552892.2500 - val_mean_squared_error: 552892.2500 - val_mean_absolute_error: 659.3835\n",
      "Epoch 534/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 501085.0000 - mean_squared_error: 501085.0000 - mean_absolute_error: 517.0047\n",
      "Epoch 00534: val_loss improved from 552892.25000 to 551862.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 701064.8851 - mean_squared_error: 701064.8750 - mean_absolute_error: 594.3403 - val_loss: 551862.0625 - val_mean_squared_error: 551862.0625 - val_mean_absolute_error: 658.8126\n",
      "Epoch 535/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 673566.7500 - mean_squared_error: 673566.7500 - mean_absolute_error: 612.8666\n",
      "Epoch 00535: val_loss improved from 551862.06250 to 550929.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 700103.8658 - mean_squared_error: 700103.8750 - mean_absolute_error: 593.9081 - val_loss: 550929.2500 - val_mean_squared_error: 550929.2500 - val_mean_absolute_error: 658.2708\n",
      "Epoch 536/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 723559.0000 - mean_squared_error: 723559.0000 - mean_absolute_error: 573.9611\n",
      "Epoch 00536: val_loss improved from 550929.25000 to 549977.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 699206.4187 - mean_squared_error: 699206.4375 - mean_absolute_error: 593.5281 - val_loss: 549977.3125 - val_mean_squared_error: 549977.3125 - val_mean_absolute_error: 657.7405\n",
      "Epoch 537/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 591153.0000 - mean_squared_error: 591153.0000 - mean_absolute_error: 568.0573\n",
      "Epoch 00537: val_loss improved from 549977.31250 to 549125.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 698255.8346 - mean_squared_error: 698255.8750 - mean_absolute_error: 593.1667 - val_loss: 549125.6875 - val_mean_squared_error: 549125.6875 - val_mean_absolute_error: 657.2271\n",
      "Epoch 538/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 533940.0000 - mean_squared_error: 533940.0000 - mean_absolute_error: 545.5156\n",
      "Epoch 00538: val_loss improved from 549125.68750 to 548238.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 697379.4485 - mean_squared_error: 697379.5000 - mean_absolute_error: 592.7603 - val_loss: 548238.7500 - val_mean_squared_error: 548238.7500 - val_mean_absolute_error: 656.6985\n",
      "Epoch 539/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1054223.5000 - mean_squared_error: 1054223.5000 - mean_absolute_error: 714.9731\n",
      "Epoch 00539: val_loss improved from 548238.75000 to 547173.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 696515.1176 - mean_squared_error: 696515.0625 - mean_absolute_error: 592.3654 - val_loss: 547173.7500 - val_mean_squared_error: 547173.7500 - val_mean_absolute_error: 656.1342\n",
      "Epoch 540/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 694773.0000 - mean_squared_error: 694773.0000 - mean_absolute_error: 611.8992\n",
      "Epoch 00540: val_loss improved from 547173.75000 to 546020.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 695549.5993 - mean_squared_error: 695549.5625 - mean_absolute_error: 592.0660 - val_loss: 546020.5625 - val_mean_squared_error: 546020.5625 - val_mean_absolute_error: 655.5350\n",
      "Epoch 541/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 837002.1875 - mean_squared_error: 837002.1875 - mean_absolute_error: 663.4202\n",
      "Epoch 00541: val_loss improved from 546020.56250 to 544938.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 694479.9265 - mean_squared_error: 694479.8750 - mean_absolute_error: 591.7010 - val_loss: 544938.1875 - val_mean_squared_error: 544938.1875 - val_mean_absolute_error: 654.9433\n",
      "Epoch 542/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 356227.5625 - mean_squared_error: 356227.5625 - mean_absolute_error: 486.9349\n",
      "Epoch 00542: val_loss improved from 544938.18750 to 543889.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 693399.2721 - mean_squared_error: 693399.3125 - mean_absolute_error: 591.3391 - val_loss: 543889.3750 - val_mean_squared_error: 543889.3750 - val_mean_absolute_error: 654.3766\n",
      "Epoch 543/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 667920.6250 - mean_squared_error: 667920.6250 - mean_absolute_error: 600.5195\n",
      "Epoch 00543: val_loss improved from 543889.37500 to 542753.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 692534.3382 - mean_squared_error: 692534.3750 - mean_absolute_error: 591.1045 - val_loss: 542753.5625 - val_mean_squared_error: 542753.5625 - val_mean_absolute_error: 653.7708\n",
      "Epoch 544/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 577177.8125 - mean_squared_error: 577177.8125 - mean_absolute_error: 551.0816\n",
      "Epoch 00544: val_loss improved from 542753.56250 to 541626.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 691445.8686 - mean_squared_error: 691445.8750 - mean_absolute_error: 590.7113 - val_loss: 541626.6875 - val_mean_squared_error: 541626.6875 - val_mean_absolute_error: 653.1371\n",
      "Epoch 545/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 518346.4062 - mean_squared_error: 518346.4062 - mean_absolute_error: 516.9229\n",
      "Epoch 00545: val_loss improved from 541626.68750 to 540683.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 690403.3015 - mean_squared_error: 690403.3125 - mean_absolute_error: 590.2912 - val_loss: 540683.7500 - val_mean_squared_error: 540683.7500 - val_mean_absolute_error: 652.5555\n",
      "Epoch 546/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 520746.3750 - mean_squared_error: 520746.3750 - mean_absolute_error: 529.5100\n",
      "Epoch 00546: val_loss improved from 540683.75000 to 539805.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 689415.7279 - mean_squared_error: 689415.6875 - mean_absolute_error: 589.8267 - val_loss: 539805.5625 - val_mean_squared_error: 539805.5625 - val_mean_absolute_error: 651.9999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 547/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 424792.1875 - mean_squared_error: 424792.1875 - mean_absolute_error: 471.7451\n",
      "Epoch 00547: val_loss improved from 539805.56250 to 538881.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 688460.8897 - mean_squared_error: 688460.8750 - mean_absolute_error: 589.3937 - val_loss: 538881.1250 - val_mean_squared_error: 538881.1250 - val_mean_absolute_error: 651.4258\n",
      "Epoch 548/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 808382.3750 - mean_squared_error: 808382.3750 - mean_absolute_error: 674.3315\n",
      "Epoch 00548: val_loss improved from 538881.12500 to 537810.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 687597.5487 - mean_squared_error: 687597.5000 - mean_absolute_error: 589.0323 - val_loss: 537810.2500 - val_mean_squared_error: 537810.2500 - val_mean_absolute_error: 650.7972\n",
      "Epoch 549/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 839620.2500 - mean_squared_error: 839620.2500 - mean_absolute_error: 624.4615\n",
      "Epoch 00549: val_loss improved from 537810.25000 to 536870.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 686571.7224 - mean_squared_error: 686571.6875 - mean_absolute_error: 588.6497 - val_loss: 536870.8750 - val_mean_squared_error: 536870.8750 - val_mean_absolute_error: 650.2212\n",
      "Epoch 550/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 357672.0000 - mean_squared_error: 357672.0000 - mean_absolute_error: 507.4927\n",
      "Epoch 00550: val_loss improved from 536870.87500 to 536012.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 685521.2647 - mean_squared_error: 685521.2500 - mean_absolute_error: 588.2113 - val_loss: 536012.3125 - val_mean_squared_error: 536012.3125 - val_mean_absolute_error: 649.6641\n",
      "Epoch 551/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 678186.2500 - mean_squared_error: 678186.2500 - mean_absolute_error: 591.9559\n",
      "Epoch 00551: val_loss improved from 536012.31250 to 535001.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 684587.7592 - mean_squared_error: 684587.6875 - mean_absolute_error: 587.7634 - val_loss: 535001.6250 - val_mean_squared_error: 535001.6250 - val_mean_absolute_error: 649.0384\n",
      "Epoch 552/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 830395.7500 - mean_squared_error: 830395.7500 - mean_absolute_error: 668.9264\n",
      "Epoch 00552: val_loss improved from 535001.62500 to 533887.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 683586.0441 - mean_squared_error: 683586.0000 - mean_absolute_error: 587.3347 - val_loss: 533887.6250 - val_mean_squared_error: 533887.6250 - val_mean_absolute_error: 648.3736\n",
      "Epoch 553/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 646680.3125 - mean_squared_error: 646680.3125 - mean_absolute_error: 603.4225\n",
      "Epoch 00553: val_loss improved from 533887.62500 to 532666.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 682474.8998 - mean_squared_error: 682474.8750 - mean_absolute_error: 586.9341 - val_loss: 532666.1875 - val_mean_squared_error: 532666.1875 - val_mean_absolute_error: 647.6848\n",
      "Epoch 554/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 412463.0312 - mean_squared_error: 412463.0312 - mean_absolute_error: 511.3126\n",
      "Epoch 00554: val_loss improved from 532666.18750 to 531644.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 681296.7004 - mean_squared_error: 681296.6875 - mean_absolute_error: 586.5466 - val_loss: 531644.0625 - val_mean_squared_error: 531644.0625 - val_mean_absolute_error: 647.0702\n",
      "Epoch 555/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 501835.6250 - mean_squared_error: 501835.6250 - mean_absolute_error: 490.8518\n",
      "Epoch 00555: val_loss improved from 531644.06250 to 530693.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 680286.7390 - mean_squared_error: 680286.7500 - mean_absolute_error: 586.1402 - val_loss: 530693.0625 - val_mean_squared_error: 530693.0625 - val_mean_absolute_error: 646.4917\n",
      "Epoch 556/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582242.7500 - mean_squared_error: 582242.7500 - mean_absolute_error: 594.3920\n",
      "Epoch 00556: val_loss improved from 530693.06250 to 529683.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 679337.7647 - mean_squared_error: 679337.7500 - mean_absolute_error: 585.8110 - val_loss: 529683.8750 - val_mean_squared_error: 529683.8750 - val_mean_absolute_error: 645.8845\n",
      "Epoch 557/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 400637.5312 - mean_squared_error: 400637.5312 - mean_absolute_error: 538.3894\n",
      "Epoch 00557: val_loss improved from 529683.87500 to 528626.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 678331.2509 - mean_squared_error: 678331.3125 - mean_absolute_error: 585.4195 - val_loss: 528626.1250 - val_mean_squared_error: 528626.1250 - val_mean_absolute_error: 645.2545\n",
      "Epoch 558/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 347030.8125 - mean_squared_error: 347030.8125 - mean_absolute_error: 486.3521\n",
      "Epoch 00558: val_loss improved from 528626.12500 to 527540.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 677245.2647 - mean_squared_error: 677245.3125 - mean_absolute_error: 585.0054 - val_loss: 527540.4375 - val_mean_squared_error: 527540.4375 - val_mean_absolute_error: 644.6211\n",
      "Epoch 559/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 356917.0312 - mean_squared_error: 356917.0312 - mean_absolute_error: 471.1813\n",
      "Epoch 00559: val_loss improved from 527540.43750 to 526206.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 676174.4026 - mean_squared_error: 676174.4375 - mean_absolute_error: 584.7177 - val_loss: 526206.3125 - val_mean_squared_error: 526206.3125 - val_mean_absolute_error: 643.8951\n",
      "Epoch 560/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 341013.4375 - mean_squared_error: 341013.4375 - mean_absolute_error: 480.0973\n",
      "Epoch 00560: val_loss improved from 526206.31250 to 524862.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 674921.9485 - mean_squared_error: 674921.9375 - mean_absolute_error: 584.3581 - val_loss: 524862.1250 - val_mean_squared_error: 524862.1250 - val_mean_absolute_error: 643.1587\n",
      "Epoch 561/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 575854.1250 - mean_squared_error: 575854.1250 - mean_absolute_error: 511.4418\n",
      "Epoch 00561: val_loss improved from 524862.12500 to 523359.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 673818.1618 - mean_squared_error: 673818.1875 - mean_absolute_error: 584.1835 - val_loss: 523359.5625 - val_mean_squared_error: 523359.5625 - val_mean_absolute_error: 642.3567\n",
      "Epoch 562/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 461034.5000 - mean_squared_error: 461034.5000 - mean_absolute_error: 566.9391\n",
      "Epoch 00562: val_loss improved from 523359.56250 to 521890.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 672629.5533 - mean_squared_error: 672629.5000 - mean_absolute_error: 584.0128 - val_loss: 521890.2812 - val_mean_squared_error: 521890.2812 - val_mean_absolute_error: 641.5474\n",
      "Epoch 563/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 1069183.7500 - mean_squared_error: 1069183.7500 - mean_absolute_error: 718.1887\n",
      "Epoch 00563: val_loss improved from 521890.28125 to 520688.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 671454.7362 - mean_squared_error: 671454.6875 - mean_absolute_error: 583.7046 - val_loss: 520688.2812 - val_mean_squared_error: 520688.2812 - val_mean_absolute_error: 640.8258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 564/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 524152.1250 - mean_squared_error: 524152.1250 - mean_absolute_error: 504.5197\n",
      "Epoch 00564: val_loss improved from 520688.28125 to 519625.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 670107.2721 - mean_squared_error: 670107.3125 - mean_absolute_error: 583.2036 - val_loss: 519625.1562 - val_mean_squared_error: 519625.1562 - val_mean_absolute_error: 640.1589\n",
      "Epoch 565/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 934661.2500 - mean_squared_error: 934661.2500 - mean_absolute_error: 687.6134\n",
      "Epoch 00565: val_loss improved from 519625.15625 to 518528.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 669225.3143 - mean_squared_error: 669225.3125 - mean_absolute_error: 582.8795 - val_loss: 518528.3438 - val_mean_squared_error: 518528.3438 - val_mean_absolute_error: 639.4700\n",
      "Epoch 566/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 891517.0000 - mean_squared_error: 891517.0000 - mean_absolute_error: 643.5059\n",
      "Epoch 00566: val_loss improved from 518528.34375 to 517637.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 668034.3575 - mean_squared_error: 668034.3750 - mean_absolute_error: 582.3571 - val_loss: 517637.4375 - val_mean_squared_error: 517637.4375 - val_mean_absolute_error: 638.8603\n",
      "Epoch 567/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 623723.6250 - mean_squared_error: 623723.6250 - mean_absolute_error: 571.2522\n",
      "Epoch 00567: val_loss improved from 517637.43750 to 516775.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 667048.7831 - mean_squared_error: 667048.7500 - mean_absolute_error: 581.8692 - val_loss: 516775.7812 - val_mean_squared_error: 516775.7812 - val_mean_absolute_error: 638.2755\n",
      "Epoch 568/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 854284.9375 - mean_squared_error: 854284.9375 - mean_absolute_error: 650.4762\n",
      "Epoch 00568: val_loss improved from 516775.78125 to 515872.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 666144.9182 - mean_squared_error: 666144.9375 - mean_absolute_error: 581.3998 - val_loss: 515872.8438 - val_mean_squared_error: 515872.8438 - val_mean_absolute_error: 637.6870\n",
      "Epoch 569/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 412408.4062 - mean_squared_error: 412408.4062 - mean_absolute_error: 538.0431\n",
      "Epoch 00569: val_loss improved from 515872.84375 to 514967.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 665123.6544 - mean_squared_error: 665123.6250 - mean_absolute_error: 580.9646 - val_loss: 514967.4375 - val_mean_squared_error: 514967.4375 - val_mean_absolute_error: 637.1092\n",
      "Epoch 570/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 337969.6250 - mean_squared_error: 337969.6250 - mean_absolute_error: 451.2877\n",
      "Epoch 00570: val_loss improved from 514967.43750 to 514008.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 664164.7794 - mean_squared_error: 664164.7500 - mean_absolute_error: 580.5839 - val_loss: 514008.8750 - val_mean_squared_error: 514008.8750 - val_mean_absolute_error: 636.5007\n",
      "Epoch 571/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 725943.6250 - mean_squared_error: 725943.6250 - mean_absolute_error: 589.7245\n",
      "Epoch 00571: val_loss improved from 514008.87500 to 513039.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 663252.6507 - mean_squared_error: 663252.6250 - mean_absolute_error: 580.1784 - val_loss: 513039.6562 - val_mean_squared_error: 513039.6562 - val_mean_absolute_error: 635.8754\n",
      "Epoch 572/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 490592.6250 - mean_squared_error: 490592.6250 - mean_absolute_error: 508.0371\n",
      "Epoch 00572: val_loss improved from 513039.65625 to 511928.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 662193.8925 - mean_squared_error: 662193.8750 - mean_absolute_error: 579.7549 - val_loss: 511928.7188 - val_mean_squared_error: 511928.7188 - val_mean_absolute_error: 635.2021\n",
      "Epoch 573/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 446020.7812 - mean_squared_error: 446020.7812 - mean_absolute_error: 452.3041\n",
      "Epoch 00573: val_loss improved from 511928.71875 to 510830.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 661138.3713 - mean_squared_error: 661138.4375 - mean_absolute_error: 579.5443 - val_loss: 510830.3438 - val_mean_squared_error: 510830.3438 - val_mean_absolute_error: 634.5452\n",
      "Epoch 574/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582593.8750 - mean_squared_error: 582593.8750 - mean_absolute_error: 545.5863\n",
      "Epoch 00574: val_loss improved from 510830.34375 to 509735.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 660195.5928 - mean_squared_error: 660195.5625 - mean_absolute_error: 579.3568 - val_loss: 509735.5625 - val_mean_squared_error: 509735.5625 - val_mean_absolute_error: 633.8762\n",
      "Epoch 575/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 583029.5625 - mean_squared_error: 583029.5625 - mean_absolute_error: 531.2612\n",
      "Epoch 00575: val_loss improved from 509735.56250 to 508781.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 659109.6057 - mean_squared_error: 659109.5625 - mean_absolute_error: 579.0422 - val_loss: 508781.6562 - val_mean_squared_error: 508781.6562 - val_mean_absolute_error: 633.2630\n",
      "Epoch 576/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 753858.5000 - mean_squared_error: 753858.5000 - mean_absolute_error: 589.1240\n",
      "Epoch 00576: val_loss improved from 508781.65625 to 507898.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 658241.8713 - mean_squared_error: 658241.8750 - mean_absolute_error: 578.7318 - val_loss: 507898.4375 - val_mean_squared_error: 507898.4375 - val_mean_absolute_error: 632.6775\n",
      "Epoch 577/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 579292.0000 - mean_squared_error: 579292.0000 - mean_absolute_error: 535.4443\n",
      "Epoch 00577: val_loss improved from 507898.43750 to 507118.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 657277.6452 - mean_squared_error: 657277.6250 - mean_absolute_error: 578.3422 - val_loss: 507118.8750 - val_mean_squared_error: 507118.8750 - val_mean_absolute_error: 632.1279\n",
      "Epoch 578/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 401375.7188 - mean_squared_error: 401375.7188 - mean_absolute_error: 503.1737\n",
      "Epoch 00578: val_loss improved from 507118.87500 to 506424.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 656390.7978 - mean_squared_error: 656390.8125 - mean_absolute_error: 577.8745 - val_loss: 506424.6562 - val_mean_squared_error: 506424.6562 - val_mean_absolute_error: 631.6039\n",
      "Epoch 579/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 754307.3125 - mean_squared_error: 754307.3125 - mean_absolute_error: 576.9415\n",
      "Epoch 00579: val_loss improved from 506424.65625 to 505780.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 655523.2426 - mean_squared_error: 655523.2500 - mean_absolute_error: 577.3402 - val_loss: 505780.3750 - val_mean_squared_error: 505780.3750 - val_mean_absolute_error: 631.0803\n",
      "Epoch 580/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 555932.3750 - mean_squared_error: 555932.3750 - mean_absolute_error: 580.9280\n",
      "Epoch 00580: val_loss improved from 505780.37500 to 505037.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 654656.2206 - mean_squared_error: 654656.2500 - mean_absolute_error: 576.6807 - val_loss: 505037.8438 - val_mean_squared_error: 505037.8438 - val_mean_absolute_error: 630.4946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 581/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 424481.2188 - mean_squared_error: 424481.2188 - mean_absolute_error: 520.5878\n",
      "Epoch 00581: val_loss improved from 505037.84375 to 504090.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 653697.4890 - mean_squared_error: 653697.5000 - mean_absolute_error: 576.0945 - val_loss: 504090.7812 - val_mean_squared_error: 504090.7812 - val_mean_absolute_error: 629.8176\n",
      "Epoch 582/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 712769.6250 - mean_squared_error: 712769.6250 - mean_absolute_error: 592.0403\n",
      "Epoch 00582: val_loss improved from 504090.78125 to 503032.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 652662.7206 - mean_squared_error: 652662.6875 - mean_absolute_error: 575.5500 - val_loss: 503032.3438 - val_mean_squared_error: 503032.3438 - val_mean_absolute_error: 629.1077\n",
      "Epoch 583/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 911045.1250 - mean_squared_error: 911045.1250 - mean_absolute_error: 613.3402\n",
      "Epoch 00583: val_loss improved from 503032.34375 to 501842.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 651617.9835 - mean_squared_error: 651618.0000 - mean_absolute_error: 575.1771 - val_loss: 501842.6562 - val_mean_squared_error: 501842.6562 - val_mean_absolute_error: 628.3541\n",
      "Epoch 584/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 614091.1875 - mean_squared_error: 614091.1875 - mean_absolute_error: 568.4222\n",
      "Epoch 00584: val_loss improved from 501842.65625 to 500696.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 650339.4412 - mean_squared_error: 650339.5000 - mean_absolute_error: 574.7810 - val_loss: 500696.1250 - val_mean_squared_error: 500696.1250 - val_mean_absolute_error: 627.6133\n",
      "Epoch 585/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 313181.8438 - mean_squared_error: 313181.8438 - mean_absolute_error: 469.4540\n",
      "Epoch 00585: val_loss improved from 500696.12500 to 499423.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 649119.1654 - mean_squared_error: 649119.1875 - mean_absolute_error: 574.4166 - val_loss: 499423.5625 - val_mean_squared_error: 499423.5625 - val_mean_absolute_error: 626.8191\n",
      "Epoch 586/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 885724.0625 - mean_squared_error: 885724.0625 - mean_absolute_error: 658.0778\n",
      "Epoch 00586: val_loss improved from 499423.56250 to 498264.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 648124.3153 - mean_squared_error: 648124.3125 - mean_absolute_error: 574.1657 - val_loss: 498264.7812 - val_mean_squared_error: 498264.7812 - val_mean_absolute_error: 626.0836\n",
      "Epoch 587/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 567593.9375 - mean_squared_error: 567593.9375 - mean_absolute_error: 562.6957\n",
      "Epoch 00587: val_loss improved from 498264.78125 to 497311.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 646922.9660 - mean_squared_error: 646923.0000 - mean_absolute_error: 573.8138 - val_loss: 497311.9375 - val_mean_squared_error: 497311.9375 - val_mean_absolute_error: 625.4311\n",
      "Epoch 588/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 804871.3750 - mean_squared_error: 804871.3750 - mean_absolute_error: 617.1096\n",
      "Epoch 00588: val_loss improved from 497311.93750 to 496447.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 645952.0809 - mean_squared_error: 645952.0625 - mean_absolute_error: 573.3839 - val_loss: 496447.2188 - val_mean_squared_error: 496447.2188 - val_mean_absolute_error: 624.8209\n",
      "Epoch 589/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 523715.5625 - mean_squared_error: 523715.5625 - mean_absolute_error: 554.6752\n",
      "Epoch 00589: val_loss improved from 496447.21875 to 495565.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 644940.1324 - mean_squared_error: 644940.1250 - mean_absolute_error: 572.9127 - val_loss: 495565.8750 - val_mean_squared_error: 495565.8750 - val_mean_absolute_error: 624.2063\n",
      "Epoch 590/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 709512.7500 - mean_squared_error: 709512.7500 - mean_absolute_error: 602.0314\n",
      "Epoch 00590: val_loss improved from 495565.87500 to 494621.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 644043.8658 - mean_squared_error: 644043.8750 - mean_absolute_error: 572.5220 - val_loss: 494621.0000 - val_mean_squared_error: 494621.0000 - val_mean_absolute_error: 623.5581\n",
      "Epoch 591/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 674096.9375 - mean_squared_error: 674096.9375 - mean_absolute_error: 541.2234\n",
      "Epoch 00591: val_loss improved from 494621.00000 to 493811.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 643019.6535 - mean_squared_error: 643019.6250 - mean_absolute_error: 572.0729 - val_loss: 493811.6250 - val_mean_squared_error: 493811.6250 - val_mean_absolute_error: 622.9637\n",
      "Epoch 592/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 473378.3125 - mean_squared_error: 473378.3125 - mean_absolute_error: 484.0962\n",
      "Epoch 00592: val_loss improved from 493811.62500 to 493041.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 642106.5368 - mean_squared_error: 642106.5000 - mean_absolute_error: 571.5687 - val_loss: 493041.1250 - val_mean_squared_error: 493041.1250 - val_mean_absolute_error: 622.3880\n",
      "Epoch 593/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 273548.3750 - mean_squared_error: 273548.3750 - mean_absolute_error: 433.7462\n",
      "Epoch 00593: val_loss improved from 493041.12500 to 492168.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 641137.2633 - mean_squared_error: 641137.2500 - mean_absolute_error: 571.0887 - val_loss: 492168.8438 - val_mean_squared_error: 492168.8438 - val_mean_absolute_error: 621.7786\n",
      "Epoch 594/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 437012.0625 - mean_squared_error: 437012.0625 - mean_absolute_error: 492.4219\n",
      "Epoch 00594: val_loss improved from 492168.84375 to 491256.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 640196.9191 - mean_squared_error: 640196.9375 - mean_absolute_error: 570.6550 - val_loss: 491256.3438 - val_mean_squared_error: 491256.3438 - val_mean_absolute_error: 621.1516\n",
      "Epoch 595/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 862680.7500 - mean_squared_error: 862680.7500 - mean_absolute_error: 660.8591\n",
      "Epoch 00595: val_loss improved from 491256.34375 to 490229.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 639365.6688 - mean_squared_error: 639365.6250 - mean_absolute_error: 570.3669 - val_loss: 490229.1562 - val_mean_squared_error: 490229.1562 - val_mean_absolute_error: 620.4691\n",
      "Epoch 596/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 369225.8125 - mean_squared_error: 369225.8125 - mean_absolute_error: 470.2017\n",
      "Epoch 00596: val_loss improved from 490229.15625 to 489364.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 638252.7096 - mean_squared_error: 638252.6875 - mean_absolute_error: 569.9672 - val_loss: 489364.6562 - val_mean_squared_error: 489364.6562 - val_mean_absolute_error: 619.8626\n",
      "Epoch 597/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 534328.3750 - mean_squared_error: 534328.3750 - mean_absolute_error: 548.2985\n",
      "Epoch 00597: val_loss improved from 489364.65625 to 488546.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 637330.5882 - mean_squared_error: 637330.5625 - mean_absolute_error: 569.5328 - val_loss: 488546.1562 - val_mean_squared_error: 488546.1562 - val_mean_absolute_error: 619.2580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 598/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 239520.8438 - mean_squared_error: 239520.8438 - mean_absolute_error: 421.6886\n",
      "Epoch 00598: val_loss improved from 488546.15625 to 487596.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 636296.4926 - mean_squared_error: 636296.5000 - mean_absolute_error: 569.0180 - val_loss: 487596.3750 - val_mean_squared_error: 487596.3750 - val_mean_absolute_error: 618.5931\n",
      "Epoch 599/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 492559.6250 - mean_squared_error: 492559.6250 - mean_absolute_error: 501.8896\n",
      "Epoch 00599: val_loss improved from 487596.37500 to 486575.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 635360.3915 - mean_squared_error: 635360.4375 - mean_absolute_error: 568.6285 - val_loss: 486575.4375 - val_mean_squared_error: 486575.4375 - val_mean_absolute_error: 617.8909\n",
      "Epoch 600/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 606423.0000 - mean_squared_error: 606423.0000 - mean_absolute_error: 586.1367\n",
      "Epoch 00600: val_loss improved from 486575.43750 to 485639.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 634317.9118 - mean_squared_error: 634317.8750 - mean_absolute_error: 568.1961 - val_loss: 485639.1250 - val_mean_squared_error: 485639.1250 - val_mean_absolute_error: 617.2181\n",
      "Epoch 601/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 500000.1250 - mean_squared_error: 500000.1250 - mean_absolute_error: 500.1422\n",
      "Epoch 00601: val_loss improved from 485639.12500 to 484788.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 633289.3750 - mean_squared_error: 633289.4375 - mean_absolute_error: 567.7303 - val_loss: 484788.0000 - val_mean_squared_error: 484788.0000 - val_mean_absolute_error: 616.5818\n",
      "Epoch 602/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 351249.2188 - mean_squared_error: 351249.2188 - mean_absolute_error: 482.6378\n",
      "Epoch 00602: val_loss improved from 484788.00000 to 484044.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 632344.1342 - mean_squared_error: 632344.1875 - mean_absolute_error: 567.2213 - val_loss: 484044.8438 - val_mean_squared_error: 484044.8438 - val_mean_absolute_error: 615.9962\n",
      "Epoch 603/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 769612.0625 - mean_squared_error: 769612.0625 - mean_absolute_error: 642.0398\n",
      "Epoch 00603: val_loss improved from 484044.84375 to 483358.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 631477.5119 - mean_squared_error: 631477.5000 - mean_absolute_error: 566.6462 - val_loss: 483358.4375 - val_mean_squared_error: 483358.4375 - val_mean_absolute_error: 615.4481\n",
      "Epoch 604/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 302692.7500 - mean_squared_error: 302692.7500 - mean_absolute_error: 453.6155\n",
      "Epoch 00604: val_loss improved from 483358.43750 to 482702.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 630598.4954 - mean_squared_error: 630598.5000 - mean_absolute_error: 566.0419 - val_loss: 482702.5625 - val_mean_squared_error: 482702.5625 - val_mean_absolute_error: 614.9162\n",
      "Epoch 605/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 416215.7500 - mean_squared_error: 416215.7500 - mean_absolute_error: 444.9192\n",
      "Epoch 00605: val_loss improved from 482702.56250 to 482025.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 629757.6085 - mean_squared_error: 629757.5625 - mean_absolute_error: 565.4778 - val_loss: 482025.9375 - val_mean_squared_error: 482025.9375 - val_mean_absolute_error: 614.3741\n",
      "Epoch 606/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 721220.2500 - mean_squared_error: 721220.2500 - mean_absolute_error: 580.1146\n",
      "Epoch 00606: val_loss improved from 482025.93750 to 481349.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 628965.5074 - mean_squared_error: 628965.5000 - mean_absolute_error: 564.9833 - val_loss: 481349.6250 - val_mean_squared_error: 481349.6250 - val_mean_absolute_error: 613.8405\n",
      "Epoch 607/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 766414.8125 - mean_squared_error: 766414.8125 - mean_absolute_error: 647.5374\n",
      "Epoch 00607: val_loss improved from 481349.62500 to 480661.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 628167.8750 - mean_squared_error: 628167.8125 - mean_absolute_error: 564.4802 - val_loss: 480661.5625 - val_mean_squared_error: 480661.5625 - val_mean_absolute_error: 613.3105\n",
      "Epoch 608/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 623180.5000 - mean_squared_error: 623180.5000 - mean_absolute_error: 549.9571\n",
      "Epoch 00608: val_loss improved from 480661.56250 to 480003.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 627320.6379 - mean_squared_error: 627320.6250 - mean_absolute_error: 564.0035 - val_loss: 480003.2188 - val_mean_squared_error: 480003.2188 - val_mean_absolute_error: 612.7931\n",
      "Epoch 609/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 354900.5625 - mean_squared_error: 354900.5625 - mean_absolute_error: 470.1755\n",
      "Epoch 00609: val_loss improved from 480003.21875 to 479351.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 626507.1480 - mean_squared_error: 626507.1875 - mean_absolute_error: 563.5049 - val_loss: 479351.7188 - val_mean_squared_error: 479351.7188 - val_mean_absolute_error: 612.2703\n",
      "Epoch 610/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 642048.7500 - mean_squared_error: 642048.7500 - mean_absolute_error: 576.3457\n",
      "Epoch 00610: val_loss improved from 479351.71875 to 478653.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 625704.8309 - mean_squared_error: 625704.8125 - mean_absolute_error: 562.9837 - val_loss: 478653.8750 - val_mean_squared_error: 478653.8750 - val_mean_absolute_error: 611.7156\n",
      "Epoch 611/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 573149.3750 - mean_squared_error: 573149.3750 - mean_absolute_error: 535.0741\n",
      "Epoch 00611: val_loss improved from 478653.87500 to 477711.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 624791.6912 - mean_squared_error: 624791.6875 - mean_absolute_error: 562.4535 - val_loss: 477711.5625 - val_mean_squared_error: 477711.5625 - val_mean_absolute_error: 611.0385\n",
      "Epoch 612/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 992529.0000 - mean_squared_error: 992529.0000 - mean_absolute_error: 689.4521\n",
      "Epoch 00612: val_loss improved from 477711.56250 to 476588.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 623881.1985 - mean_squared_error: 623881.1875 - mean_absolute_error: 562.0425 - val_loss: 476588.6562 - val_mean_squared_error: 476588.6562 - val_mean_absolute_error: 610.2771\n",
      "Epoch 613/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 645154.5000 - mean_squared_error: 645154.5000 - mean_absolute_error: 607.7798\n",
      "Epoch 00613: val_loss improved from 476588.65625 to 475554.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 622736.4357 - mean_squared_error: 622736.4375 - mean_absolute_error: 561.7293 - val_loss: 475554.5625 - val_mean_squared_error: 475554.5625 - val_mean_absolute_error: 609.5736\n",
      "Epoch 614/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 513885.2812 - mean_squared_error: 513885.2812 - mean_absolute_error: 548.2462\n",
      "Epoch 00614: val_loss improved from 475554.56250 to 474537.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 621639.6618 - mean_squared_error: 621639.6250 - mean_absolute_error: 561.3744 - val_loss: 474537.1250 - val_mean_squared_error: 474537.1250 - val_mean_absolute_error: 608.8851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 615/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 747062.7500 - mean_squared_error: 747062.7500 - mean_absolute_error: 592.9325\n",
      "Epoch 00615: val_loss improved from 474537.12500 to 473388.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 620719.0046 - mean_squared_error: 620719.0000 - mean_absolute_error: 561.1900 - val_loss: 473388.6562 - val_mean_squared_error: 473388.6562 - val_mean_absolute_error: 608.1412\n",
      "Epoch 616/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 852143.6250 - mean_squared_error: 852143.6250 - mean_absolute_error: 633.5677\n",
      "Epoch 00616: val_loss improved from 473388.65625 to 472392.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 619722.5533 - mean_squared_error: 619722.5625 - mean_absolute_error: 561.0944 - val_loss: 472392.5625 - val_mean_squared_error: 472392.5625 - val_mean_absolute_error: 607.4554\n",
      "Epoch 617/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 273410.0000 - mean_squared_error: 273410.0000 - mean_absolute_error: 421.8499\n",
      "Epoch 00617: val_loss improved from 472392.56250 to 471599.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 618626.7279 - mean_squared_error: 618626.6875 - mean_absolute_error: 560.8029 - val_loss: 471599.1562 - val_mean_squared_error: 471599.1562 - val_mean_absolute_error: 606.8555\n",
      "Epoch 618/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 528833.8750 - mean_squared_error: 528833.8750 - mean_absolute_error: 505.7269\n",
      "Epoch 00618: val_loss improved from 471599.15625 to 470869.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 617773.6176 - mean_squared_error: 617773.6250 - mean_absolute_error: 560.3258 - val_loss: 470869.1250 - val_mean_squared_error: 470869.1250 - val_mean_absolute_error: 606.2829\n",
      "Epoch 619/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 691224.8125 - mean_squared_error: 691224.8125 - mean_absolute_error: 549.3135\n",
      "Epoch 00619: val_loss improved from 470869.12500 to 470104.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 616930.1039 - mean_squared_error: 616930.1250 - mean_absolute_error: 559.9253 - val_loss: 470104.7188 - val_mean_squared_error: 470104.7188 - val_mean_absolute_error: 605.7114\n",
      "Epoch 620/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 502021.3125 - mean_squared_error: 502021.3125 - mean_absolute_error: 512.0681\n",
      "Epoch 00620: val_loss improved from 470104.71875 to 469410.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 616086.5092 - mean_squared_error: 616086.5000 - mean_absolute_error: 559.5524 - val_loss: 469410.5625 - val_mean_squared_error: 469410.5625 - val_mean_absolute_error: 605.1769\n",
      "Epoch 621/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 929865.9375 - mean_squared_error: 929865.9375 - mean_absolute_error: 657.7139\n",
      "Epoch 00621: val_loss improved from 469410.56250 to 468718.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 615339.4191 - mean_squared_error: 615339.5000 - mean_absolute_error: 559.1658 - val_loss: 468718.8438 - val_mean_squared_error: 468718.8438 - val_mean_absolute_error: 604.6274\n",
      "Epoch 622/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 814019.4375 - mean_squared_error: 814019.4375 - mean_absolute_error: 664.5891\n",
      "Epoch 00622: val_loss improved from 468718.84375 to 467996.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 614500.7555 - mean_squared_error: 614500.6875 - mean_absolute_error: 558.6815 - val_loss: 467996.1250 - val_mean_squared_error: 467996.1250 - val_mean_absolute_error: 604.0557\n",
      "Epoch 623/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 505882.0000 - mean_squared_error: 505882.0000 - mean_absolute_error: 524.7541\n",
      "Epoch 00623: val_loss improved from 467996.12500 to 467199.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 613565.4706 - mean_squared_error: 613565.5000 - mean_absolute_error: 558.1805 - val_loss: 467199.8438 - val_mean_squared_error: 467199.8438 - val_mean_absolute_error: 603.4472\n",
      "Epoch 624/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 545764.9375 - mean_squared_error: 545764.9375 - mean_absolute_error: 539.3961\n",
      "Epoch 00624: val_loss improved from 467199.84375 to 466212.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 612713.5754 - mean_squared_error: 612713.5625 - mean_absolute_error: 557.8565 - val_loss: 466212.6250 - val_mean_squared_error: 466212.6250 - val_mean_absolute_error: 602.7401\n",
      "Epoch 625/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 538296.1250 - mean_squared_error: 538296.1250 - mean_absolute_error: 530.1038\n",
      "Epoch 00625: val_loss improved from 466212.62500 to 465258.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 611615.0147 - mean_squared_error: 611615.0000 - mean_absolute_error: 557.4714 - val_loss: 465258.0000 - val_mean_squared_error: 465258.0000 - val_mean_absolute_error: 602.0582\n",
      "Epoch 626/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 293960.8750 - mean_squared_error: 293960.8750 - mean_absolute_error: 448.0938\n",
      "Epoch 00626: val_loss improved from 465258.00000 to 464113.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 610534.4926 - mean_squared_error: 610534.5000 - mean_absolute_error: 557.1909 - val_loss: 464113.8438 - val_mean_squared_error: 464113.8438 - val_mean_absolute_error: 601.2788\n",
      "Epoch 627/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 762381.3750 - mean_squared_error: 762381.3750 - mean_absolute_error: 588.5504\n",
      "Epoch 00627: val_loss improved from 464113.84375 to 462824.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 609656.9430 - mean_squared_error: 609656.9375 - mean_absolute_error: 557.1299 - val_loss: 462824.3750 - val_mean_squared_error: 462824.3750 - val_mean_absolute_error: 600.4124\n",
      "Epoch 628/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 450680.5000 - mean_squared_error: 450680.5000 - mean_absolute_error: 489.5386\n",
      "Epoch 00628: val_loss improved from 462824.37500 to 461679.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 608363.4522 - mean_squared_error: 608363.4375 - mean_absolute_error: 556.9658 - val_loss: 461679.8750 - val_mean_squared_error: 461679.8750 - val_mean_absolute_error: 599.6088\n",
      "Epoch 629/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 498454.5938 - mean_squared_error: 498454.5938 - mean_absolute_error: 543.9750\n",
      "Epoch 00629: val_loss improved from 461679.87500 to 460646.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 607255.5239 - mean_squared_error: 607255.5000 - mean_absolute_error: 556.7185 - val_loss: 460646.0000 - val_mean_squared_error: 460646.0000 - val_mean_absolute_error: 598.8608\n",
      "Epoch 630/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 385352.4375 - mean_squared_error: 385352.4375 - mean_absolute_error: 456.0819\n",
      "Epoch 00630: val_loss improved from 460646.00000 to 459684.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 606215.2748 - mean_squared_error: 606215.3125 - mean_absolute_error: 556.4254 - val_loss: 459684.9375 - val_mean_squared_error: 459684.9375 - val_mean_absolute_error: 598.1567\n",
      "Epoch 631/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 544947.6250 - mean_squared_error: 544947.6250 - mean_absolute_error: 527.8243\n",
      "Epoch 00631: val_loss improved from 459684.93750 to 458836.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 605267.8667 - mean_squared_error: 605267.8750 - mean_absolute_error: 556.1090 - val_loss: 458836.3750 - val_mean_squared_error: 458836.3750 - val_mean_absolute_error: 597.5123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 632/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 379348.9375 - mean_squared_error: 379348.9375 - mean_absolute_error: 445.4030\n",
      "Epoch 00632: val_loss improved from 458836.37500 to 458014.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 604324.9099 - mean_squared_error: 604324.8750 - mean_absolute_error: 555.7522 - val_loss: 458014.4375 - val_mean_squared_error: 458014.4375 - val_mean_absolute_error: 596.8852\n",
      "Epoch 633/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 302970.0312 - mean_squared_error: 302970.0312 - mean_absolute_error: 470.4952\n",
      "Epoch 00633: val_loss improved from 458014.43750 to 457149.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 603424.9853 - mean_squared_error: 603424.9375 - mean_absolute_error: 555.4261 - val_loss: 457149.4688 - val_mean_squared_error: 457149.4688 - val_mean_absolute_error: 596.2231\n",
      "Epoch 634/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 706968.6250 - mean_squared_error: 706968.6250 - mean_absolute_error: 571.1177\n",
      "Epoch 00634: val_loss improved from 457149.46875 to 456245.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 602554.0221 - mean_squared_error: 602554.0000 - mean_absolute_error: 555.0471 - val_loss: 456245.7500 - val_mean_squared_error: 456245.7500 - val_mean_absolute_error: 595.5182\n",
      "Epoch 635/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 324991.8438 - mean_squared_error: 324991.8438 - mean_absolute_error: 474.5248\n",
      "Epoch 00635: val_loss improved from 456245.75000 to 455429.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 601506.3897 - mean_squared_error: 601506.4375 - mean_absolute_error: 554.5934 - val_loss: 455429.6250 - val_mean_squared_error: 455429.6250 - val_mean_absolute_error: 594.8722\n",
      "Epoch 636/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 661509.5000 - mean_squared_error: 661509.5000 - mean_absolute_error: 581.6727\n",
      "Epoch 00636: val_loss improved from 455429.62500 to 454702.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 600642.8217 - mean_squared_error: 600642.8125 - mean_absolute_error: 554.1389 - val_loss: 454702.0000 - val_mean_squared_error: 454702.0000 - val_mean_absolute_error: 594.2806\n",
      "Epoch 637/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 969343.8125 - mean_squared_error: 969343.8125 - mean_absolute_error: 685.5334\n",
      "Epoch 00637: val_loss improved from 454702.00000 to 454008.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 599813.5083 - mean_squared_error: 599813.5000 - mean_absolute_error: 553.6780 - val_loss: 454008.9688 - val_mean_squared_error: 454008.9688 - val_mean_absolute_error: 593.7126\n",
      "Epoch 638/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 736485.5000 - mean_squared_error: 736485.5000 - mean_absolute_error: 569.5318\n",
      "Epoch 00638: val_loss improved from 454008.96875 to 453358.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 598931.7279 - mean_squared_error: 598931.7500 - mean_absolute_error: 553.1752 - val_loss: 453358.0625 - val_mean_squared_error: 453358.0625 - val_mean_absolute_error: 593.1618\n",
      "Epoch 639/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 496540.1250 - mean_squared_error: 496540.1250 - mean_absolute_error: 544.3604\n",
      "Epoch 00639: val_loss improved from 453358.06250 to 452721.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 598085.5643 - mean_squared_error: 598085.5625 - mean_absolute_error: 552.6313 - val_loss: 452721.6250 - val_mean_squared_error: 452721.6250 - val_mean_absolute_error: 592.6047\n",
      "Epoch 640/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 804670.0000 - mean_squared_error: 804670.0000 - mean_absolute_error: 621.4775\n",
      "Epoch 00640: val_loss improved from 452721.62500 to 452052.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 597329.6241 - mean_squared_error: 597329.6250 - mean_absolute_error: 552.1055 - val_loss: 452052.3438 - val_mean_squared_error: 452052.3438 - val_mean_absolute_error: 592.0296\n",
      "Epoch 641/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 384348.6250 - mean_squared_error: 384348.6250 - mean_absolute_error: 517.9473\n",
      "Epoch 00641: val_loss improved from 452052.34375 to 451232.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 322us/sample - loss: 596396.0882 - mean_squared_error: 596396.1250 - mean_absolute_error: 551.5461 - val_loss: 451232.5312 - val_mean_squared_error: 451232.5312 - val_mean_absolute_error: 591.3849\n",
      "Epoch 642/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 494726.5625 - mean_squared_error: 494726.5625 - mean_absolute_error: 517.5920\n",
      "Epoch 00642: val_loss improved from 451232.53125 to 450167.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 595497.6847 - mean_squared_error: 595497.6875 - mean_absolute_error: 551.1887 - val_loss: 450167.0625 - val_mean_squared_error: 450167.0625 - val_mean_absolute_error: 590.5913\n",
      "Epoch 643/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 648782.6875 - mean_squared_error: 648782.6875 - mean_absolute_error: 591.9667\n",
      "Epoch 00643: val_loss improved from 450167.06250 to 449269.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 594427.4959 - mean_squared_error: 594427.5000 - mean_absolute_error: 550.8530 - val_loss: 449269.5312 - val_mean_squared_error: 449269.5312 - val_mean_absolute_error: 589.8931\n",
      "Epoch 644/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 706698.4375 - mean_squared_error: 706698.4375 - mean_absolute_error: 566.8453\n",
      "Epoch 00644: val_loss improved from 449269.53125 to 448376.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 593429.2353 - mean_squared_error: 593429.2500 - mean_absolute_error: 550.4785 - val_loss: 448376.1250 - val_mean_squared_error: 448376.1250 - val_mean_absolute_error: 589.1995\n",
      "Epoch 645/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582627.8750 - mean_squared_error: 582627.8750 - mean_absolute_error: 558.6713\n",
      "Epoch 00645: val_loss improved from 448376.12500 to 447403.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 592497.4256 - mean_squared_error: 592497.4375 - mean_absolute_error: 550.1627 - val_loss: 447403.6250 - val_mean_squared_error: 447403.6250 - val_mean_absolute_error: 588.4590\n",
      "Epoch 646/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 594442.5000 - mean_squared_error: 594442.5000 - mean_absolute_error: 578.6196\n",
      "Epoch 00646: val_loss improved from 447403.62500 to 446480.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 591487.2794 - mean_squared_error: 591487.3125 - mean_absolute_error: 549.8479 - val_loss: 446480.6250 - val_mean_squared_error: 446480.6250 - val_mean_absolute_error: 587.7470\n",
      "Epoch 647/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 839490.2500 - mean_squared_error: 839490.2500 - mean_absolute_error: 677.4684\n",
      "Epoch 00647: val_loss improved from 446480.62500 to 445526.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 590638.4835 - mean_squared_error: 590638.5000 - mean_absolute_error: 549.6149 - val_loss: 445526.7188 - val_mean_squared_error: 445526.7188 - val_mean_absolute_error: 587.0045\n",
      "Epoch 648/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 872284.3750 - mean_squared_error: 872284.3750 - mean_absolute_error: 692.5621\n",
      "Epoch 00648: val_loss improved from 445526.71875 to 444701.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 589578.8300 - mean_squared_error: 589578.8125 - mean_absolute_error: 549.1582 - val_loss: 444701.1250 - val_mean_squared_error: 444701.1250 - val_mean_absolute_error: 586.3337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 649/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 435859.9375 - mean_squared_error: 435859.9375 - mean_absolute_error: 497.3520\n",
      "Epoch 00649: val_loss improved from 444701.12500 to 443915.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 588583.6365 - mean_squared_error: 588583.5625 - mean_absolute_error: 548.7184 - val_loss: 443915.5000 - val_mean_squared_error: 443915.5000 - val_mean_absolute_error: 585.7014\n",
      "Epoch 650/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 557459.2500 - mean_squared_error: 557459.2500 - mean_absolute_error: 549.3083\n",
      "Epoch 00650: val_loss improved from 443915.50000 to 443179.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 587738.8768 - mean_squared_error: 587738.8750 - mean_absolute_error: 548.3419 - val_loss: 443179.5625 - val_mean_squared_error: 443179.5625 - val_mean_absolute_error: 585.0979\n",
      "Epoch 651/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 750648.0000 - mean_squared_error: 750648.0000 - mean_absolute_error: 587.9141\n",
      "Epoch 00651: val_loss improved from 443179.56250 to 442479.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 586904.2371 - mean_squared_error: 586904.3125 - mean_absolute_error: 547.9082 - val_loss: 442479.7188 - val_mean_squared_error: 442479.7188 - val_mean_absolute_error: 584.5157\n",
      "Epoch 652/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 389218.1250 - mean_squared_error: 389218.1250 - mean_absolute_error: 438.0039\n",
      "Epoch 00652: val_loss improved from 442479.71875 to 441818.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 586073.0625 - mean_squared_error: 586073.0625 - mean_absolute_error: 547.5054 - val_loss: 441818.5625 - val_mean_squared_error: 441818.5625 - val_mean_absolute_error: 583.9509\n",
      "Epoch 653/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 977874.6875 - mean_squared_error: 977874.6875 - mean_absolute_error: 690.4840\n",
      "Epoch 00653: val_loss improved from 441818.56250 to 441137.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 585341.3070 - mean_squared_error: 585341.3125 - mean_absolute_error: 547.0450 - val_loss: 441137.3438 - val_mean_squared_error: 441137.3438 - val_mean_absolute_error: 583.3708\n",
      "Epoch 654/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 707173.2500 - mean_squared_error: 707173.2500 - mean_absolute_error: 579.0958\n",
      "Epoch 00654: val_loss improved from 441137.34375 to 440486.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 584492.6875 - mean_squared_error: 584492.6250 - mean_absolute_error: 546.5405 - val_loss: 440486.7500 - val_mean_squared_error: 440486.7500 - val_mean_absolute_error: 582.8038\n",
      "Epoch 655/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 848271.6250 - mean_squared_error: 848271.6250 - mean_absolute_error: 607.0046\n",
      "Epoch 00655: val_loss improved from 440486.75000 to 439806.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 583675.2188 - mean_squared_error: 583675.2500 - mean_absolute_error: 546.0185 - val_loss: 439806.9375 - val_mean_squared_error: 439806.9375 - val_mean_absolute_error: 582.2273\n",
      "Epoch 656/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 472865.2812 - mean_squared_error: 472865.2812 - mean_absolute_error: 484.5787\n",
      "Epoch 00656: val_loss improved from 439806.93750 to 439190.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 582829.3787 - mean_squared_error: 582829.3750 - mean_absolute_error: 545.5507 - val_loss: 439190.7188 - val_mean_squared_error: 439190.7188 - val_mean_absolute_error: 581.6917\n",
      "Epoch 657/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 734036.7500 - mean_squared_error: 734036.7500 - mean_absolute_error: 551.1012\n",
      "Epoch 00657: val_loss improved from 439190.71875 to 438592.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 582100.9743 - mean_squared_error: 582100.9375 - mean_absolute_error: 545.0827 - val_loss: 438592.3750 - val_mean_squared_error: 438592.3750 - val_mean_absolute_error: 581.1641\n",
      "Epoch 658/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 571794.1250 - mean_squared_error: 571794.1250 - mean_absolute_error: 518.5175\n",
      "Epoch 00658: val_loss improved from 438592.37500 to 438029.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 581367.2748 - mean_squared_error: 581367.3125 - mean_absolute_error: 544.5972 - val_loss: 438029.0312 - val_mean_squared_error: 438029.0312 - val_mean_absolute_error: 580.6577\n",
      "Epoch 659/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 956252.9375 - mean_squared_error: 956252.9375 - mean_absolute_error: 678.8151\n",
      "Epoch 00659: val_loss improved from 438029.03125 to 437377.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 580698.4991 - mean_squared_error: 580698.5000 - mean_absolute_error: 544.1371 - val_loss: 437377.9062 - val_mean_squared_error: 437377.9062 - val_mean_absolute_error: 580.1052\n",
      "Epoch 660/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 722371.0000 - mean_squared_error: 722371.0000 - mean_absolute_error: 617.5000\n",
      "Epoch 00660: val_loss improved from 437377.90625 to 436745.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 579900.8814 - mean_squared_error: 579900.8750 - mean_absolute_error: 543.7169 - val_loss: 436745.3438 - val_mean_squared_error: 436745.3438 - val_mean_absolute_error: 579.5697\n",
      "Epoch 661/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 348142.3750 - mean_squared_error: 348142.3750 - mean_absolute_error: 484.2621\n",
      "Epoch 00661: val_loss improved from 436745.34375 to 436123.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 579114.1085 - mean_squared_error: 579114.1250 - mean_absolute_error: 543.3440 - val_loss: 436123.4688 - val_mean_squared_error: 436123.4688 - val_mean_absolute_error: 579.0511\n",
      "Epoch 662/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 508678.5625 - mean_squared_error: 508678.5625 - mean_absolute_error: 499.3678\n",
      "Epoch 00662: val_loss improved from 436123.46875 to 435445.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 578364.4926 - mean_squared_error: 578364.5000 - mean_absolute_error: 542.9536 - val_loss: 435445.3438 - val_mean_squared_error: 435445.3438 - val_mean_absolute_error: 578.4854\n",
      "Epoch 663/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 729049.8125 - mean_squared_error: 729049.8125 - mean_absolute_error: 625.9763\n",
      "Epoch 00663: val_loss improved from 435445.34375 to 434534.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 577631.0294 - mean_squared_error: 577631.0000 - mean_absolute_error: 542.6325 - val_loss: 434534.3750 - val_mean_squared_error: 434534.3750 - val_mean_absolute_error: 577.7618\n",
      "Epoch 664/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 605752.0000 - mean_squared_error: 605752.0000 - mean_absolute_error: 545.2388\n",
      "Epoch 00664: val_loss improved from 434534.37500 to 433499.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 576618.0441 - mean_squared_error: 576618.0625 - mean_absolute_error: 542.3471 - val_loss: 433499.6562 - val_mean_squared_error: 433499.6562 - val_mean_absolute_error: 576.9725\n",
      "Epoch 665/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 422032.1250 - mean_squared_error: 422032.1250 - mean_absolute_error: 486.6190\n",
      "Epoch 00665: val_loss improved from 433499.65625 to 432464.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 575514.3199 - mean_squared_error: 575514.3125 - mean_absolute_error: 542.1497 - val_loss: 432464.3125 - val_mean_squared_error: 432464.3125 - val_mean_absolute_error: 576.1809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 666/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 720765.6875 - mean_squared_error: 720765.6875 - mean_absolute_error: 627.4816\n",
      "Epoch 00666: val_loss improved from 432464.31250 to 431452.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 574687.8134 - mean_squared_error: 574687.8125 - mean_absolute_error: 542.0940 - val_loss: 431452.2812 - val_mean_squared_error: 431452.2812 - val_mean_absolute_error: 575.5852\n",
      "Epoch 667/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 518629.6250 - mean_squared_error: 518629.6250 - mean_absolute_error: 509.0441\n",
      "Epoch 00667: val_loss improved from 431452.28125 to 430517.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 573592.5404 - mean_squared_error: 573592.5000 - mean_absolute_error: 541.7995 - val_loss: 430517.0938 - val_mean_squared_error: 430517.0938 - val_mean_absolute_error: 575.1050\n",
      "Epoch 668/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 494675.2188 - mean_squared_error: 494675.2188 - mean_absolute_error: 500.4352\n",
      "Epoch 00668: val_loss improved from 430517.09375 to 429557.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 572593.2279 - mean_squared_error: 572593.2500 - mean_absolute_error: 541.6108 - val_loss: 429557.0312 - val_mean_squared_error: 429557.0312 - val_mean_absolute_error: 574.6168\n",
      "Epoch 669/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 253762.0156 - mean_squared_error: 253762.0156 - mean_absolute_error: 412.8552\n",
      "Epoch 00669: val_loss improved from 429557.03125 to 428533.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 571589.6434 - mean_squared_error: 571589.6250 - mean_absolute_error: 541.4506 - val_loss: 428533.1250 - val_mean_squared_error: 428533.1250 - val_mean_absolute_error: 574.1047\n",
      "Epoch 670/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 891624.5000 - mean_squared_error: 891624.5000 - mean_absolute_error: 633.7745\n",
      "Epoch 00670: val_loss improved from 428533.12500 to 427460.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 570830.3824 - mean_squared_error: 570830.4375 - mean_absolute_error: 541.3287 - val_loss: 427460.0625 - val_mean_squared_error: 427460.0625 - val_mean_absolute_error: 573.5656\n",
      "Epoch 671/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 383762.2500 - mean_squared_error: 383762.2500 - mean_absolute_error: 462.9281\n",
      "Epoch 00671: val_loss improved from 427460.06250 to 426506.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 569654.1066 - mean_squared_error: 569654.1250 - mean_absolute_error: 541.1538 - val_loss: 426506.6562 - val_mean_squared_error: 426506.6562 - val_mean_absolute_error: 573.0247\n",
      "Epoch 672/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 611299.7500 - mean_squared_error: 611299.7500 - mean_absolute_error: 548.6324\n",
      "Epoch 00672: val_loss improved from 426506.65625 to 425708.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 568723.3134 - mean_squared_error: 568723.3125 - mean_absolute_error: 540.7950 - val_loss: 425708.8750 - val_mean_squared_error: 425708.8750 - val_mean_absolute_error: 572.5066\n",
      "Epoch 673/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 691534.6250 - mean_squared_error: 691534.6250 - mean_absolute_error: 612.9396\n",
      "Epoch 00673: val_loss improved from 425708.87500 to 425007.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 567821.1121 - mean_squared_error: 567821.1250 - mean_absolute_error: 540.3477 - val_loss: 425007.3438 - val_mean_squared_error: 425007.3438 - val_mean_absolute_error: 572.0178\n",
      "Epoch 674/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 415901.5312 - mean_squared_error: 415901.5312 - mean_absolute_error: 478.9063\n",
      "Epoch 00674: val_loss improved from 425007.34375 to 424360.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 566915.4099 - mean_squared_error: 566915.4375 - mean_absolute_error: 539.8091 - val_loss: 424360.3750 - val_mean_squared_error: 424360.3750 - val_mean_absolute_error: 571.5455\n",
      "Epoch 675/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 470569.8125 - mean_squared_error: 470569.8125 - mean_absolute_error: 543.5997\n",
      "Epoch 00675: val_loss improved from 424360.37500 to 423683.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 566148.0735 - mean_squared_error: 566148.1250 - mean_absolute_error: 539.3847 - val_loss: 423683.4375 - val_mean_squared_error: 423683.4375 - val_mean_absolute_error: 571.0670\n",
      "Epoch 676/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 482430.3125 - mean_squared_error: 482430.3125 - mean_absolute_error: 554.8954\n",
      "Epoch 00676: val_loss improved from 423683.43750 to 422979.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 565312.6324 - mean_squared_error: 565312.6250 - mean_absolute_error: 538.8976 - val_loss: 422979.8438 - val_mean_squared_error: 422979.8438 - val_mean_absolute_error: 570.5755\n",
      "Epoch 677/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 572370.2500 - mean_squared_error: 572370.2500 - mean_absolute_error: 531.4844\n",
      "Epoch 00677: val_loss improved from 422979.84375 to 422161.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 564451.4550 - mean_squared_error: 564451.5000 - mean_absolute_error: 538.4219 - val_loss: 422161.0938 - val_mean_squared_error: 422161.0938 - val_mean_absolute_error: 570.0495\n",
      "Epoch 678/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 706121.2500 - mean_squared_error: 706121.2500 - mean_absolute_error: 591.3950\n",
      "Epoch 00678: val_loss improved from 422161.09375 to 421386.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 563543.7059 - mean_squared_error: 563543.6875 - mean_absolute_error: 537.9987 - val_loss: 421386.0312 - val_mean_squared_error: 421386.0312 - val_mean_absolute_error: 569.5322\n",
      "Epoch 679/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 667374.1875 - mean_squared_error: 667374.1875 - mean_absolute_error: 572.4849\n",
      "Epoch 00679: val_loss improved from 421386.03125 to 420546.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 562640.8033 - mean_squared_error: 562640.7500 - mean_absolute_error: 537.5833 - val_loss: 420546.4375 - val_mean_squared_error: 420546.4375 - val_mean_absolute_error: 569.0139\n",
      "Epoch 680/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 179760.8750 - mean_squared_error: 179760.8750 - mean_absolute_error: 333.9610\n",
      "Epoch 00680: val_loss improved from 420546.43750 to 419682.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 561594.3971 - mean_squared_error: 561594.4375 - mean_absolute_error: 537.1953 - val_loss: 419682.1875 - val_mean_squared_error: 419682.1875 - val_mean_absolute_error: 568.4886\n",
      "Epoch 681/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 712421.5000 - mean_squared_error: 712421.5000 - mean_absolute_error: 629.6135\n",
      "Epoch 00681: val_loss improved from 419682.18750 to 418709.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 560803.2822 - mean_squared_error: 560803.3125 - mean_absolute_error: 536.8845 - val_loss: 418709.5000 - val_mean_squared_error: 418709.5000 - val_mean_absolute_error: 567.9304\n",
      "Epoch 682/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 718840.9375 - mean_squared_error: 718840.9375 - mean_absolute_error: 598.7400\n",
      "Epoch 00682: val_loss improved from 418709.50000 to 417861.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 559868.8713 - mean_squared_error: 559868.8750 - mean_absolute_error: 536.6810 - val_loss: 417861.4375 - val_mean_squared_error: 417861.4375 - val_mean_absolute_error: 567.3973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 683/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 588504.0000 - mean_squared_error: 588504.0000 - mean_absolute_error: 525.8706\n",
      "Epoch 00683: val_loss improved from 417861.43750 to 417146.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 558828.5101 - mean_squared_error: 558828.5000 - mean_absolute_error: 536.1553 - val_loss: 417146.7188 - val_mean_squared_error: 417146.7188 - val_mean_absolute_error: 566.8560\n",
      "Epoch 684/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 450212.5625 - mean_squared_error: 450212.5625 - mean_absolute_error: 442.8768\n",
      "Epoch 00684: val_loss improved from 417146.71875 to 416508.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 557909.5772 - mean_squared_error: 557909.5625 - mean_absolute_error: 535.5645 - val_loss: 416508.0625 - val_mean_squared_error: 416508.0625 - val_mean_absolute_error: 566.3264\n",
      "Epoch 685/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 375217.4062 - mean_squared_error: 375217.4062 - mean_absolute_error: 471.3254\n",
      "Epoch 00685: val_loss improved from 416508.06250 to 415791.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 557069.5000 - mean_squared_error: 557069.5000 - mean_absolute_error: 534.9391 - val_loss: 415791.3438 - val_mean_squared_error: 415791.3438 - val_mean_absolute_error: 565.7756\n",
      "Epoch 686/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 271122.1562 - mean_squared_error: 271122.1562 - mean_absolute_error: 455.2194\n",
      "Epoch 00686: val_loss improved from 415791.34375 to 414968.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 556101.7096 - mean_squared_error: 556101.6875 - mean_absolute_error: 534.3480 - val_loss: 414968.4375 - val_mean_squared_error: 414968.4375 - val_mean_absolute_error: 565.2187\n",
      "Epoch 687/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 684585.2500 - mean_squared_error: 684585.2500 - mean_absolute_error: 605.5840\n",
      "Epoch 00687: val_loss improved from 414968.43750 to 414168.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 555251.3787 - mean_squared_error: 555251.3750 - mean_absolute_error: 533.9441 - val_loss: 414168.0625 - val_mean_squared_error: 414168.0625 - val_mean_absolute_error: 564.6949\n",
      "Epoch 688/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 489863.6250 - mean_squared_error: 489863.6250 - mean_absolute_error: 525.3748\n",
      "Epoch 00688: val_loss improved from 414168.06250 to 413373.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 554305.8389 - mean_squared_error: 554305.8125 - mean_absolute_error: 533.5168 - val_loss: 413373.7812 - val_mean_squared_error: 413373.7812 - val_mean_absolute_error: 564.1987\n",
      "Epoch 689/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 334023.1875 - mean_squared_error: 334023.1875 - mean_absolute_error: 485.7576\n",
      "Epoch 00689: val_loss improved from 413373.78125 to 412583.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 553401.6103 - mean_squared_error: 553401.5625 - mean_absolute_error: 533.2420 - val_loss: 412583.0312 - val_mean_squared_error: 412583.0312 - val_mean_absolute_error: 563.7018\n",
      "Epoch 690/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 466566.0000 - mean_squared_error: 466566.0000 - mean_absolute_error: 511.4444\n",
      "Epoch 00690: val_loss improved from 412583.03125 to 411649.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 552494.5956 - mean_squared_error: 552494.5625 - mean_absolute_error: 532.8622 - val_loss: 411649.7188 - val_mean_squared_error: 411649.7188 - val_mean_absolute_error: 563.1467\n",
      "Epoch 691/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 328677.2500 - mean_squared_error: 328677.2500 - mean_absolute_error: 479.3126\n",
      "Epoch 00691: val_loss improved from 411649.71875 to 410640.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 551516.6967 - mean_squared_error: 551516.6250 - mean_absolute_error: 532.6389 - val_loss: 410640.9062 - val_mean_squared_error: 410640.9062 - val_mean_absolute_error: 562.5640\n",
      "Epoch 692/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 495488.9062 - mean_squared_error: 495488.9062 - mean_absolute_error: 508.0765\n",
      "Epoch 00692: val_loss improved from 410640.90625 to 409749.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 550485.0579 - mean_squared_error: 550485.0625 - mean_absolute_error: 532.3008 - val_loss: 409749.3125 - val_mean_squared_error: 409749.3125 - val_mean_absolute_error: 562.0168\n",
      "Epoch 693/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 505390.1875 - mean_squared_error: 505390.1875 - mean_absolute_error: 512.2867\n",
      "Epoch 00693: val_loss improved from 409749.31250 to 408922.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 549547.9044 - mean_squared_error: 549547.9375 - mean_absolute_error: 531.9872 - val_loss: 408922.4062 - val_mean_squared_error: 408922.4062 - val_mean_absolute_error: 561.4888\n",
      "Epoch 694/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 706373.7500 - mean_squared_error: 706373.7500 - mean_absolute_error: 577.3663\n",
      "Epoch 00694: val_loss improved from 408922.40625 to 408107.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 548681.9062 - mean_squared_error: 548681.9375 - mean_absolute_error: 531.6463 - val_loss: 408107.7812 - val_mean_squared_error: 408107.7812 - val_mean_absolute_error: 560.9437\n",
      "Epoch 695/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 266537.8750 - mean_squared_error: 266537.8750 - mean_absolute_error: 425.2889\n",
      "Epoch 00695: val_loss improved from 408107.78125 to 407336.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 547685.7445 - mean_squared_error: 547685.7500 - mean_absolute_error: 531.2249 - val_loss: 407336.7188 - val_mean_squared_error: 407336.7188 - val_mean_absolute_error: 560.4258\n",
      "Epoch 696/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 398789.6875 - mean_squared_error: 398789.6875 - mean_absolute_error: 503.5119\n",
      "Epoch 00696: val_loss improved from 407336.71875 to 406628.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 546838.7861 - mean_squared_error: 546838.7500 - mean_absolute_error: 530.8529 - val_loss: 406628.6250 - val_mean_squared_error: 406628.6250 - val_mean_absolute_error: 559.9429\n",
      "Epoch 697/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 448160.5000 - mean_squared_error: 448160.5000 - mean_absolute_error: 488.9280\n",
      "Epoch 00697: val_loss improved from 406628.62500 to 405983.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 546086.3107 - mean_squared_error: 546086.3125 - mean_absolute_error: 530.5104 - val_loss: 405983.5312 - val_mean_squared_error: 405983.5312 - val_mean_absolute_error: 559.4870\n",
      "Epoch 698/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 677475.3750 - mean_squared_error: 677475.3750 - mean_absolute_error: 579.2404\n",
      "Epoch 00698: val_loss improved from 405983.53125 to 405397.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 545331.7528 - mean_squared_error: 545331.6875 - mean_absolute_error: 530.0918 - val_loss: 405397.1562 - val_mean_squared_error: 405397.1562 - val_mean_absolute_error: 559.0448\n",
      "Epoch 699/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 211184.5000 - mean_squared_error: 211184.5000 - mean_absolute_error: 407.2115\n",
      "Epoch 00699: val_loss improved from 405397.15625 to 404802.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 544547.1250 - mean_squared_error: 544547.1250 - mean_absolute_error: 529.6588 - val_loss: 404802.7812 - val_mean_squared_error: 404802.7812 - val_mean_absolute_error: 558.5946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 700/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 551936.6875 - mean_squared_error: 551936.6875 - mean_absolute_error: 542.3696\n",
      "Epoch 00700: val_loss improved from 404802.78125 to 404125.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 543869.1608 - mean_squared_error: 543869.1250 - mean_absolute_error: 529.2377 - val_loss: 404125.5000 - val_mean_squared_error: 404125.5000 - val_mean_absolute_error: 558.0991\n",
      "Epoch 701/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 881286.3750 - mean_squared_error: 881286.3750 - mean_absolute_error: 637.4023\n",
      "Epoch 00701: val_loss improved from 404125.50000 to 403459.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 543109.7868 - mean_squared_error: 543109.7500 - mean_absolute_error: 528.7902 - val_loss: 403459.5000 - val_mean_squared_error: 403459.5000 - val_mean_absolute_error: 557.6145\n",
      "Epoch 702/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 473418.6875 - mean_squared_error: 473418.6875 - mean_absolute_error: 473.6890\n",
      "Epoch 00702: val_loss improved from 403459.50000 to 402788.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 542250.5395 - mean_squared_error: 542250.5000 - mean_absolute_error: 528.3658 - val_loss: 402788.0312 - val_mean_squared_error: 402788.0312 - val_mean_absolute_error: 557.1624\n",
      "Epoch 703/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 870750.3750 - mean_squared_error: 870750.3750 - mean_absolute_error: 639.9862\n",
      "Epoch 00703: val_loss improved from 402788.03125 to 402104.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 541673.6967 - mean_squared_error: 541673.6875 - mean_absolute_error: 528.1440 - val_loss: 402104.3750 - val_mean_squared_error: 402104.3750 - val_mean_absolute_error: 556.7365\n",
      "Epoch 704/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 439435.3438 - mean_squared_error: 439435.3438 - mean_absolute_error: 492.0059\n",
      "Epoch 00704: val_loss improved from 402104.37500 to 401463.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 540759.8971 - mean_squared_error: 540759.8750 - mean_absolute_error: 527.8431 - val_loss: 401463.3750 - val_mean_squared_error: 401463.3750 - val_mean_absolute_error: 556.2970\n",
      "Epoch 705/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 628791.0625 - mean_squared_error: 628791.0625 - mean_absolute_error: 568.0686\n",
      "Epoch 00705: val_loss improved from 401463.37500 to 400738.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 540062.9954 - mean_squared_error: 540063.0000 - mean_absolute_error: 527.5179 - val_loss: 400738.3125 - val_mean_squared_error: 400738.3125 - val_mean_absolute_error: 555.8303\n",
      "Epoch 706/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 675194.2500 - mean_squared_error: 675194.2500 - mean_absolute_error: 568.0079\n",
      "Epoch 00706: val_loss improved from 400738.31250 to 400051.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 539229.8199 - mean_squared_error: 539229.8125 - mean_absolute_error: 527.2079 - val_loss: 400051.6562 - val_mean_squared_error: 400051.6562 - val_mean_absolute_error: 555.3805\n",
      "Epoch 707/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 427427.8125 - mean_squared_error: 427427.8125 - mean_absolute_error: 477.6912\n",
      "Epoch 00707: val_loss improved from 400051.65625 to 399408.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 538479.2243 - mean_squared_error: 538479.2500 - mean_absolute_error: 526.9651 - val_loss: 399408.0000 - val_mean_squared_error: 399408.0000 - val_mean_absolute_error: 554.9304\n",
      "Epoch 708/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 437601.3750 - mean_squared_error: 437601.3750 - mean_absolute_error: 489.5118\n",
      "Epoch 00708: val_loss improved from 399408.00000 to 398794.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 537750.0294 - mean_squared_error: 537750.0000 - mean_absolute_error: 526.6141 - val_loss: 398794.4375 - val_mean_squared_error: 398794.4375 - val_mean_absolute_error: 554.4593\n",
      "Epoch 709/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 827546.8750 - mean_squared_error: 827546.8750 - mean_absolute_error: 617.6870\n",
      "Epoch 00709: val_loss improved from 398794.43750 to 398195.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 537073.0772 - mean_squared_error: 537073.0625 - mean_absolute_error: 526.2292 - val_loss: 398195.4375 - val_mean_squared_error: 398195.4375 - val_mean_absolute_error: 554.0009\n",
      "Epoch 710/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 427238.1250 - mean_squared_error: 427238.1250 - mean_absolute_error: 511.2495\n",
      "Epoch 00710: val_loss improved from 398195.43750 to 397683.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 536275.3097 - mean_squared_error: 536275.3125 - mean_absolute_error: 525.7893 - val_loss: 397683.3750 - val_mean_squared_error: 397683.3750 - val_mean_absolute_error: 553.5505\n",
      "Epoch 711/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 461041.4688 - mean_squared_error: 461041.4688 - mean_absolute_error: 532.1873\n",
      "Epoch 00711: val_loss improved from 397683.37500 to 397160.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 535620.0515 - mean_squared_error: 535620.0625 - mean_absolute_error: 525.2687 - val_loss: 397160.3438 - val_mean_squared_error: 397160.3438 - val_mean_absolute_error: 553.0857\n",
      "Epoch 712/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 517839.6250 - mean_squared_error: 517839.6250 - mean_absolute_error: 531.3610\n",
      "Epoch 00712: val_loss improved from 397160.34375 to 396501.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 534872.3033 - mean_squared_error: 534872.3125 - mean_absolute_error: 524.7427 - val_loss: 396501.0625 - val_mean_squared_error: 396501.0625 - val_mean_absolute_error: 552.5836\n",
      "Epoch 713/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 849737.5000 - mean_squared_error: 849737.5000 - mean_absolute_error: 631.2487\n",
      "Epoch 00713: val_loss improved from 396501.06250 to 395859.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 534088.2307 - mean_squared_error: 534088.2500 - mean_absolute_error: 524.3000 - val_loss: 395859.7500 - val_mean_squared_error: 395859.7500 - val_mean_absolute_error: 552.0878\n",
      "Epoch 714/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 377919.0000 - mean_squared_error: 377919.0000 - mean_absolute_error: 448.2025\n",
      "Epoch 00714: val_loss improved from 395859.75000 to 395260.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 533226.1158 - mean_squared_error: 533226.1250 - mean_absolute_error: 523.8322 - val_loss: 395260.7812 - val_mean_squared_error: 395260.7812 - val_mean_absolute_error: 551.6064\n",
      "Epoch 715/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 616879.1875 - mean_squared_error: 616879.1875 - mean_absolute_error: 623.5058\n",
      "Epoch 00715: val_loss improved from 395260.78125 to 394690.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 322us/sample - loss: 532510.1746 - mean_squared_error: 532510.1250 - mean_absolute_error: 523.3936 - val_loss: 394690.0938 - val_mean_squared_error: 394690.0938 - val_mean_absolute_error: 551.1166\n",
      "Epoch 716/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 603930.0625 - mean_squared_error: 603930.0625 - mean_absolute_error: 545.6561\n",
      "Epoch 00716: val_loss improved from 394690.09375 to 394141.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 531713.6636 - mean_squared_error: 531713.6250 - mean_absolute_error: 522.8073 - val_loss: 394141.5312 - val_mean_squared_error: 394141.5312 - val_mean_absolute_error: 550.6240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 717/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 346766.6875 - mean_squared_error: 346766.6875 - mean_absolute_error: 448.5763\n",
      "Epoch 00717: val_loss improved from 394141.53125 to 393624.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 530968.7096 - mean_squared_error: 530968.6875 - mean_absolute_error: 522.2687 - val_loss: 393624.0625 - val_mean_squared_error: 393624.0625 - val_mean_absolute_error: 550.1355\n",
      "Epoch 718/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 655435.1250 - mean_squared_error: 655435.1250 - mean_absolute_error: 588.6165\n",
      "Epoch 00718: val_loss improved from 393624.06250 to 393140.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 530247.9816 - mean_squared_error: 530248.0000 - mean_absolute_error: 521.6619 - val_loss: 393140.0938 - val_mean_squared_error: 393140.0938 - val_mean_absolute_error: 549.6489\n",
      "Epoch 719/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 496675.9375 - mean_squared_error: 496675.9375 - mean_absolute_error: 517.5610\n",
      "Epoch 00719: val_loss improved from 393140.09375 to 392746.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 529559.7454 - mean_squared_error: 529559.7500 - mean_absolute_error: 520.9327 - val_loss: 392746.1250 - val_mean_squared_error: 392746.1250 - val_mean_absolute_error: 549.1695\n",
      "Epoch 720/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 857529.8125 - mean_squared_error: 857529.8125 - mean_absolute_error: 633.1329\n",
      "Epoch 00720: val_loss improved from 392746.12500 to 392332.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 528899.8695 - mean_squared_error: 528899.8125 - mean_absolute_error: 520.1689 - val_loss: 392332.2188 - val_mean_squared_error: 392332.2188 - val_mean_absolute_error: 548.6990\n",
      "Epoch 721/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 390738.8125 - mean_squared_error: 390738.8125 - mean_absolute_error: 484.8518\n",
      "Epoch 00721: val_loss improved from 392332.21875 to 391913.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 528172.0368 - mean_squared_error: 528172.0000 - mean_absolute_error: 519.4403 - val_loss: 391913.2812 - val_mean_squared_error: 391913.2812 - val_mean_absolute_error: 548.2534\n",
      "Epoch 722/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 648244.5000 - mean_squared_error: 648244.5000 - mean_absolute_error: 553.8134\n",
      "Epoch 00722: val_loss improved from 391913.28125 to 391496.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 527530.7546 - mean_squared_error: 527530.7500 - mean_absolute_error: 518.8042 - val_loss: 391496.3750 - val_mean_squared_error: 391496.3750 - val_mean_absolute_error: 547.8064\n",
      "Epoch 723/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 725266.3750 - mean_squared_error: 725266.3750 - mean_absolute_error: 607.2054\n",
      "Epoch 00723: val_loss improved from 391496.37500 to 391033.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 526944.4706 - mean_squared_error: 526944.5000 - mean_absolute_error: 518.2067 - val_loss: 391033.7812 - val_mean_squared_error: 391033.7812 - val_mean_absolute_error: 547.3424\n",
      "Epoch 724/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 423739.0625 - mean_squared_error: 423739.0625 - mean_absolute_error: 491.3867\n",
      "Epoch 00724: val_loss improved from 391033.78125 to 390458.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 526217.5882 - mean_squared_error: 526217.6250 - mean_absolute_error: 517.6362 - val_loss: 390458.2500 - val_mean_squared_error: 390458.2500 - val_mean_absolute_error: 546.8494\n",
      "Epoch 725/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 839711.5000 - mean_squared_error: 839711.5000 - mean_absolute_error: 624.9562\n",
      "Epoch 00725: val_loss improved from 390458.25000 to 389904.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 525478.5809 - mean_squared_error: 525478.5625 - mean_absolute_error: 517.0718 - val_loss: 389904.7188 - val_mean_squared_error: 389904.7188 - val_mean_absolute_error: 546.3511\n",
      "Epoch 726/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 594596.9375 - mean_squared_error: 594596.9375 - mean_absolute_error: 513.1875\n",
      "Epoch 00726: val_loss improved from 389904.71875 to 389318.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 524750.9118 - mean_squared_error: 524750.9375 - mean_absolute_error: 516.5736 - val_loss: 389318.4375 - val_mean_squared_error: 389318.4375 - val_mean_absolute_error: 545.8372\n",
      "Epoch 727/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 463099.5312 - mean_squared_error: 463099.5312 - mean_absolute_error: 495.6604\n",
      "Epoch 00727: val_loss improved from 389318.43750 to 388675.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 523945.0147 - mean_squared_error: 523945.0000 - mean_absolute_error: 516.0475 - val_loss: 388675.7812 - val_mean_squared_error: 388675.7812 - val_mean_absolute_error: 545.3214\n",
      "Epoch 728/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 856616.6875 - mean_squared_error: 856616.6875 - mean_absolute_error: 655.4678\n",
      "Epoch 00728: val_loss improved from 388675.78125 to 387954.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 523213.7086 - mean_squared_error: 523213.7500 - mean_absolute_error: 515.6214 - val_loss: 387954.0000 - val_mean_squared_error: 387954.0000 - val_mean_absolute_error: 544.7847\n",
      "Epoch 729/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 679500.3125 - mean_squared_error: 679500.3125 - mean_absolute_error: 549.4558\n",
      "Epoch 00729: val_loss improved from 387954.00000 to 387325.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 522376.9017 - mean_squared_error: 522376.9375 - mean_absolute_error: 515.2975 - val_loss: 387325.8125 - val_mean_squared_error: 387325.8125 - val_mean_absolute_error: 544.2919\n",
      "Epoch 730/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 504898.1875 - mean_squared_error: 504898.1875 - mean_absolute_error: 539.4801\n",
      "Epoch 00730: val_loss improved from 387325.81250 to 386731.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 521565.0147 - mean_squared_error: 521565.0000 - mean_absolute_error: 514.8290 - val_loss: 386731.6562 - val_mean_squared_error: 386731.6562 - val_mean_absolute_error: 543.8143\n",
      "Epoch 731/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 861196.0625 - mean_squared_error: 861196.0625 - mean_absolute_error: 645.5117\n",
      "Epoch 00731: val_loss improved from 386731.65625 to 386010.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 520881.6750 - mean_squared_error: 520881.6562 - mean_absolute_error: 514.4750 - val_loss: 386010.2500 - val_mean_squared_error: 386010.2500 - val_mean_absolute_error: 543.3082\n",
      "Epoch 732/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 303983.7500 - mean_squared_error: 303983.7500 - mean_absolute_error: 457.3663\n",
      "Epoch 00732: val_loss improved from 386010.25000 to 385364.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 519984.6149 - mean_squared_error: 519984.5938 - mean_absolute_error: 514.2082 - val_loss: 385364.9062 - val_mean_squared_error: 385364.9062 - val_mean_absolute_error: 542.8470\n",
      "Epoch 733/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 448476.8750 - mean_squared_error: 448476.8750 - mean_absolute_error: 483.0350\n",
      "Epoch 00733: val_loss improved from 385364.90625 to 384710.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 519251.1324 - mean_squared_error: 519251.1250 - mean_absolute_error: 513.9541 - val_loss: 384710.9062 - val_mean_squared_error: 384710.9062 - val_mean_absolute_error: 542.4074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 734/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 442250.4375 - mean_squared_error: 442250.4375 - mean_absolute_error: 487.3674\n",
      "Epoch 00734: val_loss improved from 384710.90625 to 384083.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 518536.5882 - mean_squared_error: 518536.5938 - mean_absolute_error: 513.7822 - val_loss: 384083.1250 - val_mean_squared_error: 384083.1250 - val_mean_absolute_error: 541.9645\n",
      "Epoch 735/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 591641.5625 - mean_squared_error: 591641.5625 - mean_absolute_error: 499.4041\n",
      "Epoch 00735: val_loss improved from 384083.12500 to 383486.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 517858.4853 - mean_squared_error: 517858.4688 - mean_absolute_error: 513.5376 - val_loss: 383486.5312 - val_mean_squared_error: 383486.5312 - val_mean_absolute_error: 541.5451\n",
      "Epoch 736/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 675416.9375 - mean_squared_error: 675416.9375 - mean_absolute_error: 568.7387\n",
      "Epoch 00736: val_loss improved from 383486.53125 to 382923.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 517243.3879 - mean_squared_error: 517243.4062 - mean_absolute_error: 513.3837 - val_loss: 382923.0938 - val_mean_squared_error: 382923.0938 - val_mean_absolute_error: 541.1339\n",
      "Epoch 737/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 693143.5000 - mean_squared_error: 693143.5000 - mean_absolute_error: 580.6247\n",
      "Epoch 00737: val_loss improved from 382923.09375 to 382417.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 516510.3529 - mean_squared_error: 516510.3438 - mean_absolute_error: 513.0156 - val_loss: 382417.2500 - val_mean_squared_error: 382417.2500 - val_mean_absolute_error: 540.7000\n",
      "Epoch 738/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 452622.1250 - mean_squared_error: 452622.1250 - mean_absolute_error: 523.2122\n",
      "Epoch 00738: val_loss improved from 382417.25000 to 381855.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 515838.3971 - mean_squared_error: 515838.4062 - mean_absolute_error: 512.6270 - val_loss: 381855.8750 - val_mean_squared_error: 381855.8750 - val_mean_absolute_error: 540.2314\n",
      "Epoch 739/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 425850.1875 - mean_squared_error: 425850.1875 - mean_absolute_error: 505.6026\n",
      "Epoch 00739: val_loss improved from 381855.87500 to 381286.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 515135.4393 - mean_squared_error: 515135.4688 - mean_absolute_error: 512.2238 - val_loss: 381286.2812 - val_mean_squared_error: 381286.2812 - val_mean_absolute_error: 539.7573\n",
      "Epoch 740/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 692477.5000 - mean_squared_error: 692477.5000 - mean_absolute_error: 583.0557\n",
      "Epoch 00740: val_loss improved from 381286.28125 to 380717.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 514497.3658 - mean_squared_error: 514497.3438 - mean_absolute_error: 511.8653 - val_loss: 380717.4375 - val_mean_squared_error: 380717.4375 - val_mean_absolute_error: 539.2928\n",
      "Epoch 741/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 830892.8750 - mean_squared_error: 830892.8750 - mean_absolute_error: 631.1226\n",
      "Epoch 00741: val_loss improved from 380717.43750 to 380182.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 513782.0101 - mean_squared_error: 513782.0000 - mean_absolute_error: 511.4449 - val_loss: 380182.1250 - val_mean_squared_error: 380182.1250 - val_mean_absolute_error: 538.8352\n",
      "Epoch 742/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 478176.0625 - mean_squared_error: 478176.0625 - mean_absolute_error: 507.8136\n",
      "Epoch 00742: val_loss improved from 380182.12500 to 379643.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 513045.7169 - mean_squared_error: 513045.7188 - mean_absolute_error: 511.0398 - val_loss: 379643.6250 - val_mean_squared_error: 379643.6250 - val_mean_absolute_error: 538.3893\n",
      "Epoch 743/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 868562.3750 - mean_squared_error: 868562.3750 - mean_absolute_error: 679.2733\n",
      "Epoch 00743: val_loss improved from 379643.62500 to 379117.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 512465.3272 - mean_squared_error: 512465.3438 - mean_absolute_error: 510.6870 - val_loss: 379117.8438 - val_mean_squared_error: 379117.8438 - val_mean_absolute_error: 537.9294\n",
      "Epoch 744/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 198719.8750 - mean_squared_error: 198719.8750 - mean_absolute_error: 387.8546\n",
      "Epoch 00744: val_loss improved from 379117.84375 to 378675.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 511672.3171 - mean_squared_error: 511672.2812 - mean_absolute_error: 510.1824 - val_loss: 378675.9062 - val_mean_squared_error: 378675.9062 - val_mean_absolute_error: 537.5055\n",
      "Epoch 745/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582927.7500 - mean_squared_error: 582927.7500 - mean_absolute_error: 521.0485\n",
      "Epoch 00745: val_loss improved from 378675.90625 to 378275.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 511108.0919 - mean_squared_error: 511108.0625 - mean_absolute_error: 509.7214 - val_loss: 378275.9688 - val_mean_squared_error: 378275.9688 - val_mean_absolute_error: 537.0803\n",
      "Epoch 746/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 499077.5625 - mean_squared_error: 499077.5625 - mean_absolute_error: 538.1459\n",
      "Epoch 00746: val_loss improved from 378275.96875 to 377822.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 510585.9044 - mean_squared_error: 510585.8750 - mean_absolute_error: 509.2034 - val_loss: 377822.5625 - val_mean_squared_error: 377822.5625 - val_mean_absolute_error: 536.6235\n",
      "Epoch 747/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 204555.1250 - mean_squared_error: 204555.1250 - mean_absolute_error: 419.5488\n",
      "Epoch 00747: val_loss improved from 377822.56250 to 377111.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 509737.8088 - mean_squared_error: 509737.8125 - mean_absolute_error: 508.6530 - val_loss: 377111.3750 - val_mean_squared_error: 377111.3750 - val_mean_absolute_error: 536.0696\n",
      "Epoch 748/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 439679.5312 - mean_squared_error: 439679.5312 - mean_absolute_error: 494.1711\n",
      "Epoch 00748: val_loss improved from 377111.37500 to 376180.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 508924.3143 - mean_squared_error: 508924.2812 - mean_absolute_error: 508.2971 - val_loss: 376180.1562 - val_mean_squared_error: 376180.1562 - val_mean_absolute_error: 535.4185\n",
      "Epoch 749/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 417924.8750 - mean_squared_error: 417924.8750 - mean_absolute_error: 502.6230\n",
      "Epoch 00749: val_loss improved from 376180.15625 to 375337.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 507922.8288 - mean_squared_error: 507922.8125 - mean_absolute_error: 508.0855 - val_loss: 375337.6250 - val_mean_squared_error: 375337.6250 - val_mean_absolute_error: 534.8179\n",
      "Epoch 750/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 291765.1562 - mean_squared_error: 291765.1562 - mean_absolute_error: 477.9923\n",
      "Epoch 00750: val_loss improved from 375337.62500 to 374535.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 506897.3235 - mean_squared_error: 506897.2812 - mean_absolute_error: 507.8605 - val_loss: 374535.3438 - val_mean_squared_error: 374535.3438 - val_mean_absolute_error: 534.2362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 751/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 253723.3594 - mean_squared_error: 253723.3594 - mean_absolute_error: 433.4226\n",
      "Epoch 00751: val_loss improved from 374535.34375 to 373699.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 505992.4265 - mean_squared_error: 505992.4062 - mean_absolute_error: 507.5462 - val_loss: 373699.7188 - val_mean_squared_error: 373699.7188 - val_mean_absolute_error: 533.6402\n",
      "Epoch 752/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 723594.8750 - mean_squared_error: 723594.8750 - mean_absolute_error: 541.4619\n",
      "Epoch 00752: val_loss improved from 373699.71875 to 372923.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 505196.6714 - mean_squared_error: 505196.6562 - mean_absolute_error: 507.3034 - val_loss: 372923.2188 - val_mean_squared_error: 372923.2188 - val_mean_absolute_error: 533.1046\n",
      "Epoch 753/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 378284.3125 - mean_squared_error: 378284.3125 - mean_absolute_error: 466.1544\n",
      "Epoch 00753: val_loss improved from 372923.21875 to 372137.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 504237.0441 - mean_squared_error: 504237.0625 - mean_absolute_error: 507.2615 - val_loss: 372137.9688 - val_mean_squared_error: 372137.9688 - val_mean_absolute_error: 532.5574\n",
      "Epoch 754/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 665006.0625 - mean_squared_error: 665006.0625 - mean_absolute_error: 587.5256\n",
      "Epoch 00754: val_loss improved from 372137.96875 to 371276.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 503531.7518 - mean_squared_error: 503531.7500 - mean_absolute_error: 507.1867 - val_loss: 371276.0625 - val_mean_squared_error: 371276.0625 - val_mean_absolute_error: 531.9590\n",
      "Epoch 755/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 387852.5625 - mean_squared_error: 387852.5625 - mean_absolute_error: 472.6892\n",
      "Epoch 00755: val_loss improved from 371276.06250 to 370531.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 502479.1167 - mean_squared_error: 502479.1250 - mean_absolute_error: 506.9764 - val_loss: 370531.1562 - val_mean_squared_error: 370531.1562 - val_mean_absolute_error: 531.4097\n",
      "Epoch 756/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 273388.0938 - mean_squared_error: 273388.0938 - mean_absolute_error: 431.2767\n",
      "Epoch 00756: val_loss improved from 370531.15625 to 369779.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 501620.1103 - mean_squared_error: 501620.1250 - mean_absolute_error: 506.7891 - val_loss: 369779.6562 - val_mean_squared_error: 369779.6562 - val_mean_absolute_error: 531.0283\n",
      "Epoch 757/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 356583.0938 - mean_squared_error: 356583.0938 - mean_absolute_error: 443.9693\n",
      "Epoch 00757: val_loss improved from 369779.65625 to 368932.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 500766.1471 - mean_squared_error: 500766.1250 - mean_absolute_error: 506.7375 - val_loss: 368932.2812 - val_mean_squared_error: 368932.2812 - val_mean_absolute_error: 530.8521\n",
      "Epoch 758/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 251052.2500 - mean_squared_error: 251052.2500 - mean_absolute_error: 420.9909\n",
      "Epoch 00758: val_loss improved from 368932.28125 to 368064.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 499770.0000 - mean_squared_error: 499770.0000 - mean_absolute_error: 506.6698 - val_loss: 368064.0000 - val_mean_squared_error: 368064.0000 - val_mean_absolute_error: 530.6304\n",
      "Epoch 759/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 454745.0938 - mean_squared_error: 454745.0938 - mean_absolute_error: 494.6632\n",
      "Epoch 00759: val_loss improved from 368064.00000 to 367176.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 499005.2748 - mean_squared_error: 499005.2500 - mean_absolute_error: 506.6425 - val_loss: 367176.3125 - val_mean_squared_error: 367176.3125 - val_mean_absolute_error: 530.3908\n",
      "Epoch 760/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 599820.8125 - mean_squared_error: 599820.8125 - mean_absolute_error: 557.9215\n",
      "Epoch 00760: val_loss improved from 367176.31250 to 366398.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 498147.8511 - mean_squared_error: 498147.8125 - mean_absolute_error: 506.6408 - val_loss: 366398.3125 - val_mean_squared_error: 366398.3125 - val_mean_absolute_error: 530.1612\n",
      "Epoch 761/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 567397.6250 - mean_squared_error: 567397.6250 - mean_absolute_error: 521.2434\n",
      "Epoch 00761: val_loss improved from 366398.31250 to 365661.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 497298.9632 - mean_squared_error: 497298.9375 - mean_absolute_error: 506.5796 - val_loss: 365661.7188 - val_mean_squared_error: 365661.7188 - val_mean_absolute_error: 529.9426\n",
      "Epoch 762/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 396707.2500 - mean_squared_error: 396707.2500 - mean_absolute_error: 482.3723\n",
      "Epoch 00762: val_loss improved from 365661.71875 to 364930.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 496389.7941 - mean_squared_error: 496389.7500 - mean_absolute_error: 506.4432 - val_loss: 364930.9062 - val_mean_squared_error: 364930.9062 - val_mean_absolute_error: 529.6871\n",
      "Epoch 763/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 405309.6250 - mean_squared_error: 405309.6250 - mean_absolute_error: 464.0919\n",
      "Epoch 00763: val_loss improved from 364930.90625 to 364273.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 495570.1994 - mean_squared_error: 495570.1875 - mean_absolute_error: 506.2385 - val_loss: 364273.7188 - val_mean_squared_error: 364273.7188 - val_mean_absolute_error: 529.4250\n",
      "Epoch 764/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 788353.6250 - mean_squared_error: 788353.6250 - mean_absolute_error: 609.4504\n",
      "Epoch 00764: val_loss improved from 364273.71875 to 363647.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 494926.5699 - mean_squared_error: 494926.5312 - mean_absolute_error: 506.0767 - val_loss: 363647.0000 - val_mean_squared_error: 363647.0000 - val_mean_absolute_error: 529.1152\n",
      "Epoch 765/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 465624.3438 - mean_squared_error: 465624.3438 - mean_absolute_error: 504.2470\n",
      "Epoch 00765: val_loss improved from 363647.00000 to 363091.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 494079.3649 - mean_squared_error: 494079.3438 - mean_absolute_error: 505.6990 - val_loss: 363091.8438 - val_mean_squared_error: 363091.8438 - val_mean_absolute_error: 528.7571\n",
      "Epoch 766/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 521435.5000 - mean_squared_error: 521435.5000 - mean_absolute_error: 490.8328\n",
      "Epoch 00766: val_loss improved from 363091.84375 to 362536.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 493366.2316 - mean_squared_error: 493366.2500 - mean_absolute_error: 505.2880 - val_loss: 362536.1250 - val_mean_squared_error: 362536.1250 - val_mean_absolute_error: 528.3610\n",
      "Epoch 767/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 428699.5938 - mean_squared_error: 428699.5938 - mean_absolute_error: 456.0251\n",
      "Epoch 00767: val_loss improved from 362536.12500 to 362019.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 492591.2592 - mean_squared_error: 492591.2500 - mean_absolute_error: 504.7902 - val_loss: 362019.3750 - val_mean_squared_error: 362019.3750 - val_mean_absolute_error: 527.9384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 768/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 480495.3125 - mean_squared_error: 480495.3125 - mean_absolute_error: 482.2187\n",
      "Epoch 00768: val_loss improved from 362019.37500 to 361555.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 491882.8134 - mean_squared_error: 491882.8125 - mean_absolute_error: 504.1915 - val_loss: 361555.8438 - val_mean_squared_error: 361555.8438 - val_mean_absolute_error: 527.5028\n",
      "Epoch 769/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 657969.8750 - mean_squared_error: 657969.8750 - mean_absolute_error: 578.4327\n",
      "Epoch 00769: val_loss improved from 361555.84375 to 361107.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 491226.3640 - mean_squared_error: 491226.3438 - mean_absolute_error: 503.5812 - val_loss: 361107.0625 - val_mean_squared_error: 361107.0625 - val_mean_absolute_error: 527.0447\n",
      "Epoch 770/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 239711.8125 - mean_squared_error: 239711.8125 - mean_absolute_error: 427.9519\n",
      "Epoch 00770: val_loss improved from 361107.06250 to 360677.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 490531.7592 - mean_squared_error: 490531.7500 - mean_absolute_error: 502.8744 - val_loss: 360677.5000 - val_mean_squared_error: 360677.5000 - val_mean_absolute_error: 526.5623\n",
      "Epoch 771/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 259671.9688 - mean_squared_error: 259671.9688 - mean_absolute_error: 454.7284\n",
      "Epoch 00771: val_loss improved from 360677.50000 to 360226.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 489913.3199 - mean_squared_error: 489913.2812 - mean_absolute_error: 502.2264 - val_loss: 360226.4375 - val_mean_squared_error: 360226.4375 - val_mean_absolute_error: 526.1122\n",
      "Epoch 772/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 339453.6250 - mean_squared_error: 339453.6250 - mean_absolute_error: 433.8111\n",
      "Epoch 00772: val_loss improved from 360226.43750 to 359722.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 489169.3603 - mean_squared_error: 489169.3438 - mean_absolute_error: 501.5604 - val_loss: 359722.4375 - val_mean_squared_error: 359722.4375 - val_mean_absolute_error: 525.7170\n",
      "Epoch 773/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 435979.2500 - mean_squared_error: 435979.2500 - mean_absolute_error: 484.4365\n",
      "Epoch 00773: val_loss improved from 359722.43750 to 359218.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 488484.2169 - mean_squared_error: 488484.2188 - mean_absolute_error: 501.0487 - val_loss: 359218.3438 - val_mean_squared_error: 359218.3438 - val_mean_absolute_error: 525.3034\n",
      "Epoch 774/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 315663.0625 - mean_squared_error: 315663.0625 - mean_absolute_error: 410.0232\n",
      "Epoch 00774: val_loss improved from 359218.34375 to 358685.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 487768.8824 - mean_squared_error: 487768.8750 - mean_absolute_error: 500.4623 - val_loss: 358685.3438 - val_mean_squared_error: 358685.3438 - val_mean_absolute_error: 524.8851\n",
      "Epoch 775/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 451478.1562 - mean_squared_error: 451478.1562 - mean_absolute_error: 500.6696\n",
      "Epoch 00775: val_loss improved from 358685.34375 to 358099.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 487048.2335 - mean_squared_error: 487048.2188 - mean_absolute_error: 499.9449 - val_loss: 358099.0000 - val_mean_squared_error: 358099.0000 - val_mean_absolute_error: 524.4852\n",
      "Epoch 776/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 245214.9062 - mean_squared_error: 245214.9062 - mean_absolute_error: 416.7851\n",
      "Epoch 00776: val_loss improved from 358099.00000 to 357532.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 486213.0882 - mean_squared_error: 486213.0625 - mean_absolute_error: 499.4365 - val_loss: 357532.8750 - val_mean_squared_error: 357532.8750 - val_mean_absolute_error: 524.0983\n",
      "Epoch 777/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 379341.9688 - mean_squared_error: 379341.9688 - mean_absolute_error: 432.5833\n",
      "Epoch 00777: val_loss improved from 357532.87500 to 356959.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 485525.3373 - mean_squared_error: 485525.3438 - mean_absolute_error: 499.0333 - val_loss: 356959.1562 - val_mean_squared_error: 356959.1562 - val_mean_absolute_error: 523.7069\n",
      "Epoch 778/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 533307.6250 - mean_squared_error: 533307.6250 - mean_absolute_error: 543.8282\n",
      "Epoch 00778: val_loss improved from 356959.15625 to 356440.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 484762.6544 - mean_squared_error: 484762.6562 - mean_absolute_error: 498.5216 - val_loss: 356440.8125 - val_mean_squared_error: 356440.8125 - val_mean_absolute_error: 523.3036\n",
      "Epoch 779/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 627735.2500 - mean_squared_error: 627735.2500 - mean_absolute_error: 546.0010\n",
      "Epoch 00779: val_loss improved from 356440.81250 to 355961.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 484092.2858 - mean_squared_error: 484092.2812 - mean_absolute_error: 498.0102 - val_loss: 355961.2188 - val_mean_squared_error: 355961.2188 - val_mean_absolute_error: 522.8967\n",
      "Epoch 780/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 436117.6875 - mean_squared_error: 436117.6875 - mean_absolute_error: 455.6251\n",
      "Epoch 00780: val_loss improved from 355961.21875 to 355538.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 483409.7417 - mean_squared_error: 483409.7500 - mean_absolute_error: 497.4829 - val_loss: 355538.9062 - val_mean_squared_error: 355538.9062 - val_mean_absolute_error: 522.4724\n",
      "Epoch 781/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 392867.1250 - mean_squared_error: 392867.1250 - mean_absolute_error: 477.4694\n",
      "Epoch 00781: val_loss improved from 355538.90625 to 355142.59375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 482732.1351 - mean_squared_error: 482732.1562 - mean_absolute_error: 496.8041 - val_loss: 355142.5938 - val_mean_squared_error: 355142.5938 - val_mean_absolute_error: 522.0352\n",
      "Epoch 782/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 591846.4375 - mean_squared_error: 591846.4375 - mean_absolute_error: 531.7587\n",
      "Epoch 00782: val_loss improved from 355142.59375 to 354733.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 482137.2261 - mean_squared_error: 482137.2500 - mean_absolute_error: 496.1907 - val_loss: 354733.9688 - val_mean_squared_error: 354733.9688 - val_mean_absolute_error: 521.5836\n",
      "Epoch 783/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 174815.8750 - mean_squared_error: 174815.8750 - mean_absolute_error: 371.0933\n",
      "Epoch 00783: val_loss improved from 354733.96875 to 354323.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 481537.1241 - mean_squared_error: 481537.1250 - mean_absolute_error: 495.5550 - val_loss: 354323.9062 - val_mean_squared_error: 354323.9062 - val_mean_absolute_error: 521.1463\n",
      "Epoch 784/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 481721.5000 - mean_squared_error: 481721.5000 - mean_absolute_error: 533.2651\n",
      "Epoch 00784: val_loss improved from 354323.90625 to 353882.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 480933.3775 - mean_squared_error: 480933.3750 - mean_absolute_error: 494.9742 - val_loss: 353882.9062 - val_mean_squared_error: 353882.9062 - val_mean_absolute_error: 520.7592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 785/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 227430.3438 - mean_squared_error: 227430.3438 - mean_absolute_error: 391.9702\n",
      "Epoch 00785: val_loss improved from 353882.90625 to 353456.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 480259.6746 - mean_squared_error: 480259.6875 - mean_absolute_error: 494.4242 - val_loss: 353456.8750 - val_mean_squared_error: 353456.8750 - val_mean_absolute_error: 520.4145\n",
      "Epoch 786/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 366263.5938 - mean_squared_error: 366263.5938 - mean_absolute_error: 441.5156\n",
      "Epoch 00786: val_loss improved from 353456.87500 to 352991.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 479670.4779 - mean_squared_error: 479670.5000 - mean_absolute_error: 493.9967 - val_loss: 352991.7812 - val_mean_squared_error: 352991.7812 - val_mean_absolute_error: 520.0798\n",
      "Epoch 787/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 225705.9375 - mean_squared_error: 225705.9375 - mean_absolute_error: 407.1743\n",
      "Epoch 00787: val_loss improved from 352991.78125 to 352544.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 479031.0570 - mean_squared_error: 479031.0625 - mean_absolute_error: 493.5650 - val_loss: 352544.6250 - val_mean_squared_error: 352544.6250 - val_mean_absolute_error: 519.7266\n",
      "Epoch 788/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 351365.8125 - mean_squared_error: 351365.8125 - mean_absolute_error: 456.3025\n",
      "Epoch 00788: val_loss improved from 352544.62500 to 352052.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 478436.3143 - mean_squared_error: 478436.3125 - mean_absolute_error: 493.1273 - val_loss: 352052.8125 - val_mean_squared_error: 352052.8125 - val_mean_absolute_error: 519.3458\n",
      "Epoch 789/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 185185.9688 - mean_squared_error: 185185.9688 - mean_absolute_error: 362.2374\n",
      "Epoch 00789: val_loss improved from 352052.81250 to 351508.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 477699.0809 - mean_squared_error: 477699.0938 - mean_absolute_error: 492.6673 - val_loss: 351508.2812 - val_mean_squared_error: 351508.2812 - val_mean_absolute_error: 518.9827\n",
      "Epoch 790/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 611340.0625 - mean_squared_error: 611340.0625 - mean_absolute_error: 539.2003\n",
      "Epoch 00790: val_loss improved from 351508.28125 to 350933.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 477137.4890 - mean_squared_error: 477137.5000 - mean_absolute_error: 492.3436 - val_loss: 350933.9375 - val_mean_squared_error: 350933.9375 - val_mean_absolute_error: 518.6253\n",
      "Epoch 791/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 766788.5625 - mean_squared_error: 766788.5625 - mean_absolute_error: 596.9402\n",
      "Epoch 00791: val_loss improved from 350933.93750 to 350438.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 476378.1783 - mean_squared_error: 476378.1875 - mean_absolute_error: 491.8587 - val_loss: 350438.7188 - val_mean_squared_error: 350438.7188 - val_mean_absolute_error: 518.2515\n",
      "Epoch 792/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 788711.5000 - mean_squared_error: 788711.5000 - mean_absolute_error: 615.3077\n",
      "Epoch 00792: val_loss improved from 350438.71875 to 349937.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 475710.0446 - mean_squared_error: 475710.0625 - mean_absolute_error: 491.3831 - val_loss: 349937.3750 - val_mean_squared_error: 349937.3750 - val_mean_absolute_error: 517.8613\n",
      "Epoch 793/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 384278.8125 - mean_squared_error: 384278.8125 - mean_absolute_error: 424.6111\n",
      "Epoch 00793: val_loss improved from 349937.37500 to 349427.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 474923.4853 - mean_squared_error: 474923.5000 - mean_absolute_error: 490.8749 - val_loss: 349427.0000 - val_mean_squared_error: 349427.0000 - val_mean_absolute_error: 517.4714\n",
      "Epoch 794/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 259039.0000 - mean_squared_error: 259039.0000 - mean_absolute_error: 424.1818\n",
      "Epoch 00794: val_loss improved from 349427.00000 to 348818.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 474194.8327 - mean_squared_error: 474194.8125 - mean_absolute_error: 490.4423 - val_loss: 348818.9375 - val_mean_squared_error: 348818.9375 - val_mean_absolute_error: 517.1071\n",
      "Epoch 795/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 641685.1250 - mean_squared_error: 641685.1250 - mean_absolute_error: 562.5718\n",
      "Epoch 00795: val_loss improved from 348818.93750 to 348187.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 473541.6875 - mean_squared_error: 473541.6875 - mean_absolute_error: 490.2068 - val_loss: 348187.0625 - val_mean_squared_error: 348187.0625 - val_mean_absolute_error: 516.7939\n",
      "Epoch 796/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 634272.8750 - mean_squared_error: 634272.8750 - mean_absolute_error: 573.9826\n",
      "Epoch 00796: val_loss improved from 348187.06250 to 347626.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 472816.8456 - mean_squared_error: 472816.8125 - mean_absolute_error: 490.0068 - val_loss: 347626.3438 - val_mean_squared_error: 347626.3438 - val_mean_absolute_error: 516.4819\n",
      "Epoch 797/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 597582.3125 - mean_squared_error: 597582.3125 - mean_absolute_error: 538.8088\n",
      "Epoch 00797: val_loss improved from 347626.34375 to 347110.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 472018.6471 - mean_squared_error: 472018.6562 - mean_absolute_error: 489.6722 - val_loss: 347110.0625 - val_mean_squared_error: 347110.0625 - val_mean_absolute_error: 516.1613\n",
      "Epoch 798/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 520297.6875 - mean_squared_error: 520297.6875 - mean_absolute_error: 509.3499\n",
      "Epoch 00798: val_loss improved from 347110.06250 to 346603.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 471361.7509 - mean_squared_error: 471361.7500 - mean_absolute_error: 489.4050 - val_loss: 346603.9688 - val_mean_squared_error: 346603.9688 - val_mean_absolute_error: 515.8336\n",
      "Epoch 799/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 257921.4688 - mean_squared_error: 257921.4688 - mean_absolute_error: 410.6595\n",
      "Epoch 00799: val_loss improved from 346603.96875 to 346071.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 470617.0294 - mean_squared_error: 470617.0625 - mean_absolute_error: 489.0576 - val_loss: 346071.1250 - val_mean_squared_error: 346071.1250 - val_mean_absolute_error: 515.4906\n",
      "Epoch 800/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 634784.3750 - mean_squared_error: 634784.3750 - mean_absolute_error: 569.3358\n",
      "Epoch 00800: val_loss improved from 346071.12500 to 345418.59375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 470008.0584 - mean_squared_error: 470008.0625 - mean_absolute_error: 488.7877 - val_loss: 345418.5938 - val_mean_squared_error: 345418.5938 - val_mean_absolute_error: 515.1417\n",
      "Epoch 801/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 214699.6562 - mean_squared_error: 214699.6562 - mean_absolute_error: 384.3465\n",
      "Epoch 00801: val_loss improved from 345418.59375 to 344884.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 469139.0404 - mean_squared_error: 469139.0312 - mean_absolute_error: 488.5356 - val_loss: 344884.4062 - val_mean_squared_error: 344884.4062 - val_mean_absolute_error: 514.7815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 802/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 219964.0000 - mean_squared_error: 219964.0000 - mean_absolute_error: 403.2982\n",
      "Epoch 00802: val_loss improved from 344884.40625 to 344430.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 468422.0248 - mean_squared_error: 468422.0312 - mean_absolute_error: 488.1051 - val_loss: 344430.3750 - val_mean_squared_error: 344430.3750 - val_mean_absolute_error: 514.3908\n",
      "Epoch 803/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 557211.0625 - mean_squared_error: 557211.0625 - mean_absolute_error: 522.3303\n",
      "Epoch 00803: val_loss improved from 344430.37500 to 343991.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 467836.7665 - mean_squared_error: 467836.7500 - mean_absolute_error: 487.6767 - val_loss: 343991.3438 - val_mean_squared_error: 343991.3438 - val_mean_absolute_error: 514.0005\n",
      "Epoch 804/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 543863.1250 - mean_squared_error: 543863.1250 - mean_absolute_error: 521.6470\n",
      "Epoch 00804: val_loss improved from 343991.34375 to 343596.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 467214.2022 - mean_squared_error: 467214.2188 - mean_absolute_error: 487.1669 - val_loss: 343596.5000 - val_mean_squared_error: 343596.5000 - val_mean_absolute_error: 513.5748\n",
      "Epoch 805/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 395297.6875 - mean_squared_error: 395297.6875 - mean_absolute_error: 430.5518\n",
      "Epoch 00805: val_loss improved from 343596.50000 to 343253.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 466600.5101 - mean_squared_error: 466600.5000 - mean_absolute_error: 486.5545 - val_loss: 343253.3125 - val_mean_squared_error: 343253.3125 - val_mean_absolute_error: 513.1196\n",
      "Epoch 806/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 588548.0000 - mean_squared_error: 588548.0000 - mean_absolute_error: 510.5982\n",
      "Epoch 00806: val_loss improved from 343253.31250 to 342882.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 466018.7004 - mean_squared_error: 466018.7188 - mean_absolute_error: 485.8439 - val_loss: 342882.2500 - val_mean_squared_error: 342882.2500 - val_mean_absolute_error: 512.6683\n",
      "Epoch 807/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 291928.1875 - mean_squared_error: 291928.1875 - mean_absolute_error: 466.1908\n",
      "Epoch 00807: val_loss improved from 342882.25000 to 342507.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 465462.8571 - mean_squared_error: 465462.8438 - mean_absolute_error: 485.2705 - val_loss: 342507.6250 - val_mean_squared_error: 342507.6250 - val_mean_absolute_error: 512.2334\n",
      "Epoch 808/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 519148.6875 - mean_squared_error: 519148.6875 - mean_absolute_error: 481.9730\n",
      "Epoch 00808: val_loss improved from 342507.62500 to 342139.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 464877.8676 - mean_squared_error: 464877.8750 - mean_absolute_error: 484.7005 - val_loss: 342139.2188 - val_mean_squared_error: 342139.2188 - val_mean_absolute_error: 511.8397\n",
      "Epoch 809/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 398365.4375 - mean_squared_error: 398365.4375 - mean_absolute_error: 428.6638\n",
      "Epoch 00809: val_loss improved from 342139.21875 to 341774.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 464310.3842 - mean_squared_error: 464310.3750 - mean_absolute_error: 484.2251 - val_loss: 341774.8750 - val_mean_squared_error: 341774.8750 - val_mean_absolute_error: 511.4685\n",
      "Epoch 810/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 322883.1250 - mean_squared_error: 322883.1250 - mean_absolute_error: 399.0575\n",
      "Epoch 00810: val_loss improved from 341774.87500 to 341385.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 463795.6434 - mean_squared_error: 463795.6562 - mean_absolute_error: 483.7639 - val_loss: 341385.3750 - val_mean_squared_error: 341385.3750 - val_mean_absolute_error: 511.0692\n",
      "Epoch 811/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 554124.1250 - mean_squared_error: 554124.1250 - mean_absolute_error: 523.6420\n",
      "Epoch 00811: val_loss improved from 341385.37500 to 340928.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 463210.8438 - mean_squared_error: 463210.8438 - mean_absolute_error: 483.2793 - val_loss: 340928.3750 - val_mean_squared_error: 340928.3750 - val_mean_absolute_error: 510.7173\n",
      "Epoch 812/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 784631.8125 - mean_squared_error: 784631.8125 - mean_absolute_error: 635.7727\n",
      "Epoch 00812: val_loss improved from 340928.37500 to 340501.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 462631.2123 - mean_squared_error: 462631.2188 - mean_absolute_error: 482.9211 - val_loss: 340501.4375 - val_mean_squared_error: 340501.4375 - val_mean_absolute_error: 510.3641\n",
      "Epoch 813/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 524149.3125 - mean_squared_error: 524149.3125 - mean_absolute_error: 466.6632\n",
      "Epoch 00813: val_loss improved from 340501.43750 to 340108.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 461991.1783 - mean_squared_error: 461991.1875 - mean_absolute_error: 482.5070 - val_loss: 340108.8438 - val_mean_squared_error: 340108.8438 - val_mean_absolute_error: 510.0495\n",
      "Epoch 814/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 382356.1562 - mean_squared_error: 382356.1562 - mean_absolute_error: 486.5185\n",
      "Epoch 00814: val_loss improved from 340108.84375 to 339715.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 461422.7941 - mean_squared_error: 461422.8125 - mean_absolute_error: 482.1892 - val_loss: 339715.8750 - val_mean_squared_error: 339715.8750 - val_mean_absolute_error: 509.7631\n",
      "Epoch 815/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 584796.6250 - mean_squared_error: 584796.6250 - mean_absolute_error: 474.5500\n",
      "Epoch 00815: val_loss improved from 339715.87500 to 339289.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 460945.3070 - mean_squared_error: 460945.2812 - mean_absolute_error: 481.9273 - val_loss: 339289.5625 - val_mean_squared_error: 339289.5625 - val_mean_absolute_error: 509.4713\n",
      "Epoch 816/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 371301.9062 - mean_squared_error: 371301.9062 - mean_absolute_error: 459.5915\n",
      "Epoch 00816: val_loss improved from 339289.56250 to 338892.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 460303.8180 - mean_squared_error: 460303.7812 - mean_absolute_error: 481.6169 - val_loss: 338892.6250 - val_mean_squared_error: 338892.6250 - val_mean_absolute_error: 509.1463\n",
      "Epoch 817/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 261197.2500 - mean_squared_error: 261197.2500 - mean_absolute_error: 413.7817\n",
      "Epoch 00817: val_loss improved from 338892.62500 to 338463.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 459745.0349 - mean_squared_error: 459745.0312 - mean_absolute_error: 481.3035 - val_loss: 338463.8750 - val_mean_squared_error: 338463.8750 - val_mean_absolute_error: 508.8071\n",
      "Epoch 818/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582283.3750 - mean_squared_error: 582283.3750 - mean_absolute_error: 528.7880\n",
      "Epoch 00818: val_loss improved from 338463.87500 to 337990.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 459206.7555 - mean_squared_error: 459206.7500 - mean_absolute_error: 481.0193 - val_loss: 337990.5625 - val_mean_squared_error: 337990.5625 - val_mean_absolute_error: 508.5112\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 819/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 208684.1562 - mean_squared_error: 208684.1562 - mean_absolute_error: 382.3103\n",
      "Epoch 00819: val_loss improved from 337990.56250 to 337545.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 458501.3006 - mean_squared_error: 458501.2812 - mean_absolute_error: 480.7568 - val_loss: 337545.9062 - val_mean_squared_error: 337545.9062 - val_mean_absolute_error: 508.2529\n",
      "Epoch 820/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 455391.7500 - mean_squared_error: 455391.7500 - mean_absolute_error: 486.0658\n",
      "Epoch 00820: val_loss improved from 337545.90625 to 337115.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 457990.5864 - mean_squared_error: 457990.5938 - mean_absolute_error: 480.5749 - val_loss: 337115.8438 - val_mean_squared_error: 337115.8438 - val_mean_absolute_error: 507.9679\n",
      "Epoch 821/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 347092.0000 - mean_squared_error: 347092.0000 - mean_absolute_error: 454.4175\n",
      "Epoch 00821: val_loss improved from 337115.84375 to 336730.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 457414.4283 - mean_squared_error: 457414.4375 - mean_absolute_error: 480.3039 - val_loss: 336730.8750 - val_mean_squared_error: 336730.8750 - val_mean_absolute_error: 507.6230\n",
      "Epoch 822/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 548205.6250 - mean_squared_error: 548205.6250 - mean_absolute_error: 486.2328\n",
      "Epoch 00822: val_loss improved from 336730.87500 to 336358.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 456885.6176 - mean_squared_error: 456885.6250 - mean_absolute_error: 479.9360 - val_loss: 336358.9375 - val_mean_squared_error: 336358.9375 - val_mean_absolute_error: 507.2308\n",
      "Epoch 823/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 352659.5000 - mean_squared_error: 352659.5000 - mean_absolute_error: 448.3176\n",
      "Epoch 00823: val_loss improved from 336358.93750 to 335983.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 456303.0579 - mean_squared_error: 456303.0625 - mean_absolute_error: 479.4578 - val_loss: 335983.2812 - val_mean_squared_error: 335983.2812 - val_mean_absolute_error: 506.8636\n",
      "Epoch 824/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 592342.8750 - mean_squared_error: 592342.8750 - mean_absolute_error: 523.2130\n",
      "Epoch 00824: val_loss improved from 335983.28125 to 335620.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 455738.8585 - mean_squared_error: 455738.8438 - mean_absolute_error: 479.0387 - val_loss: 335620.6562 - val_mean_squared_error: 335620.6562 - val_mean_absolute_error: 506.5249\n",
      "Epoch 825/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 424982.6562 - mean_squared_error: 424982.6562 - mean_absolute_error: 504.5410\n",
      "Epoch 00825: val_loss improved from 335620.65625 to 335219.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 455206.3971 - mean_squared_error: 455206.4062 - mean_absolute_error: 478.6908 - val_loss: 335219.0938 - val_mean_squared_error: 335219.0938 - val_mean_absolute_error: 506.1783\n",
      "Epoch 826/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 369306.6562 - mean_squared_error: 369306.6562 - mean_absolute_error: 441.8824\n",
      "Epoch 00826: val_loss improved from 335219.09375 to 334741.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 454612.2849 - mean_squared_error: 454612.2812 - mean_absolute_error: 478.3543 - val_loss: 334741.5312 - val_mean_squared_error: 334741.5312 - val_mean_absolute_error: 505.8615\n",
      "Epoch 827/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 362726.4062 - mean_squared_error: 362726.4062 - mean_absolute_error: 436.5706\n",
      "Epoch 00827: val_loss improved from 334741.53125 to 334260.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 453934.5441 - mean_squared_error: 453934.5312 - mean_absolute_error: 478.0685 - val_loss: 334260.2812 - val_mean_squared_error: 334260.2812 - val_mean_absolute_error: 505.5737\n",
      "Epoch 828/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 761066.3750 - mean_squared_error: 761066.3750 - mean_absolute_error: 597.1191\n",
      "Epoch 00828: val_loss improved from 334260.28125 to 333773.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 453456.7767 - mean_squared_error: 453456.7812 - mean_absolute_error: 477.9307 - val_loss: 333773.8750 - val_mean_squared_error: 333773.8750 - val_mean_absolute_error: 505.2703\n",
      "Epoch 829/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 240120.7812 - mean_squared_error: 240120.7812 - mean_absolute_error: 418.5880\n",
      "Epoch 00829: val_loss improved from 333773.87500 to 333355.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 452707.6714 - mean_squared_error: 452707.6562 - mean_absolute_error: 477.6711 - val_loss: 333355.8438 - val_mean_squared_error: 333355.8438 - val_mean_absolute_error: 504.9646\n",
      "Epoch 830/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 249525.3281 - mean_squared_error: 249525.3281 - mean_absolute_error: 406.3026\n",
      "Epoch 00830: val_loss improved from 333355.84375 to 332944.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 452081.7500 - mean_squared_error: 452081.7500 - mean_absolute_error: 477.3007 - val_loss: 332944.6250 - val_mean_squared_error: 332944.6250 - val_mean_absolute_error: 504.6376\n",
      "Epoch 831/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 699769.9375 - mean_squared_error: 699769.9375 - mean_absolute_error: 539.0424\n",
      "Epoch 00831: val_loss improved from 332944.62500 to 332451.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 451638.7748 - mean_squared_error: 451638.7500 - mean_absolute_error: 477.0869 - val_loss: 332451.3438 - val_mean_squared_error: 332451.3438 - val_mean_absolute_error: 504.3149\n",
      "Epoch 832/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 564901.1250 - mean_squared_error: 564901.1250 - mean_absolute_error: 524.5233\n",
      "Epoch 00832: val_loss improved from 332451.34375 to 332002.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 450932.5090 - mean_squared_error: 450932.5312 - mean_absolute_error: 476.8267 - val_loss: 332002.5000 - val_mean_squared_error: 332002.5000 - val_mean_absolute_error: 503.9920\n",
      "Epoch 833/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 715284.3125 - mean_squared_error: 715284.3125 - mean_absolute_error: 546.3160\n",
      "Epoch 00833: val_loss improved from 332002.50000 to 331598.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 450344.0588 - mean_squared_error: 450344.0625 - mean_absolute_error: 476.5339 - val_loss: 331598.5000 - val_mean_squared_error: 331598.5000 - val_mean_absolute_error: 503.6676\n",
      "Epoch 834/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 543481.1250 - mean_squared_error: 543481.1250 - mean_absolute_error: 485.3029\n",
      "Epoch 00834: val_loss improved from 331598.50000 to 331233.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 449716.1452 - mean_squared_error: 449716.1562 - mean_absolute_error: 476.1908 - val_loss: 331233.9375 - val_mean_squared_error: 331233.9375 - val_mean_absolute_error: 503.3144\n",
      "Epoch 835/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 474751.6250 - mean_squared_error: 474751.6250 - mean_absolute_error: 486.1987\n",
      "Epoch 00835: val_loss improved from 331233.93750 to 330909.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 449204.9035 - mean_squared_error: 449204.8750 - mean_absolute_error: 475.8040 - val_loss: 330909.0625 - val_mean_squared_error: 330909.0625 - val_mean_absolute_error: 502.9596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 836/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 527281.1250 - mean_squared_error: 527281.1250 - mean_absolute_error: 512.1098\n",
      "Epoch 00836: val_loss improved from 330909.06250 to 330572.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 448691.2004 - mean_squared_error: 448691.2188 - mean_absolute_error: 475.4032 - val_loss: 330572.7812 - val_mean_squared_error: 330572.7812 - val_mean_absolute_error: 502.6254\n",
      "Epoch 837/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 700031.1250 - mean_squared_error: 700031.1250 - mean_absolute_error: 554.2826\n",
      "Epoch 00837: val_loss improved from 330572.78125 to 330238.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 448210.2362 - mean_squared_error: 448210.2500 - mean_absolute_error: 475.0462 - val_loss: 330238.8750 - val_mean_squared_error: 330238.8750 - val_mean_absolute_error: 502.2531\n",
      "Epoch 838/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 548474.1250 - mean_squared_error: 548474.1250 - mean_absolute_error: 484.7551\n",
      "Epoch 00838: val_loss improved from 330238.87500 to 329897.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 447724.1149 - mean_squared_error: 447724.1250 - mean_absolute_error: 474.6695 - val_loss: 329897.8125 - val_mean_squared_error: 329897.8125 - val_mean_absolute_error: 501.9356\n",
      "Epoch 839/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 213651.6250 - mean_squared_error: 213651.6250 - mean_absolute_error: 373.0677\n",
      "Epoch 00839: val_loss improved from 329897.81250 to 329532.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 447143.0147 - mean_squared_error: 447143.0000 - mean_absolute_error: 474.3362 - val_loss: 329532.7812 - val_mean_squared_error: 329532.7812 - val_mean_absolute_error: 501.6786\n",
      "Epoch 840/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 236092.2188 - mean_squared_error: 236092.2188 - mean_absolute_error: 384.1916\n",
      "Epoch 00840: val_loss improved from 329532.78125 to 329075.81250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 446550.1985 - mean_squared_error: 446550.1875 - mean_absolute_error: 474.0436 - val_loss: 329075.8125 - val_mean_squared_error: 329075.8125 - val_mean_absolute_error: 501.3660\n",
      "Epoch 841/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 615543.6875 - mean_squared_error: 615543.6875 - mean_absolute_error: 551.1992\n",
      "Epoch 00841: val_loss improved from 329075.81250 to 328567.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 446120.0211 - mean_squared_error: 446120.0000 - mean_absolute_error: 473.9325 - val_loss: 328567.5625 - val_mean_squared_error: 328567.5625 - val_mean_absolute_error: 501.0273\n",
      "Epoch 842/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 398928.5000 - mean_squared_error: 398928.5000 - mean_absolute_error: 465.3237\n",
      "Epoch 00842: val_loss improved from 328567.56250 to 328153.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 445335.7638 - mean_squared_error: 445335.7500 - mean_absolute_error: 473.5956 - val_loss: 328153.0938 - val_mean_squared_error: 328153.0938 - val_mean_absolute_error: 500.7010\n",
      "Epoch 843/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 511711.5625 - mean_squared_error: 511711.5625 - mean_absolute_error: 511.5792\n",
      "Epoch 00843: val_loss improved from 328153.09375 to 327769.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 444774.5524 - mean_squared_error: 444774.5625 - mean_absolute_error: 473.2700 - val_loss: 327769.9688 - val_mean_squared_error: 327769.9688 - val_mean_absolute_error: 500.4041\n",
      "Epoch 844/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 513292.3750 - mean_squared_error: 513292.3750 - mean_absolute_error: 501.9051\n",
      "Epoch 00844: val_loss improved from 327769.96875 to 327404.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 444219.4403 - mean_squared_error: 444219.4375 - mean_absolute_error: 473.0070 - val_loss: 327404.8750 - val_mean_squared_error: 327404.8750 - val_mean_absolute_error: 500.0887\n",
      "Epoch 845/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 342277.6250 - mean_squared_error: 342277.6250 - mean_absolute_error: 450.4636\n",
      "Epoch 00845: val_loss improved from 327404.87500 to 327072.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 443701.9430 - mean_squared_error: 443701.9375 - mean_absolute_error: 472.6791 - val_loss: 327072.4375 - val_mean_squared_error: 327072.4375 - val_mean_absolute_error: 499.7584\n",
      "Epoch 846/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 327129.6562 - mean_squared_error: 327129.6562 - mean_absolute_error: 447.0730\n",
      "Epoch 00846: val_loss improved from 327072.43750 to 326711.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 443172.3971 - mean_squared_error: 443172.3750 - mean_absolute_error: 472.3512 - val_loss: 326711.2188 - val_mean_squared_error: 326711.2188 - val_mean_absolute_error: 499.4452\n",
      "Epoch 847/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 341114.5000 - mean_squared_error: 341114.5000 - mean_absolute_error: 428.3389\n",
      "Epoch 00847: val_loss improved from 326711.21875 to 326289.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 442639.3980 - mean_squared_error: 442639.4062 - mean_absolute_error: 472.0135 - val_loss: 326289.1562 - val_mean_squared_error: 326289.1562 - val_mean_absolute_error: 499.1415\n",
      "Epoch 848/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 680747.1875 - mean_squared_error: 680747.1875 - mean_absolute_error: 537.1441\n",
      "Epoch 00848: val_loss improved from 326289.15625 to 325888.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 442169.4596 - mean_squared_error: 442169.4688 - mean_absolute_error: 471.8498 - val_loss: 325888.5625 - val_mean_squared_error: 325888.5625 - val_mean_absolute_error: 498.8882\n",
      "Epoch 849/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 482533.6875 - mean_squared_error: 482533.6875 - mean_absolute_error: 491.2955\n",
      "Epoch 00849: val_loss improved from 325888.56250 to 325552.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 441557.8015 - mean_squared_error: 441557.8125 - mean_absolute_error: 471.6426 - val_loss: 325552.1562 - val_mean_squared_error: 325552.1562 - val_mean_absolute_error: 498.6032\n",
      "Epoch 850/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 415531.0312 - mean_squared_error: 415531.0312 - mean_absolute_error: 457.8681\n",
      "Epoch 00850: val_loss improved from 325552.15625 to 325253.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 441040.9269 - mean_squared_error: 441040.9062 - mean_absolute_error: 471.3303 - val_loss: 325253.8438 - val_mean_squared_error: 325253.8438 - val_mean_absolute_error: 498.2859\n",
      "Epoch 851/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 356665.2188 - mean_squared_error: 356665.2188 - mean_absolute_error: 434.2192\n",
      "Epoch 00851: val_loss improved from 325253.84375 to 324965.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 440592.0478 - mean_squared_error: 440592.0625 - mean_absolute_error: 471.0025 - val_loss: 324965.3438 - val_mean_squared_error: 324965.3438 - val_mean_absolute_error: 497.9476\n",
      "Epoch 852/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 530495.9375 - mean_squared_error: 530495.9375 - mean_absolute_error: 491.2536\n",
      "Epoch 00852: val_loss improved from 324965.34375 to 324674.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 440121.8824 - mean_squared_error: 440121.8750 - mean_absolute_error: 470.5773 - val_loss: 324674.9375 - val_mean_squared_error: 324674.9375 - val_mean_absolute_error: 497.5927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 853/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 538330.0000 - mean_squared_error: 538330.0000 - mean_absolute_error: 492.1876\n",
      "Epoch 00853: val_loss improved from 324674.93750 to 324381.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 439670.8336 - mean_squared_error: 439670.8125 - mean_absolute_error: 470.1882 - val_loss: 324381.8750 - val_mean_squared_error: 324381.8750 - val_mean_absolute_error: 497.2228\n",
      "Epoch 854/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 414855.9062 - mean_squared_error: 414855.9062 - mean_absolute_error: 454.5225\n",
      "Epoch 00854: val_loss improved from 324381.87500 to 324098.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 439209.8548 - mean_squared_error: 439209.8438 - mean_absolute_error: 469.7700 - val_loss: 324098.0938 - val_mean_squared_error: 324098.0938 - val_mean_absolute_error: 496.8578\n",
      "Epoch 855/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 409707.1562 - mean_squared_error: 409707.1562 - mean_absolute_error: 442.8966\n",
      "Epoch 00855: val_loss improved from 324098.09375 to 323826.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 438736.7647 - mean_squared_error: 438736.7500 - mean_absolute_error: 469.2987 - val_loss: 323826.3750 - val_mean_squared_error: 323826.3750 - val_mean_absolute_error: 496.4713\n",
      "Epoch 856/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 182355.5312 - mean_squared_error: 182355.5312 - mean_absolute_error: 357.6033\n",
      "Epoch 00856: val_loss improved from 323826.37500 to 323563.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 438295.1213 - mean_squared_error: 438295.1250 - mean_absolute_error: 468.7732 - val_loss: 323563.8438 - val_mean_squared_error: 323563.8438 - val_mean_absolute_error: 496.0444\n",
      "Epoch 857/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 489374.2500 - mean_squared_error: 489374.2500 - mean_absolute_error: 482.8183\n",
      "Epoch 00857: val_loss improved from 323563.84375 to 323232.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 437853.5735 - mean_squared_error: 437853.5938 - mean_absolute_error: 468.3737 - val_loss: 323232.4375 - val_mean_squared_error: 323232.4375 - val_mean_absolute_error: 495.6200\n",
      "Epoch 858/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 334527.1875 - mean_squared_error: 334527.1875 - mean_absolute_error: 454.9422\n",
      "Epoch 00858: val_loss improved from 323232.43750 to 322904.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 437292.8346 - mean_squared_error: 437292.8125 - mean_absolute_error: 467.9282 - val_loss: 322904.6562 - val_mean_squared_error: 322904.6562 - val_mean_absolute_error: 495.2255\n",
      "Epoch 859/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 321929.0625 - mean_squared_error: 321929.0625 - mean_absolute_error: 416.7692\n",
      "Epoch 00859: val_loss improved from 322904.65625 to 322586.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 436812.9017 - mean_squared_error: 436812.9062 - mean_absolute_error: 467.5620 - val_loss: 322586.1250 - val_mean_squared_error: 322586.1250 - val_mean_absolute_error: 494.8426\n",
      "Epoch 860/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 505654.1875 - mean_squared_error: 505654.1875 - mean_absolute_error: 488.2155\n",
      "Epoch 00860: val_loss improved from 322586.12500 to 322284.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 436324.8989 - mean_squared_error: 436324.9062 - mean_absolute_error: 467.1615 - val_loss: 322284.6562 - val_mean_squared_error: 322284.6562 - val_mean_absolute_error: 494.4603\n",
      "Epoch 861/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 337951.9062 - mean_squared_error: 337951.9062 - mean_absolute_error: 411.8949\n",
      "Epoch 00861: val_loss improved from 322284.65625 to 321942.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 435792.6360 - mean_squared_error: 435792.6250 - mean_absolute_error: 466.7483 - val_loss: 321942.4375 - val_mean_squared_error: 321942.4375 - val_mean_absolute_error: 494.1198\n",
      "Epoch 862/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 353315.1562 - mean_squared_error: 353315.1562 - mean_absolute_error: 433.3716\n",
      "Epoch 00862: val_loss improved from 321942.43750 to 321608.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 435293.9504 - mean_squared_error: 435293.9688 - mean_absolute_error: 466.4413 - val_loss: 321608.5000 - val_mean_squared_error: 321608.5000 - val_mean_absolute_error: 493.7977\n",
      "Epoch 863/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 575246.1250 - mean_squared_error: 575246.1250 - mean_absolute_error: 535.6386\n",
      "Epoch 00863: val_loss improved from 321608.50000 to 321304.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 434865.5827 - mean_squared_error: 434865.5938 - mean_absolute_error: 466.1902 - val_loss: 321304.0938 - val_mean_squared_error: 321304.0938 - val_mean_absolute_error: 493.4997\n",
      "Epoch 864/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 466484.5000 - mean_squared_error: 466484.5000 - mean_absolute_error: 487.4191\n",
      "Epoch 00864: val_loss improved from 321304.09375 to 321018.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 434375.6029 - mean_squared_error: 434375.6250 - mean_absolute_error: 465.9126 - val_loss: 321018.1250 - val_mean_squared_error: 321018.1250 - val_mean_absolute_error: 493.2374\n",
      "Epoch 865/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 298292.8125 - mean_squared_error: 298292.8125 - mean_absolute_error: 395.1008\n",
      "Epoch 00865: val_loss improved from 321018.12500 to 320689.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 433918.9559 - mean_squared_error: 433918.9375 - mean_absolute_error: 465.6671 - val_loss: 320689.9375 - val_mean_squared_error: 320689.9375 - val_mean_absolute_error: 492.9468\n",
      "Epoch 866/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 506990.4688 - mean_squared_error: 506990.4688 - mean_absolute_error: 495.2011\n",
      "Epoch 00866: val_loss improved from 320689.93750 to 320288.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 433490.8208 - mean_squared_error: 433490.8125 - mean_absolute_error: 465.4213 - val_loss: 320288.5000 - val_mean_squared_error: 320288.5000 - val_mean_absolute_error: 492.6217\n",
      "Epoch 867/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 554305.2500 - mean_squared_error: 554305.2500 - mean_absolute_error: 504.7962\n",
      "Epoch 00867: val_loss improved from 320288.50000 to 319938.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 432897.7610 - mean_squared_error: 432897.7500 - mean_absolute_error: 465.1606 - val_loss: 319938.8438 - val_mean_squared_error: 319938.8438 - val_mean_absolute_error: 492.2687\n",
      "Epoch 868/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 702592.8125 - mean_squared_error: 702592.8125 - mean_absolute_error: 591.7061\n",
      "Epoch 00868: val_loss improved from 319938.84375 to 319606.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 432349.6875 - mean_squared_error: 432349.6875 - mean_absolute_error: 464.7912 - val_loss: 319606.0625 - val_mean_squared_error: 319606.0625 - val_mean_absolute_error: 491.9199\n",
      "Epoch 869/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 220048.4062 - mean_squared_error: 220048.4062 - mean_absolute_error: 398.0275\n",
      "Epoch 00869: val_loss improved from 319606.06250 to 319278.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 431798.9099 - mean_squared_error: 431798.8750 - mean_absolute_error: 464.4780 - val_loss: 319278.2500 - val_mean_squared_error: 319278.2500 - val_mean_absolute_error: 491.5830\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 870/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 448676.1562 - mean_squared_error: 448676.1562 - mean_absolute_error: 460.2334\n",
      "Epoch 00870: val_loss improved from 319278.25000 to 318946.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 431332.2838 - mean_squared_error: 431332.2812 - mean_absolute_error: 464.1468 - val_loss: 318946.4375 - val_mean_squared_error: 318946.4375 - val_mean_absolute_error: 491.2589\n",
      "Epoch 871/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 479833.0938 - mean_squared_error: 479833.0938 - mean_absolute_error: 478.3051\n",
      "Epoch 00871: val_loss improved from 318946.43750 to 318612.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 430855.9430 - mean_squared_error: 430855.9688 - mean_absolute_error: 463.8813 - val_loss: 318612.6250 - val_mean_squared_error: 318612.6250 - val_mean_absolute_error: 490.9537\n",
      "Epoch 872/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 528381.0000 - mean_squared_error: 528381.0000 - mean_absolute_error: 492.0504\n",
      "Epoch 00872: val_loss improved from 318612.62500 to 318290.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 430390.3658 - mean_squared_error: 430390.3438 - mean_absolute_error: 463.6550 - val_loss: 318290.4688 - val_mean_squared_error: 318290.4688 - val_mean_absolute_error: 490.6551\n",
      "Epoch 873/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 392363.4375 - mean_squared_error: 392363.4375 - mean_absolute_error: 480.3788\n",
      "Epoch 00873: val_loss improved from 318290.46875 to 317998.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 429884.0294 - mean_squared_error: 429884.0312 - mean_absolute_error: 463.3714 - val_loss: 317998.2188 - val_mean_squared_error: 317998.2188 - val_mean_absolute_error: 490.3388\n",
      "Epoch 874/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 511923.9375 - mean_squared_error: 511923.9375 - mean_absolute_error: 522.1052\n",
      "Epoch 00874: val_loss improved from 317998.21875 to 317708.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 429442.9099 - mean_squared_error: 429442.9062 - mean_absolute_error: 463.0703 - val_loss: 317708.8438 - val_mean_squared_error: 317708.8438 - val_mean_absolute_error: 490.0180\n",
      "Epoch 875/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 339153.6250 - mean_squared_error: 339153.6250 - mean_absolute_error: 394.0794\n",
      "Epoch 00875: val_loss improved from 317708.84375 to 317413.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 428980.5074 - mean_squared_error: 428980.5000 - mean_absolute_error: 462.7445 - val_loss: 317413.6250 - val_mean_squared_error: 317413.6250 - val_mean_absolute_error: 489.6552\n",
      "Epoch 876/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 505212.9062 - mean_squared_error: 505212.9062 - mean_absolute_error: 513.3956\n",
      "Epoch 00876: val_loss improved from 317413.62500 to 317077.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 428552.2408 - mean_squared_error: 428552.2500 - mean_absolute_error: 462.4187 - val_loss: 317077.0625 - val_mean_squared_error: 317077.0625 - val_mean_absolute_error: 489.3165\n",
      "Epoch 877/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 484650.4375 - mean_squared_error: 484650.4375 - mean_absolute_error: 502.7861\n",
      "Epoch 00877: val_loss improved from 317077.06250 to 316795.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 428018.3704 - mean_squared_error: 428018.3750 - mean_absolute_error: 462.0916 - val_loss: 316795.0938 - val_mean_squared_error: 316795.0938 - val_mean_absolute_error: 489.0028\n",
      "Epoch 878/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 164305.8594 - mean_squared_error: 164305.8594 - mean_absolute_error: 323.4977\n",
      "Epoch 00878: val_loss improved from 316795.09375 to 316538.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 427570.6342 - mean_squared_error: 427570.6562 - mean_absolute_error: 461.8190 - val_loss: 316538.1562 - val_mean_squared_error: 316538.1562 - val_mean_absolute_error: 488.6860\n",
      "Epoch 879/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 502316.2500 - mean_squared_error: 502316.2500 - mean_absolute_error: 450.4610\n",
      "Epoch 00879: val_loss improved from 316538.15625 to 316296.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 455us/sample - loss: 427164.2132 - mean_squared_error: 427164.2188 - mean_absolute_error: 461.4503 - val_loss: 316296.3750 - val_mean_squared_error: 316296.3750 - val_mean_absolute_error: 488.3230\n",
      "Epoch 880/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 637263.0000 - mean_squared_error: 637263.0000 - mean_absolute_error: 525.4473\n",
      "Epoch 00880: val_loss improved from 316296.37500 to 316028.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 426789.3649 - mean_squared_error: 426789.3438 - mean_absolute_error: 461.0953 - val_loss: 316028.1250 - val_mean_squared_error: 316028.1250 - val_mean_absolute_error: 487.9363\n",
      "Epoch 881/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 479052.0625 - mean_squared_error: 479052.0625 - mean_absolute_error: 487.7567\n",
      "Epoch 00881: val_loss improved from 316028.12500 to 315780.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 426341.6581 - mean_squared_error: 426341.6562 - mean_absolute_error: 460.7019 - val_loss: 315780.1250 - val_mean_squared_error: 315780.1250 - val_mean_absolute_error: 487.5343\n",
      "Epoch 882/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 377443.3125 - mean_squared_error: 377443.3125 - mean_absolute_error: 457.9110\n",
      "Epoch 00882: val_loss improved from 315780.12500 to 315574.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 425900.6797 - mean_squared_error: 425900.7188 - mean_absolute_error: 460.2449 - val_loss: 315574.9062 - val_mean_squared_error: 315574.9062 - val_mean_absolute_error: 487.1333\n",
      "Epoch 883/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 310930.5312 - mean_squared_error: 310930.5312 - mean_absolute_error: 428.2496\n",
      "Epoch 00883: val_loss improved from 315574.90625 to 315348.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 425540.1618 - mean_squared_error: 425540.1875 - mean_absolute_error: 459.7970 - val_loss: 315348.0938 - val_mean_squared_error: 315348.0938 - val_mean_absolute_error: 486.7383\n",
      "Epoch 884/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 503058.5000 - mean_squared_error: 503058.5000 - mean_absolute_error: 497.6937\n",
      "Epoch 00884: val_loss improved from 315348.09375 to 315032.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 425103.1176 - mean_squared_error: 425103.1250 - mean_absolute_error: 459.3562 - val_loss: 315032.5312 - val_mean_squared_error: 315032.5312 - val_mean_absolute_error: 486.3365\n",
      "Epoch 885/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 556300.7500 - mean_squared_error: 556300.7500 - mean_absolute_error: 521.4973\n",
      "Epoch 00885: val_loss improved from 315032.53125 to 314735.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 424584.2574 - mean_squared_error: 424584.2500 - mean_absolute_error: 458.9474 - val_loss: 314735.1250 - val_mean_squared_error: 314735.1250 - val_mean_absolute_error: 485.9285\n",
      "Epoch 886/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 201658.0000 - mean_squared_error: 201658.0000 - mean_absolute_error: 357.0154\n",
      "Epoch 00886: val_loss improved from 314735.12500 to 314418.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 424070.2105 - mean_squared_error: 424070.2188 - mean_absolute_error: 458.5221 - val_loss: 314418.8750 - val_mean_squared_error: 314418.8750 - val_mean_absolute_error: 485.5383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 887/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 325264.8750 - mean_squared_error: 325264.8750 - mean_absolute_error: 411.6624\n",
      "Epoch 00887: val_loss improved from 314418.87500 to 314119.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 423585.7059 - mean_squared_error: 423585.7188 - mean_absolute_error: 458.1810 - val_loss: 314119.3750 - val_mean_squared_error: 314119.3750 - val_mean_absolute_error: 485.1600\n",
      "Epoch 888/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 320908.5312 - mean_squared_error: 320908.5312 - mean_absolute_error: 425.9371\n",
      "Epoch 00888: val_loss improved from 314119.37500 to 313869.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 423100.6326 - mean_squared_error: 423100.6250 - mean_absolute_error: 457.7929 - val_loss: 313869.8750 - val_mean_squared_error: 313869.8750 - val_mean_absolute_error: 484.8107\n",
      "Epoch 889/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 381398.6250 - mean_squared_error: 381398.6250 - mean_absolute_error: 427.5383\n",
      "Epoch 00889: val_loss improved from 313869.87500 to 313515.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 422626.2353 - mean_squared_error: 422626.2500 - mean_absolute_error: 457.4379 - val_loss: 313515.4688 - val_mean_squared_error: 313515.4688 - val_mean_absolute_error: 484.4941\n",
      "Epoch 890/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 555064.2500 - mean_squared_error: 555064.2500 - mean_absolute_error: 510.2450\n",
      "Epoch 00890: val_loss improved from 313515.46875 to 313013.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 422152.5175 - mean_squared_error: 422152.5312 - mean_absolute_error: 457.2607 - val_loss: 313013.7188 - val_mean_squared_error: 313013.7188 - val_mean_absolute_error: 484.1624\n",
      "Epoch 891/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 272697.7188 - mean_squared_error: 272697.7188 - mean_absolute_error: 353.3679\n",
      "Epoch 00891: val_loss improved from 313013.71875 to 312591.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 421309.7206 - mean_squared_error: 421309.7188 - mean_absolute_error: 457.0206 - val_loss: 312591.2812 - val_mean_squared_error: 312591.2812 - val_mean_absolute_error: 483.8205\n",
      "Epoch 892/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 316821.1250 - mean_squared_error: 316821.1250 - mean_absolute_error: 422.5231\n",
      "Epoch 00892: val_loss improved from 312591.28125 to 312147.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 420656.8566 - mean_squared_error: 420656.8438 - mean_absolute_error: 456.7751 - val_loss: 312147.8750 - val_mean_squared_error: 312147.8750 - val_mean_absolute_error: 483.4865\n",
      "Epoch 893/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 170726.8438 - mean_squared_error: 170726.8438 - mean_absolute_error: 367.5180\n",
      "Epoch 00893: val_loss improved from 312147.87500 to 311741.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 419987.5028 - mean_squared_error: 419987.5312 - mean_absolute_error: 456.6982 - val_loss: 311741.6250 - val_mean_squared_error: 311741.6250 - val_mean_absolute_error: 483.1452\n",
      "Epoch 894/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 469264.5000 - mean_squared_error: 469264.5000 - mean_absolute_error: 446.2720\n",
      "Epoch 00894: val_loss improved from 311741.62500 to 311362.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 419421.4191 - mean_squared_error: 419421.4062 - mean_absolute_error: 456.5130 - val_loss: 311362.2188 - val_mean_squared_error: 311362.2188 - val_mean_absolute_error: 482.8103\n",
      "Epoch 895/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 385020.3125 - mean_squared_error: 385020.3125 - mean_absolute_error: 432.8021\n",
      "Epoch 00895: val_loss improved from 311362.21875 to 310940.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 418790.8971 - mean_squared_error: 418790.8750 - mean_absolute_error: 456.2931 - val_loss: 310940.5312 - val_mean_squared_error: 310940.5312 - val_mean_absolute_error: 482.4286\n",
      "Epoch 896/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 470173.8750 - mean_squared_error: 470173.8750 - mean_absolute_error: 448.4321\n",
      "Epoch 00896: val_loss improved from 310940.53125 to 310529.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 418156.6549 - mean_squared_error: 418156.6562 - mean_absolute_error: 456.0774 - val_loss: 310529.2812 - val_mean_squared_error: 310529.2812 - val_mean_absolute_error: 482.0498\n",
      "Epoch 897/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 311434.8438 - mean_squared_error: 311434.8438 - mean_absolute_error: 404.7276\n",
      "Epoch 00897: val_loss improved from 310529.28125 to 310190.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 417491.7413 - mean_squared_error: 417491.7500 - mean_absolute_error: 455.8510 - val_loss: 310190.9375 - val_mean_squared_error: 310190.9375 - val_mean_absolute_error: 481.6862\n",
      "Epoch 898/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 371760.9062 - mean_squared_error: 371760.9062 - mean_absolute_error: 478.4510\n",
      "Epoch 00898: val_loss improved from 310190.93750 to 309873.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 416985.1838 - mean_squared_error: 416985.2188 - mean_absolute_error: 455.6190 - val_loss: 309873.7188 - val_mean_squared_error: 309873.7188 - val_mean_absolute_error: 481.3340\n",
      "Epoch 899/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 653874.5625 - mean_squared_error: 653874.5625 - mean_absolute_error: 544.4357\n",
      "Epoch 00899: val_loss improved from 309873.71875 to 309560.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 416476.9173 - mean_squared_error: 416476.9062 - mean_absolute_error: 455.3679 - val_loss: 309560.4688 - val_mean_squared_error: 309560.4688 - val_mean_absolute_error: 480.9695\n",
      "Epoch 900/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 468824.3125 - mean_squared_error: 468824.3125 - mean_absolute_error: 446.2598\n",
      "Epoch 00900: val_loss improved from 309560.46875 to 309246.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 415949.8676 - mean_squared_error: 415949.8750 - mean_absolute_error: 455.0864 - val_loss: 309246.6562 - val_mean_squared_error: 309246.6562 - val_mean_absolute_error: 480.6061\n",
      "Epoch 901/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 546661.5000 - mean_squared_error: 546661.5000 - mean_absolute_error: 509.1783\n",
      "Epoch 00901: val_loss improved from 309246.65625 to 308969.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 415450.7017 - mean_squared_error: 415450.7188 - mean_absolute_error: 454.7981 - val_loss: 308969.4688 - val_mean_squared_error: 308969.4688 - val_mean_absolute_error: 480.2068\n",
      "Epoch 902/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 711629.9375 - mean_squared_error: 711629.9375 - mean_absolute_error: 587.6036\n",
      "Epoch 00902: val_loss improved from 308969.46875 to 308714.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 414993.6875 - mean_squared_error: 414993.6875 - mean_absolute_error: 454.4321 - val_loss: 308714.7812 - val_mean_squared_error: 308714.7812 - val_mean_absolute_error: 479.7822\n",
      "Epoch 903/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 372772.3125 - mean_squared_error: 372772.3125 - mean_absolute_error: 421.6364\n",
      "Epoch 00903: val_loss improved from 308714.78125 to 308487.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 414502.1985 - mean_squared_error: 414502.2188 - mean_absolute_error: 454.0093 - val_loss: 308487.5000 - val_mean_squared_error: 308487.5000 - val_mean_absolute_error: 479.3391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 904/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 298437.0000 - mean_squared_error: 298437.0000 - mean_absolute_error: 412.0911\n",
      "Epoch 00904: val_loss improved from 308487.50000 to 308215.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 414075.4338 - mean_squared_error: 414075.4375 - mean_absolute_error: 453.5062 - val_loss: 308215.1562 - val_mean_squared_error: 308215.1562 - val_mean_absolute_error: 478.8983\n",
      "Epoch 905/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 346673.3750 - mean_squared_error: 346673.3750 - mean_absolute_error: 406.7742\n",
      "Epoch 00905: val_loss improved from 308215.15625 to 307883.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 413599.3419 - mean_squared_error: 413599.3438 - mean_absolute_error: 453.1498 - val_loss: 307883.7812 - val_mean_squared_error: 307883.7812 - val_mean_absolute_error: 478.4881\n",
      "Epoch 906/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 470042.8438 - mean_squared_error: 470042.8438 - mean_absolute_error: 486.6610\n",
      "Epoch 00906: val_loss improved from 307883.78125 to 307551.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 413001.2132 - mean_squared_error: 413001.2500 - mean_absolute_error: 452.7947 - val_loss: 307551.9062 - val_mean_squared_error: 307551.9062 - val_mean_absolute_error: 478.1782\n",
      "Epoch 907/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 518377.9688 - mean_squared_error: 518377.9688 - mean_absolute_error: 518.0515\n",
      "Epoch 00907: val_loss improved from 307551.90625 to 307210.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 412541.3911 - mean_squared_error: 412541.4062 - mean_absolute_error: 452.7426 - val_loss: 307210.2188 - val_mean_squared_error: 307210.2188 - val_mean_absolute_error: 477.8685\n",
      "Epoch 908/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 182546.7188 - mean_squared_error: 182546.7188 - mean_absolute_error: 352.3181\n",
      "Epoch 00908: val_loss improved from 307210.21875 to 306930.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 411893.0184 - mean_squared_error: 411893.0312 - mean_absolute_error: 452.5230 - val_loss: 306930.8750 - val_mean_squared_error: 306930.8750 - val_mean_absolute_error: 477.5738\n",
      "Epoch 909/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 742769.5000 - mean_squared_error: 742769.5000 - mean_absolute_error: 636.1272\n",
      "Epoch 00909: val_loss improved from 306930.87500 to 306651.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 411588.2158 - mean_squared_error: 411588.2188 - mean_absolute_error: 452.4523 - val_loss: 306651.8438 - val_mean_squared_error: 306651.8438 - val_mean_absolute_error: 477.3293\n",
      "Epoch 910/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 625141.2500 - mean_squared_error: 625141.2500 - mean_absolute_error: 513.1335\n",
      "Epoch 00910: val_loss improved from 306651.84375 to 306392.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 411072.0349 - mean_squared_error: 411072.0625 - mean_absolute_error: 452.2825 - val_loss: 306392.2188 - val_mean_squared_error: 306392.2188 - val_mean_absolute_error: 477.0569\n",
      "Epoch 911/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 340183.1875 - mean_squared_error: 340183.1875 - mean_absolute_error: 437.3984\n",
      "Epoch 00911: val_loss improved from 306392.21875 to 306143.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 410610.4568 - mean_squared_error: 410610.4688 - mean_absolute_error: 452.1477 - val_loss: 306143.9375 - val_mean_squared_error: 306143.9375 - val_mean_absolute_error: 476.7609\n",
      "Epoch 912/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 197457.7500 - mean_squared_error: 197457.7500 - mean_absolute_error: 384.1183\n",
      "Epoch 00912: val_loss improved from 306143.93750 to 305896.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 410148.5037 - mean_squared_error: 410148.5000 - mean_absolute_error: 451.8976 - val_loss: 305896.2500 - val_mean_squared_error: 305896.2500 - val_mean_absolute_error: 476.4588\n",
      "Epoch 913/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 544039.5000 - mean_squared_error: 544039.5000 - mean_absolute_error: 497.8647\n",
      "Epoch 00913: val_loss improved from 305896.25000 to 305599.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 409747.2509 - mean_squared_error: 409747.2500 - mean_absolute_error: 451.6660 - val_loss: 305599.2812 - val_mean_squared_error: 305599.2812 - val_mean_absolute_error: 476.1577\n",
      "Epoch 914/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 548141.3750 - mean_squared_error: 548141.3750 - mean_absolute_error: 528.0251\n",
      "Epoch 00914: val_loss improved from 305599.28125 to 305275.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 409271.5662 - mean_squared_error: 409271.5625 - mean_absolute_error: 451.5795 - val_loss: 305275.4062 - val_mean_squared_error: 305275.4062 - val_mean_absolute_error: 475.8468\n",
      "Epoch 915/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 446561.2500 - mean_squared_error: 446561.2500 - mean_absolute_error: 458.2595\n",
      "Epoch 00915: val_loss improved from 305275.40625 to 304913.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 408692.3051 - mean_squared_error: 408692.2812 - mean_absolute_error: 451.4192 - val_loss: 304913.5312 - val_mean_squared_error: 304913.5312 - val_mean_absolute_error: 475.5057\n",
      "Epoch 916/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 357531.1250 - mean_squared_error: 357531.1250 - mean_absolute_error: 436.7632\n",
      "Epoch 00916: val_loss improved from 304913.53125 to 304571.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 408040.8162 - mean_squared_error: 408040.7812 - mean_absolute_error: 451.3055 - val_loss: 304571.0000 - val_mean_squared_error: 304571.0000 - val_mean_absolute_error: 475.1396\n",
      "Epoch 917/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 297479.6875 - mean_squared_error: 297479.6875 - mean_absolute_error: 410.5362\n",
      "Epoch 00917: val_loss improved from 304571.00000 to 304232.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 407394.2941 - mean_squared_error: 407394.2812 - mean_absolute_error: 451.0782 - val_loss: 304232.2812 - val_mean_squared_error: 304232.2812 - val_mean_absolute_error: 474.7681\n",
      "Epoch 918/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 339885.1875 - mean_squared_error: 339885.1875 - mean_absolute_error: 437.9590\n",
      "Epoch 00918: val_loss improved from 304232.28125 to 303904.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 406775.7580 - mean_squared_error: 406775.7500 - mean_absolute_error: 450.8309 - val_loss: 303904.1562 - val_mean_squared_error: 303904.1562 - val_mean_absolute_error: 474.4098\n",
      "Epoch 919/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 572550.5000 - mean_squared_error: 572550.5000 - mean_absolute_error: 540.7354\n",
      "Epoch 00919: val_loss improved from 303904.15625 to 303607.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 406374.8235 - mean_squared_error: 406374.8125 - mean_absolute_error: 450.7854 - val_loss: 303607.7812 - val_mean_squared_error: 303607.7812 - val_mean_absolute_error: 474.0597\n",
      "Epoch 920/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 314375.0000 - mean_squared_error: 314375.0000 - mean_absolute_error: 419.8488\n",
      "Epoch 00920: val_loss improved from 303607.78125 to 303350.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 405747.5349 - mean_squared_error: 405747.5625 - mean_absolute_error: 450.4996 - val_loss: 303350.9062 - val_mean_squared_error: 303350.9062 - val_mean_absolute_error: 473.7006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 921/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 185913.4062 - mean_squared_error: 185913.4062 - mean_absolute_error: 364.6908\n",
      "Epoch 00921: val_loss improved from 303350.90625 to 303101.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 405259.5404 - mean_squared_error: 405259.5312 - mean_absolute_error: 450.2221 - val_loss: 303101.8750 - val_mean_squared_error: 303101.8750 - val_mean_absolute_error: 473.3629\n",
      "Epoch 922/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 306730.9375 - mean_squared_error: 306730.9375 - mean_absolute_error: 429.8855\n",
      "Epoch 00922: val_loss improved from 303101.87500 to 302872.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 404824.3309 - mean_squared_error: 404824.3125 - mean_absolute_error: 450.0168 - val_loss: 302872.3438 - val_mean_squared_error: 302872.3438 - val_mean_absolute_error: 473.0777\n",
      "Epoch 923/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 278747.9375 - mean_squared_error: 278747.9375 - mean_absolute_error: 371.5211\n",
      "Epoch 00923: val_loss improved from 302872.34375 to 302670.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 404423.2684 - mean_squared_error: 404423.2500 - mean_absolute_error: 449.8531 - val_loss: 302670.2812 - val_mean_squared_error: 302670.2812 - val_mean_absolute_error: 472.7933\n",
      "Epoch 924/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 154859.3438 - mean_squared_error: 154859.3438 - mean_absolute_error: 333.8744\n",
      "Epoch 00924: val_loss improved from 302670.28125 to 302491.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 404064.2619 - mean_squared_error: 404064.2500 - mean_absolute_error: 449.6468 - val_loss: 302491.2500 - val_mean_squared_error: 302491.2500 - val_mean_absolute_error: 472.5198\n",
      "Epoch 925/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 604971.1250 - mean_squared_error: 604971.1250 - mean_absolute_error: 517.1862\n",
      "Epoch 00925: val_loss improved from 302491.25000 to 302309.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 403813.5349 - mean_squared_error: 403813.5312 - mean_absolute_error: 449.4703 - val_loss: 302309.4062 - val_mean_squared_error: 302309.4062 - val_mean_absolute_error: 472.2695\n",
      "Epoch 926/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 425475.3125 - mean_squared_error: 425475.3125 - mean_absolute_error: 453.0462\n",
      "Epoch 00926: val_loss improved from 302309.40625 to 302119.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 403395.4485 - mean_squared_error: 403395.4375 - mean_absolute_error: 449.2359 - val_loss: 302119.2812 - val_mean_squared_error: 302119.2812 - val_mean_absolute_error: 471.9869\n",
      "Epoch 927/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 272336.4375 - mean_squared_error: 272336.4375 - mean_absolute_error: 379.0705\n",
      "Epoch 00927: val_loss improved from 302119.28125 to 301895.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 402994.3516 - mean_squared_error: 402994.3438 - mean_absolute_error: 449.0222 - val_loss: 301895.6562 - val_mean_squared_error: 301895.6562 - val_mean_absolute_error: 471.6801\n",
      "Epoch 928/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 279529.4688 - mean_squared_error: 279529.4688 - mean_absolute_error: 391.2553\n",
      "Epoch 00928: val_loss improved from 301895.65625 to 301689.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 402605.8759 - mean_squared_error: 402605.8438 - mean_absolute_error: 448.8360 - val_loss: 301689.4062 - val_mean_squared_error: 301689.4062 - val_mean_absolute_error: 471.3545\n",
      "Epoch 929/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 617171.3125 - mean_squared_error: 617171.3125 - mean_absolute_error: 512.0902\n",
      "Epoch 00929: val_loss improved from 301689.40625 to 301507.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 402265.2307 - mean_squared_error: 402265.2500 - mean_absolute_error: 448.5658 - val_loss: 301507.0625 - val_mean_squared_error: 301507.0625 - val_mean_absolute_error: 471.0379\n",
      "Epoch 930/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 618487.0000 - mean_squared_error: 618487.0000 - mean_absolute_error: 506.8905\n",
      "Epoch 00930: val_loss improved from 301507.06250 to 301341.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 401901.5956 - mean_squared_error: 401901.5938 - mean_absolute_error: 448.2488 - val_loss: 301341.9688 - val_mean_squared_error: 301341.9688 - val_mean_absolute_error: 470.7038\n",
      "Epoch 931/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 413313.5000 - mean_squared_error: 413313.5000 - mean_absolute_error: 448.4740\n",
      "Epoch 00931: val_loss improved from 301341.96875 to 301157.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 401592.5699 - mean_squared_error: 401592.5625 - mean_absolute_error: 447.9342 - val_loss: 301157.6250 - val_mean_squared_error: 301157.6250 - val_mean_absolute_error: 470.3185\n",
      "Epoch 932/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 340554.5938 - mean_squared_error: 340554.5938 - mean_absolute_error: 407.9810\n",
      "Epoch 00932: val_loss improved from 301157.62500 to 300952.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 401240.6176 - mean_squared_error: 401240.5938 - mean_absolute_error: 447.4930 - val_loss: 300952.3750 - val_mean_squared_error: 300952.3750 - val_mean_absolute_error: 469.9315\n",
      "Epoch 933/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 311041.0938 - mean_squared_error: 311041.0938 - mean_absolute_error: 427.2309\n",
      "Epoch 00933: val_loss improved from 300952.37500 to 300730.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 400854.8589 - mean_squared_error: 400854.8750 - mean_absolute_error: 447.1309 - val_loss: 300730.8438 - val_mean_squared_error: 300730.8438 - val_mean_absolute_error: 469.5813\n",
      "Epoch 934/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 294719.1250 - mean_squared_error: 294719.1250 - mean_absolute_error: 396.4568\n",
      "Epoch 00934: val_loss improved from 300730.84375 to 300504.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 400411.0368 - mean_squared_error: 400411.0312 - mean_absolute_error: 446.8535 - val_loss: 300504.6562 - val_mean_squared_error: 300504.6562 - val_mean_absolute_error: 469.2663\n",
      "Epoch 935/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 415003.2188 - mean_squared_error: 415003.2188 - mean_absolute_error: 436.9968\n",
      "Epoch 00935: val_loss improved from 300504.65625 to 300222.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 399931.4191 - mean_squared_error: 399931.4062 - mean_absolute_error: 446.6508 - val_loss: 300222.9375 - val_mean_squared_error: 300222.9375 - val_mean_absolute_error: 468.9152\n",
      "Epoch 936/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 365296.2188 - mean_squared_error: 365296.2188 - mean_absolute_error: 473.9321\n",
      "Epoch 00936: val_loss improved from 300222.93750 to 299934.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 399419.3559 - mean_squared_error: 399419.3438 - mean_absolute_error: 446.5439 - val_loss: 299934.8750 - val_mean_squared_error: 299934.8750 - val_mean_absolute_error: 468.5611\n",
      "Epoch 937/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 480784.8125 - mean_squared_error: 480784.8125 - mean_absolute_error: 440.9211\n",
      "Epoch 00937: val_loss improved from 299934.87500 to 299671.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 398934.0735 - mean_squared_error: 398934.0938 - mean_absolute_error: 446.4511 - val_loss: 299671.8750 - val_mean_squared_error: 299671.8750 - val_mean_absolute_error: 468.2231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 938/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 452707.4375 - mean_squared_error: 452707.4375 - mean_absolute_error: 470.8170\n",
      "Epoch 00938: val_loss improved from 299671.87500 to 299426.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 398449.4500 - mean_squared_error: 398449.4688 - mean_absolute_error: 446.3286 - val_loss: 299426.5000 - val_mean_squared_error: 299426.5000 - val_mean_absolute_error: 467.9195\n",
      "Epoch 939/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 597886.0000 - mean_squared_error: 597886.0000 - mean_absolute_error: 520.4025\n",
      "Epoch 00939: val_loss improved from 299426.50000 to 299206.75000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 397866.7693 - mean_squared_error: 397866.7500 - mean_absolute_error: 446.1215 - val_loss: 299206.7500 - val_mean_squared_error: 299206.7500 - val_mean_absolute_error: 467.5938\n",
      "Epoch 940/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 219007.5312 - mean_squared_error: 219007.5312 - mean_absolute_error: 399.3628\n",
      "Epoch 00940: val_loss improved from 299206.75000 to 299001.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 397325.8088 - mean_squared_error: 397325.8125 - mean_absolute_error: 445.9385 - val_loss: 299001.3750 - val_mean_squared_error: 299001.3750 - val_mean_absolute_error: 467.2766\n",
      "Epoch 941/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 515383.4375 - mean_squared_error: 515383.4375 - mean_absolute_error: 500.7513\n",
      "Epoch 00941: val_loss improved from 299001.37500 to 298787.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 396937.6618 - mean_squared_error: 396937.6875 - mean_absolute_error: 445.7354 - val_loss: 298787.3438 - val_mean_squared_error: 298787.3438 - val_mean_absolute_error: 466.9519\n",
      "Epoch 942/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 269873.3750 - mean_squared_error: 269873.3750 - mean_absolute_error: 377.9296\n",
      "Epoch 00942: val_loss improved from 298787.34375 to 298595.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 396484.8626 - mean_squared_error: 396484.8438 - mean_absolute_error: 445.5970 - val_loss: 298595.6875 - val_mean_squared_error: 298595.6875 - val_mean_absolute_error: 466.6429\n",
      "Epoch 943/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 516221.1562 - mean_squared_error: 516221.1562 - mean_absolute_error: 486.9858\n",
      "Epoch 00943: val_loss improved from 298595.68750 to 298404.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 396110.1985 - mean_squared_error: 396110.2188 - mean_absolute_error: 445.3831 - val_loss: 298404.7812 - val_mean_squared_error: 298404.7812 - val_mean_absolute_error: 466.3099\n",
      "Epoch 944/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 360867.0312 - mean_squared_error: 360867.0312 - mean_absolute_error: 398.3681\n",
      "Epoch 00944: val_loss improved from 298404.78125 to 298209.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 395673.9835 - mean_squared_error: 395674.0000 - mean_absolute_error: 445.1539 - val_loss: 298209.3750 - val_mean_squared_error: 298209.3750 - val_mean_absolute_error: 465.9746\n",
      "Epoch 945/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 351907.3125 - mean_squared_error: 351907.3125 - mean_absolute_error: 435.8939\n",
      "Epoch 00945: val_loss improved from 298209.37500 to 298009.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 395295.4182 - mean_squared_error: 395295.4062 - mean_absolute_error: 444.9617 - val_loss: 298009.3750 - val_mean_squared_error: 298009.3750 - val_mean_absolute_error: 465.6122\n",
      "Epoch 946/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 407105.1562 - mean_squared_error: 407105.1562 - mean_absolute_error: 446.6335\n",
      "Epoch 00946: val_loss improved from 298009.37500 to 297814.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 394827.4412 - mean_squared_error: 394827.4688 - mean_absolute_error: 444.6204 - val_loss: 297814.6562 - val_mean_squared_error: 297814.6562 - val_mean_absolute_error: 465.2132\n",
      "Epoch 947/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 330838.1875 - mean_squared_error: 330838.1875 - mean_absolute_error: 415.7948\n",
      "Epoch 00947: val_loss improved from 297814.65625 to 297631.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 394513.7116 - mean_squared_error: 394513.7188 - mean_absolute_error: 444.3258 - val_loss: 297631.3750 - val_mean_squared_error: 297631.3750 - val_mean_absolute_error: 464.8188\n",
      "Epoch 948/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 288959.9062 - mean_squared_error: 288959.9062 - mean_absolute_error: 369.9640\n",
      "Epoch 00948: val_loss improved from 297631.37500 to 297466.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 394058.6815 - mean_squared_error: 394058.7188 - mean_absolute_error: 443.8710 - val_loss: 297466.0312 - val_mean_squared_error: 297466.0312 - val_mean_absolute_error: 464.4736\n",
      "Epoch 949/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 304347.5625 - mean_squared_error: 304347.5625 - mean_absolute_error: 399.4221\n",
      "Epoch 00949: val_loss improved from 297466.03125 to 297294.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 393769.3520 - mean_squared_error: 393769.3438 - mean_absolute_error: 443.5818 - val_loss: 297294.6562 - val_mean_squared_error: 297294.6562 - val_mean_absolute_error: 464.0877\n",
      "Epoch 950/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 460759.1875 - mean_squared_error: 460759.1875 - mean_absolute_error: 479.3040\n",
      "Epoch 00950: val_loss improved from 297294.65625 to 297123.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 393428.3994 - mean_squared_error: 393428.4062 - mean_absolute_error: 443.2059 - val_loss: 297123.4688 - val_mean_squared_error: 297123.4688 - val_mean_absolute_error: 463.6961\n",
      "Epoch 951/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 538272.0625 - mean_squared_error: 538272.0625 - mean_absolute_error: 535.3763\n",
      "Epoch 00951: val_loss improved from 297123.46875 to 296973.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 393071.0409 - mean_squared_error: 393071.0312 - mean_absolute_error: 442.8318 - val_loss: 296973.2188 - val_mean_squared_error: 296973.2188 - val_mean_absolute_error: 463.3707\n",
      "Epoch 952/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 209452.9375 - mean_squared_error: 209452.9375 - mean_absolute_error: 387.7845\n",
      "Epoch 00952: val_loss improved from 296973.21875 to 296839.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 392724.0207 - mean_squared_error: 392724.0312 - mean_absolute_error: 442.5082 - val_loss: 296839.5625 - val_mean_squared_error: 296839.5625 - val_mean_absolute_error: 463.0973\n",
      "Epoch 953/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 443410.0625 - mean_squared_error: 443410.0625 - mean_absolute_error: 428.6909\n",
      "Epoch 00953: val_loss improved from 296839.56250 to 296702.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 392493.7224 - mean_squared_error: 392493.7500 - mean_absolute_error: 442.3626 - val_loss: 296702.1250 - val_mean_squared_error: 296702.1250 - val_mean_absolute_error: 462.8206\n",
      "Epoch 954/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 358700.8125 - mean_squared_error: 358700.8125 - mean_absolute_error: 454.6673\n",
      "Epoch 00954: val_loss improved from 296702.12500 to 296549.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 392158.3235 - mean_squared_error: 392158.3125 - mean_absolute_error: 442.1273 - val_loss: 296549.4375 - val_mean_squared_error: 296549.4375 - val_mean_absolute_error: 462.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 955/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 344167.0625 - mean_squared_error: 344167.0625 - mean_absolute_error: 437.0284\n",
      "Epoch 00955: val_loss improved from 296549.43750 to 296373.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 391866.0496 - mean_squared_error: 391866.0625 - mean_absolute_error: 441.9143 - val_loss: 296373.6562 - val_mean_squared_error: 296373.6562 - val_mean_absolute_error: 462.2272\n",
      "Epoch 956/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 210386.2188 - mean_squared_error: 210386.2188 - mean_absolute_error: 383.2672\n",
      "Epoch 00956: val_loss improved from 296373.65625 to 296189.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 391424.8235 - mean_squared_error: 391424.8125 - mean_absolute_error: 441.6338 - val_loss: 296189.7812 - val_mean_squared_error: 296189.7812 - val_mean_absolute_error: 462.0022\n",
      "Epoch 957/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 158307.4688 - mean_squared_error: 158307.4688 - mean_absolute_error: 326.5657\n",
      "Epoch 00957: val_loss improved from 296189.78125 to 295973.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 390970.0055 - mean_squared_error: 390970.0312 - mean_absolute_error: 441.3945 - val_loss: 295973.5312 - val_mean_squared_error: 295973.5312 - val_mean_absolute_error: 461.8671\n",
      "Epoch 958/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 475327.8750 - mean_squared_error: 475327.8750 - mean_absolute_error: 448.6792\n",
      "Epoch 00958: val_loss improved from 295973.53125 to 295783.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 390602.1140 - mean_squared_error: 390602.1250 - mean_absolute_error: 441.2734 - val_loss: 295783.1250 - val_mean_squared_error: 295783.1250 - val_mean_absolute_error: 461.6842\n",
      "Epoch 959/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 530498.0000 - mean_squared_error: 530498.0000 - mean_absolute_error: 478.2171\n",
      "Epoch 00959: val_loss improved from 295783.12500 to 295609.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 390147.1581 - mean_squared_error: 390147.1875 - mean_absolute_error: 441.0796 - val_loss: 295609.5000 - val_mean_squared_error: 295609.5000 - val_mean_absolute_error: 461.4288\n",
      "Epoch 960/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 341665.3125 - mean_squared_error: 341665.3125 - mean_absolute_error: 422.6687\n",
      "Epoch 00960: val_loss improved from 295609.50000 to 295444.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 389743.6324 - mean_squared_error: 389743.6562 - mean_absolute_error: 440.8155 - val_loss: 295444.3438 - val_mean_squared_error: 295444.3438 - val_mean_absolute_error: 461.0838\n",
      "Epoch 961/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 293298.1875 - mean_squared_error: 293298.1875 - mean_absolute_error: 394.6267\n",
      "Epoch 00961: val_loss improved from 295444.34375 to 295288.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 389378.2353 - mean_squared_error: 389378.2500 - mean_absolute_error: 440.4397 - val_loss: 295288.3750 - val_mean_squared_error: 295288.3750 - val_mean_absolute_error: 460.7083\n",
      "Epoch 962/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 496795.8125 - mean_squared_error: 496795.8125 - mean_absolute_error: 482.0771\n",
      "Epoch 00962: val_loss improved from 295288.37500 to 295137.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 389054.1857 - mean_squared_error: 389054.2188 - mean_absolute_error: 440.0844 - val_loss: 295137.6250 - val_mean_squared_error: 295137.6250 - val_mean_absolute_error: 460.3632\n",
      "Epoch 963/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 194871.0938 - mean_squared_error: 194871.0938 - mean_absolute_error: 343.6700\n",
      "Epoch 00963: val_loss improved from 295137.62500 to 294989.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 388788.8557 - mean_squared_error: 388788.8750 - mean_absolute_error: 439.7758 - val_loss: 294989.1562 - val_mean_squared_error: 294989.1562 - val_mean_absolute_error: 459.9535\n",
      "Epoch 964/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 284965.3438 - mean_squared_error: 284965.3438 - mean_absolute_error: 373.6348\n",
      "Epoch 00964: val_loss improved from 294989.15625 to 294842.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 388439.6746 - mean_squared_error: 388439.6875 - mean_absolute_error: 439.3471 - val_loss: 294842.6250 - val_mean_squared_error: 294842.6250 - val_mean_absolute_error: 459.5927\n",
      "Epoch 965/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 542051.4375 - mean_squared_error: 542051.4375 - mean_absolute_error: 536.9905\n",
      "Epoch 00965: val_loss improved from 294842.62500 to 294700.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 388128.5708 - mean_squared_error: 388128.5625 - mean_absolute_error: 438.9946 - val_loss: 294700.7188 - val_mean_squared_error: 294700.7188 - val_mean_absolute_error: 459.2257\n",
      "Epoch 966/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 502620.1562 - mean_squared_error: 502620.1562 - mean_absolute_error: 491.4787\n",
      "Epoch 00966: val_loss improved from 294700.71875 to 294561.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 387830.2353 - mean_squared_error: 387830.2500 - mean_absolute_error: 438.6033 - val_loss: 294561.6562 - val_mean_squared_error: 294561.6562 - val_mean_absolute_error: 458.8842\n",
      "Epoch 967/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 316247.1250 - mean_squared_error: 316247.1250 - mean_absolute_error: 382.4328\n",
      "Epoch 00967: val_loss improved from 294561.65625 to 294416.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 387543.8070 - mean_squared_error: 387543.8125 - mean_absolute_error: 438.3177 - val_loss: 294416.6562 - val_mean_squared_error: 294416.6562 - val_mean_absolute_error: 458.5339\n",
      "Epoch 968/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 383537.6250 - mean_squared_error: 383537.6250 - mean_absolute_error: 448.2504\n",
      "Epoch 00968: val_loss improved from 294416.65625 to 294282.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 387231.9154 - mean_squared_error: 387231.9062 - mean_absolute_error: 437.9520 - val_loss: 294282.1250 - val_mean_squared_error: 294282.1250 - val_mean_absolute_error: 458.1764\n",
      "Epoch 969/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 459507.4375 - mean_squared_error: 459507.4375 - mean_absolute_error: 494.2872\n",
      "Epoch 00969: val_loss improved from 294282.12500 to 294159.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 386986.2730 - mean_squared_error: 386986.2812 - mean_absolute_error: 437.6686 - val_loss: 294159.9375 - val_mean_squared_error: 294159.9375 - val_mean_absolute_error: 457.8530\n",
      "Epoch 970/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 289438.1250 - mean_squared_error: 289438.1250 - mean_absolute_error: 381.0008\n",
      "Epoch 00970: val_loss improved from 294159.93750 to 294048.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 386737.1645 - mean_squared_error: 386737.1875 - mean_absolute_error: 437.3510 - val_loss: 294048.2812 - val_mean_squared_error: 294048.2812 - val_mean_absolute_error: 457.5307\n",
      "Epoch 971/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 187082.0625 - mean_squared_error: 187082.0625 - mean_absolute_error: 363.2325\n",
      "Epoch 00971: val_loss improved from 294048.28125 to 293939.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 386531.6324 - mean_squared_error: 386531.6250 - mean_absolute_error: 437.0375 - val_loss: 293939.5312 - val_mean_squared_error: 293939.5312 - val_mean_absolute_error: 457.2783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 972/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 498790.1562 - mean_squared_error: 498790.1562 - mean_absolute_error: 485.5433\n",
      "Epoch 00972: val_loss improved from 293939.53125 to 293797.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 386323.2574 - mean_squared_error: 386323.2500 - mean_absolute_error: 436.9072 - val_loss: 293797.7812 - val_mean_squared_error: 293797.7812 - val_mean_absolute_error: 457.1960\n",
      "Epoch 973/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 433974.8750 - mean_squared_error: 433974.8750 - mean_absolute_error: 430.9002\n",
      "Epoch 00973: val_loss improved from 293797.78125 to 293660.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 385911.5772 - mean_squared_error: 385911.5938 - mean_absolute_error: 436.7504 - val_loss: 293660.4688 - val_mean_squared_error: 293660.4688 - val_mean_absolute_error: 457.0786\n",
      "Epoch 974/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 247730.0156 - mean_squared_error: 247730.0156 - mean_absolute_error: 431.6272\n",
      "Epoch 00974: val_loss improved from 293660.46875 to 293523.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 385538.0754 - mean_squared_error: 385538.0625 - mean_absolute_error: 436.5883 - val_loss: 293523.8750 - val_mean_squared_error: 293523.8750 - val_mean_absolute_error: 456.9095\n",
      "Epoch 975/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 366073.1250 - mean_squared_error: 366073.1250 - mean_absolute_error: 452.8701\n",
      "Epoch 00975: val_loss improved from 293523.87500 to 293394.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 385257.5193 - mean_squared_error: 385257.5312 - mean_absolute_error: 436.4301 - val_loss: 293394.4375 - val_mean_squared_error: 293394.4375 - val_mean_absolute_error: 456.6857\n",
      "Epoch 976/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 441496.5625 - mean_squared_error: 441496.5625 - mean_absolute_error: 443.7981\n",
      "Epoch 00976: val_loss improved from 293394.43750 to 293274.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 384931.0570 - mean_squared_error: 384931.0312 - mean_absolute_error: 436.1390 - val_loss: 293274.4062 - val_mean_squared_error: 293274.4062 - val_mean_absolute_error: 456.3641\n",
      "Epoch 977/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 620984.2500 - mean_squared_error: 620984.2500 - mean_absolute_error: 527.2794\n",
      "Epoch 00977: val_loss improved from 293274.40625 to 293156.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 384705.6751 - mean_squared_error: 384705.6875 - mean_absolute_error: 435.8318 - val_loss: 293156.9375 - val_mean_squared_error: 293156.9375 - val_mean_absolute_error: 456.0199\n",
      "Epoch 978/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 323233.7500 - mean_squared_error: 323233.7500 - mean_absolute_error: 426.5900\n",
      "Epoch 00978: val_loss improved from 293156.93750 to 293033.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 384438.5294 - mean_squared_error: 384438.5312 - mean_absolute_error: 435.5078 - val_loss: 293033.2812 - val_mean_squared_error: 293033.2812 - val_mean_absolute_error: 455.7219\n",
      "Epoch 979/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 451663.8750 - mean_squared_error: 451663.8750 - mean_absolute_error: 516.6935\n",
      "Epoch 00979: val_loss improved from 293033.28125 to 292889.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 384136.7992 - mean_squared_error: 384136.7812 - mean_absolute_error: 435.2531 - val_loss: 292889.3438 - val_mean_squared_error: 292889.3438 - val_mean_absolute_error: 455.5793\n",
      "Epoch 980/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 357714.7812 - mean_squared_error: 357714.7812 - mean_absolute_error: 436.9631\n",
      "Epoch 00980: val_loss improved from 292889.34375 to 292757.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 383790.7950 - mean_squared_error: 383790.7812 - mean_absolute_error: 435.1041 - val_loss: 292757.3750 - val_mean_squared_error: 292757.3750 - val_mean_absolute_error: 455.4226\n",
      "Epoch 981/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 472503.4688 - mean_squared_error: 472503.4688 - mean_absolute_error: 458.1594\n",
      "Epoch 00981: val_loss improved from 292757.37500 to 292636.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 383486.3934 - mean_squared_error: 383486.3750 - mean_absolute_error: 434.9526 - val_loss: 292636.6562 - val_mean_squared_error: 292636.6562 - val_mean_absolute_error: 455.2232\n",
      "Epoch 982/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 613395.6250 - mean_squared_error: 613395.6250 - mean_absolute_error: 543.1608\n",
      "Epoch 00982: val_loss improved from 292636.65625 to 292532.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 383208.4991 - mean_squared_error: 383208.4688 - mean_absolute_error: 434.7417 - val_loss: 292532.1250 - val_mean_squared_error: 292532.1250 - val_mean_absolute_error: 454.9179\n",
      "Epoch 983/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 279888.4062 - mean_squared_error: 279888.4062 - mean_absolute_error: 379.1890\n",
      "Epoch 00983: val_loss improved from 292532.12500 to 292444.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 382973.2346 - mean_squared_error: 382973.2188 - mean_absolute_error: 434.4009 - val_loss: 292444.3438 - val_mean_squared_error: 292444.3438 - val_mean_absolute_error: 454.5674\n",
      "Epoch 984/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 321818.5312 - mean_squared_error: 321818.5312 - mean_absolute_error: 376.9991\n",
      "Epoch 00984: val_loss improved from 292444.34375 to 292363.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 382798.3355 - mean_squared_error: 382798.3125 - mean_absolute_error: 434.0958 - val_loss: 292363.5625 - val_mean_squared_error: 292363.5625 - val_mean_absolute_error: 454.2677\n",
      "Epoch 985/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 515034.1562 - mean_squared_error: 515034.1562 - mean_absolute_error: 501.1434\n",
      "Epoch 00985: val_loss improved from 292363.56250 to 292286.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 382589.1994 - mean_squared_error: 382589.2188 - mean_absolute_error: 433.7952 - val_loss: 292286.2188 - val_mean_squared_error: 292286.2188 - val_mean_absolute_error: 454.0410\n",
      "Epoch 986/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 417889.7500 - mean_squared_error: 417889.7500 - mean_absolute_error: 457.0023\n",
      "Epoch 00986: val_loss improved from 292286.21875 to 292197.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 382425.0699 - mean_squared_error: 382425.0938 - mean_absolute_error: 433.5861 - val_loss: 292197.9062 - val_mean_squared_error: 292197.9062 - val_mean_absolute_error: 453.7909\n",
      "Epoch 987/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 308274.0312 - mean_squared_error: 308274.0312 - mean_absolute_error: 404.0439\n",
      "Epoch 00987: val_loss improved from 292197.90625 to 292100.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 382223.1553 - mean_squared_error: 382223.1562 - mean_absolute_error: 433.3467 - val_loss: 292100.7188 - val_mean_squared_error: 292100.7188 - val_mean_absolute_error: 453.5547\n",
      "Epoch 988/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 491531.0312 - mean_squared_error: 491531.0312 - mean_absolute_error: 514.7963\n",
      "Epoch 00988: val_loss improved from 292100.71875 to 292006.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 382004.5375 - mean_squared_error: 382004.5312 - mean_absolute_error: 433.1659 - val_loss: 292006.8750 - val_mean_squared_error: 292006.8750 - val_mean_absolute_error: 453.3841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 497453.4062 - mean_squared_error: 497453.4062 - mean_absolute_error: 500.0904\n",
      "Epoch 00989: val_loss improved from 292006.87500 to 291917.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 381738.6921 - mean_squared_error: 381738.7188 - mean_absolute_error: 432.9526 - val_loss: 291917.1250 - val_mean_squared_error: 291917.1250 - val_mean_absolute_error: 453.2069\n",
      "Epoch 990/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 495912.0625 - mean_squared_error: 495912.0625 - mean_absolute_error: 484.5294\n",
      "Epoch 00990: val_loss improved from 291917.12500 to 291825.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 381523.3226 - mean_squared_error: 381523.3125 - mean_absolute_error: 432.8060 - val_loss: 291825.1250 - val_mean_squared_error: 291825.1250 - val_mean_absolute_error: 452.9786\n",
      "Epoch 991/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 460911.2500 - mean_squared_error: 460911.2500 - mean_absolute_error: 463.2717\n",
      "Epoch 00991: val_loss improved from 291825.12500 to 291745.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 381268.7390 - mean_squared_error: 381268.7500 - mean_absolute_error: 432.5086 - val_loss: 291745.0625 - val_mean_squared_error: 291745.0625 - val_mean_absolute_error: 452.6732\n",
      "Epoch 992/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 461131.2812 - mean_squared_error: 461131.2812 - mean_absolute_error: 489.2913\n",
      "Epoch 00992: val_loss improved from 291745.06250 to 291670.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 381062.3548 - mean_squared_error: 381062.3438 - mean_absolute_error: 432.2078 - val_loss: 291670.9062 - val_mean_squared_error: 291670.9062 - val_mean_absolute_error: 452.2991\n",
      "Epoch 993/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 167000.2188 - mean_squared_error: 167000.2188 - mean_absolute_error: 339.6598\n",
      "Epoch 00993: val_loss improved from 291670.90625 to 291596.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 380927.2059 - mean_squared_error: 380927.2500 - mean_absolute_error: 431.8264 - val_loss: 291596.2188 - val_mean_squared_error: 291596.2188 - val_mean_absolute_error: 451.9137\n",
      "Epoch 994/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 278222.6562 - mean_squared_error: 278222.6562 - mean_absolute_error: 368.2802\n",
      "Epoch 00994: val_loss improved from 291596.21875 to 291470.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 380679.1029 - mean_squared_error: 380679.0938 - mean_absolute_error: 431.5182 - val_loss: 291470.5000 - val_mean_squared_error: 291470.5000 - val_mean_absolute_error: 451.6985\n",
      "Epoch 995/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 368369.8750 - mean_squared_error: 368369.8750 - mean_absolute_error: 434.7148\n",
      "Epoch 00995: val_loss improved from 291470.50000 to 291329.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 380254.0772 - mean_squared_error: 380254.0938 - mean_absolute_error: 431.3010 - val_loss: 291329.1562 - val_mean_squared_error: 291329.1562 - val_mean_absolute_error: 451.6280\n",
      "Epoch 996/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 367727.1875 - mean_squared_error: 367727.1875 - mean_absolute_error: 404.8125\n",
      "Epoch 00996: val_loss improved from 291329.15625 to 291195.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 379919.9338 - mean_squared_error: 379919.9375 - mean_absolute_error: 431.2470 - val_loss: 291195.3125 - val_mean_squared_error: 291195.3125 - val_mean_absolute_error: 451.6093\n",
      "Epoch 997/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 312054.9688 - mean_squared_error: 312054.9688 - mean_absolute_error: 403.7438\n",
      "Epoch 00997: val_loss improved from 291195.31250 to 291078.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 379522.7739 - mean_squared_error: 379522.7812 - mean_absolute_error: 431.2390 - val_loss: 291078.1250 - val_mean_squared_error: 291078.1250 - val_mean_absolute_error: 451.8012\n",
      "Epoch 998/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 261598.9219 - mean_squared_error: 261598.9219 - mean_absolute_error: 387.0878\n",
      "Epoch 00998: val_loss improved from 291078.12500 to 290977.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 379157.0772 - mean_squared_error: 379157.0938 - mean_absolute_error: 431.1924 - val_loss: 290977.0000 - val_mean_squared_error: 290977.0000 - val_mean_absolute_error: 451.9992\n",
      "Epoch 999/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 513006.6875 - mean_squared_error: 513006.6875 - mean_absolute_error: 493.3297\n",
      "Epoch 00999: val_loss improved from 290977.00000 to 290874.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 378925.5165 - mean_squared_error: 378925.5312 - mean_absolute_error: 431.1844 - val_loss: 290874.3750 - val_mean_squared_error: 290874.3750 - val_mean_absolute_error: 452.2126\n",
      "Epoch 1000/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 496120.6250 - mean_squared_error: 496120.6250 - mean_absolute_error: 482.3390\n",
      "Epoch 01000: val_loss improved from 290874.37500 to 290780.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 378611.2978 - mean_squared_error: 378611.3125 - mean_absolute_error: 431.1553 - val_loss: 290780.1875 - val_mean_squared_error: 290780.1875 - val_mean_absolute_error: 452.2675\n",
      "Epoch 1001/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 488035.6875 - mean_squared_error: 488035.6875 - mean_absolute_error: 479.7124\n",
      "Epoch 01001: val_loss improved from 290780.18750 to 290691.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 378313.1029 - mean_squared_error: 378313.1250 - mean_absolute_error: 430.9975 - val_loss: 290691.8750 - val_mean_squared_error: 290691.8750 - val_mean_absolute_error: 452.1429\n",
      "Epoch 1002/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 381668.6875 - mean_squared_error: 381668.6875 - mean_absolute_error: 393.8899\n",
      "Epoch 01002: val_loss improved from 290691.87500 to 290605.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 378033.7665 - mean_squared_error: 378033.7500 - mean_absolute_error: 430.7720 - val_loss: 290605.6562 - val_mean_squared_error: 290605.6562 - val_mean_absolute_error: 452.1013\n",
      "Epoch 1003/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 652967.5625 - mean_squared_error: 652967.5625 - mean_absolute_error: 560.1754\n",
      "Epoch 01003: val_loss improved from 290605.65625 to 290522.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 377851.0294 - mean_squared_error: 377851.0312 - mean_absolute_error: 430.6439 - val_loss: 290522.7188 - val_mean_squared_error: 290522.7188 - val_mean_absolute_error: 452.0112\n",
      "Epoch 1004/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 459506.7500 - mean_squared_error: 459506.7500 - mean_absolute_error: 456.6364\n",
      "Epoch 01004: val_loss improved from 290522.71875 to 290453.59375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 279us/sample - loss: 377582.7316 - mean_squared_error: 377582.7188 - mean_absolute_error: 430.4190 - val_loss: 290453.5938 - val_mean_squared_error: 290453.5938 - val_mean_absolute_error: 451.8438\n",
      "Epoch 1005/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 461125.8125 - mean_squared_error: 461125.8125 - mean_absolute_error: 439.0731\n",
      "Epoch 01005: val_loss improved from 290453.59375 to 290385.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 377437.9779 - mean_squared_error: 377438.0000 - mean_absolute_error: 430.2629 - val_loss: 290385.9375 - val_mean_squared_error: 290385.9375 - val_mean_absolute_error: 451.7860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1006/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 177116.9531 - mean_squared_error: 177116.9531 - mean_absolute_error: 338.0220\n",
      "Epoch 01006: val_loss improved from 290385.93750 to 290305.25000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 377142.3162 - mean_squared_error: 377142.3125 - mean_absolute_error: 430.0968 - val_loss: 290305.2500 - val_mean_squared_error: 290305.2500 - val_mean_absolute_error: 451.9727\n",
      "Epoch 1007/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 354896.4688 - mean_squared_error: 354896.4688 - mean_absolute_error: 443.1976\n",
      "Epoch 01007: val_loss improved from 290305.25000 to 290195.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 293us/sample - loss: 376835.4890 - mean_squared_error: 376835.5000 - mean_absolute_error: 430.0886 - val_loss: 290195.3750 - val_mean_squared_error: 290195.3750 - val_mean_absolute_error: 452.4467\n",
      "Epoch 1008/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 491822.0625 - mean_squared_error: 491822.0625 - mean_absolute_error: 469.1167\n",
      "Epoch 01008: val_loss improved from 290195.37500 to 290097.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 376572.2528 - mean_squared_error: 376572.2500 - mean_absolute_error: 430.2836 - val_loss: 290097.1562 - val_mean_squared_error: 290097.1562 - val_mean_absolute_error: 452.8708\n",
      "Epoch 1009/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 435582.9688 - mean_squared_error: 435582.9688 - mean_absolute_error: 492.0509\n",
      "Epoch 01009: val_loss improved from 290097.15625 to 290021.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 375987.3015 - mean_squared_error: 375987.3125 - mean_absolute_error: 430.1443 - val_loss: 290021.0625 - val_mean_squared_error: 290021.0625 - val_mean_absolute_error: 453.1779\n",
      "Epoch 1010/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 274762.7188 - mean_squared_error: 274762.7188 - mean_absolute_error: 385.4983\n",
      "Epoch 01010: val_loss improved from 290021.06250 to 289957.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 375703.6627 - mean_squared_error: 375703.6562 - mean_absolute_error: 430.2901 - val_loss: 289957.7812 - val_mean_squared_error: 289957.7812 - val_mean_absolute_error: 453.5522\n",
      "Epoch 1011/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 582041.7500 - mean_squared_error: 582041.7500 - mean_absolute_error: 503.9595\n",
      "Epoch 01011: val_loss improved from 289957.78125 to 289903.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 375420.8226 - mean_squared_error: 375420.8125 - mean_absolute_error: 430.2725 - val_loss: 289903.0000 - val_mean_squared_error: 289903.0000 - val_mean_absolute_error: 453.7530\n",
      "Epoch 1012/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 245205.9688 - mean_squared_error: 245205.9688 - mean_absolute_error: 346.1098\n",
      "Epoch 01012: val_loss improved from 289903.00000 to 289853.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 375081.8323 - mean_squared_error: 375081.8125 - mean_absolute_error: 430.2018 - val_loss: 289853.8750 - val_mean_squared_error: 289853.8750 - val_mean_absolute_error: 453.8517\n",
      "Epoch 1013/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 187177.9219 - mean_squared_error: 187177.9219 - mean_absolute_error: 353.5970\n",
      "Epoch 01013: val_loss improved from 289853.87500 to 289799.15625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 374869.6011 - mean_squared_error: 374869.6250 - mean_absolute_error: 430.1564 - val_loss: 289799.1562 - val_mean_squared_error: 289799.1562 - val_mean_absolute_error: 453.8087\n",
      "Epoch 1014/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 369285.7500 - mean_squared_error: 369285.7500 - mean_absolute_error: 433.1897\n",
      "Epoch 01014: val_loss improved from 289799.15625 to 289740.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 374685.5037 - mean_squared_error: 374685.5000 - mean_absolute_error: 429.9941 - val_loss: 289740.1875 - val_mean_squared_error: 289740.1875 - val_mean_absolute_error: 453.6899\n",
      "Epoch 1015/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 442892.4062 - mean_squared_error: 442892.4062 - mean_absolute_error: 444.8026\n",
      "Epoch 01015: val_loss improved from 289740.18750 to 289686.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 374495.7004 - mean_squared_error: 374495.7188 - mean_absolute_error: 429.8049 - val_loss: 289686.8438 - val_mean_squared_error: 289686.8438 - val_mean_absolute_error: 453.6125\n",
      "Epoch 1016/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 294497.8750 - mean_squared_error: 294497.8750 - mean_absolute_error: 401.9086\n",
      "Epoch 01016: val_loss improved from 289686.84375 to 289633.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 374322.1544 - mean_squared_error: 374322.1875 - mean_absolute_error: 429.6664 - val_loss: 289633.2812 - val_mean_squared_error: 289633.2812 - val_mean_absolute_error: 453.4943\n",
      "Epoch 1017/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 360865.3438 - mean_squared_error: 360865.3438 - mean_absolute_error: 425.0533\n",
      "Epoch 01017: val_loss improved from 289633.28125 to 289577.53125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 308us/sample - loss: 374161.4228 - mean_squared_error: 374161.4062 - mean_absolute_error: 429.5079 - val_loss: 289577.5312 - val_mean_squared_error: 289577.5312 - val_mean_absolute_error: 453.4060\n",
      "Epoch 1018/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 398550.3125 - mean_squared_error: 398550.3125 - mean_absolute_error: 433.1545\n",
      "Epoch 01018: val_loss improved from 289577.53125 to 289521.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 374006.5496 - mean_squared_error: 374006.5625 - mean_absolute_error: 429.3738 - val_loss: 289521.3750 - val_mean_squared_error: 289521.3750 - val_mean_absolute_error: 453.3765\n",
      "Epoch 1019/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 165351.7188 - mean_squared_error: 165351.7188 - mean_absolute_error: 330.4019\n",
      "Epoch 01019: val_loss improved from 289521.37500 to 289474.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 373755.7647 - mean_squared_error: 373755.7500 - mean_absolute_error: 429.2183 - val_loss: 289474.9062 - val_mean_squared_error: 289474.9062 - val_mean_absolute_error: 453.4863\n",
      "Epoch 1020/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 516081.9062 - mean_squared_error: 516081.9062 - mean_absolute_error: 443.9904\n",
      "Epoch 01020: val_loss improved from 289474.90625 to 289437.93750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 373650.2298 - mean_squared_error: 373650.2500 - mean_absolute_error: 429.2375 - val_loss: 289437.9375 - val_mean_squared_error: 289437.9375 - val_mean_absolute_error: 453.8000\n",
      "Epoch 1021/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 161066.5938 - mean_squared_error: 161066.5938 - mean_absolute_error: 324.0593\n",
      "Epoch 01021: val_loss improved from 289437.93750 to 289395.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 373219.4154 - mean_squared_error: 373219.4375 - mean_absolute_error: 429.1658 - val_loss: 289395.3750 - val_mean_squared_error: 289395.3750 - val_mean_absolute_error: 453.9124\n",
      "Epoch 1022/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 391209.2188 - mean_squared_error: 391209.2188 - mean_absolute_error: 462.8801\n",
      "Epoch 01022: val_loss improved from 289395.37500 to 289362.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 373009.1544 - mean_squared_error: 373009.1562 - mean_absolute_error: 429.1242 - val_loss: 289362.5625 - val_mean_squared_error: 289362.5625 - val_mean_absolute_error: 454.0916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1023/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 491558.6250 - mean_squared_error: 491558.6250 - mean_absolute_error: 483.9539\n",
      "Epoch 01023: val_loss improved from 289362.56250 to 289340.03125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 372798.1985 - mean_squared_error: 372798.2188 - mean_absolute_error: 429.1528 - val_loss: 289340.0312 - val_mean_squared_error: 289340.0312 - val_mean_absolute_error: 454.4102\n",
      "Epoch 1024/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 385607.0938 - mean_squared_error: 385607.0938 - mean_absolute_error: 448.0480\n",
      "Epoch 01024: val_loss improved from 289340.03125 to 289314.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 372509.5742 - mean_squared_error: 372509.5625 - mean_absolute_error: 429.1490 - val_loss: 289314.7812 - val_mean_squared_error: 289314.7812 - val_mean_absolute_error: 454.6523\n",
      "Epoch 1025/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 566050.7500 - mean_squared_error: 566050.7500 - mean_absolute_error: 501.8104\n",
      "Epoch 01025: val_loss improved from 289314.78125 to 289283.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 372376.9283 - mean_squared_error: 372376.9375 - mean_absolute_error: 429.1960 - val_loss: 289283.3750 - val_mean_squared_error: 289283.3750 - val_mean_absolute_error: 454.8071\n",
      "Epoch 1026/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 485370.2500 - mean_squared_error: 485370.2500 - mean_absolute_error: 471.8708\n",
      "Epoch 01026: val_loss improved from 289283.37500 to 289240.40625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 372080.7840 - mean_squared_error: 372080.7812 - mean_absolute_error: 429.1207 - val_loss: 289240.4062 - val_mean_squared_error: 289240.4062 - val_mean_absolute_error: 454.8167\n",
      "Epoch 1027/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 350828.3438 - mean_squared_error: 350828.3438 - mean_absolute_error: 457.7772\n",
      "Epoch 01027: val_loss improved from 289240.40625 to 289182.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 371855.7059 - mean_squared_error: 371855.7188 - mean_absolute_error: 428.9949 - val_loss: 289182.4688 - val_mean_squared_error: 289182.4688 - val_mean_absolute_error: 454.6851\n",
      "Epoch 1028/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 464036.3125 - mean_squared_error: 464036.3125 - mean_absolute_error: 456.8323\n",
      "Epoch 01028: val_loss improved from 289182.46875 to 289117.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 371630.1471 - mean_squared_error: 371630.1562 - mean_absolute_error: 428.7448 - val_loss: 289117.0625 - val_mean_squared_error: 289117.0625 - val_mean_absolute_error: 454.4449\n",
      "Epoch 1029/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 450280.0625 - mean_squared_error: 450280.0625 - mean_absolute_error: 459.0667\n",
      "Epoch 01029: val_loss improved from 289117.06250 to 289044.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 371476.8070 - mean_squared_error: 371476.8125 - mean_absolute_error: 428.4859 - val_loss: 289044.3750 - val_mean_squared_error: 289044.3750 - val_mean_absolute_error: 454.1676\n",
      "Epoch 1030/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 469407.8750 - mean_squared_error: 469407.8750 - mean_absolute_error: 460.7147\n",
      "Epoch 01030: val_loss improved from 289044.37500 to 288963.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 371282.8529 - mean_squared_error: 371282.8438 - mean_absolute_error: 428.2063 - val_loss: 288963.3750 - val_mean_squared_error: 288963.3750 - val_mean_absolute_error: 453.7997\n",
      "Epoch 1031/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 335506.5312 - mean_squared_error: 335506.5312 - mean_absolute_error: 440.5225\n",
      "Epoch 01031: val_loss improved from 288963.37500 to 288886.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 371144.9026 - mean_squared_error: 371144.9062 - mean_absolute_error: 427.8794 - val_loss: 288886.3125 - val_mean_squared_error: 288886.3125 - val_mean_absolute_error: 453.3902\n",
      "Epoch 1032/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 416094.6875 - mean_squared_error: 416094.6875 - mean_absolute_error: 397.6157\n",
      "Epoch 01032: val_loss improved from 288886.31250 to 288808.00000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 371017.0129 - mean_squared_error: 371017.0312 - mean_absolute_error: 427.5674 - val_loss: 288808.0000 - val_mean_squared_error: 288808.0000 - val_mean_absolute_error: 452.9360\n",
      "Epoch 1033/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 429038.9375 - mean_squared_error: 429038.9375 - mean_absolute_error: 482.0998\n",
      "Epoch 01033: val_loss improved from 288808.00000 to 288741.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 370867.3415 - mean_squared_error: 370867.3438 - mean_absolute_error: 427.1731 - val_loss: 288741.5000 - val_mean_squared_error: 288741.5000 - val_mean_absolute_error: 452.5878\n",
      "Epoch 1034/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 158397.7188 - mean_squared_error: 158397.7188 - mean_absolute_error: 330.5100\n",
      "Epoch 01034: val_loss improved from 288741.50000 to 288696.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 370681.0588 - mean_squared_error: 370681.0625 - mean_absolute_error: 426.8621 - val_loss: 288696.5000 - val_mean_squared_error: 288696.5000 - val_mean_absolute_error: 452.5068\n",
      "Epoch 1035/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 159433.2188 - mean_squared_error: 159433.2188 - mean_absolute_error: 336.2915\n",
      "Epoch 01035: val_loss improved from 288696.50000 to 288656.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 370448.8458 - mean_squared_error: 370448.8125 - mean_absolute_error: 426.7161 - val_loss: 288656.5625 - val_mean_squared_error: 288656.5625 - val_mean_absolute_error: 452.5808\n",
      "Epoch 1036/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 383240.0000 - mean_squared_error: 383240.0000 - mean_absolute_error: 445.9848\n",
      "Epoch 01036: val_loss improved from 288656.56250 to 288616.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 370216.8015 - mean_squared_error: 370216.7812 - mean_absolute_error: 426.6208 - val_loss: 288616.0625 - val_mean_squared_error: 288616.0625 - val_mean_absolute_error: 452.6586\n",
      "Epoch 1037/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 246579.3125 - mean_squared_error: 246579.3125 - mean_absolute_error: 363.6072\n",
      "Epoch 01037: val_loss improved from 288616.06250 to 288573.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 369914.2665 - mean_squared_error: 369914.2500 - mean_absolute_error: 426.4518 - val_loss: 288573.4688 - val_mean_squared_error: 288573.4688 - val_mean_absolute_error: 452.7451\n",
      "Epoch 1038/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 284704.7500 - mean_squared_error: 284704.7500 - mean_absolute_error: 405.9095\n",
      "Epoch 01038: val_loss improved from 288573.46875 to 288543.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 369571.4853 - mean_squared_error: 369571.4688 - mean_absolute_error: 426.3354 - val_loss: 288543.2188 - val_mean_squared_error: 288543.2188 - val_mean_absolute_error: 452.9297\n",
      "Epoch 1039/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 464573.4062 - mean_squared_error: 464573.4062 - mean_absolute_error: 467.2123\n",
      "Epoch 01039: val_loss improved from 288543.21875 to 288530.71875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 369447.9416 - mean_squared_error: 369447.9375 - mean_absolute_error: 426.4510 - val_loss: 288530.7188 - val_mean_squared_error: 288530.7188 - val_mean_absolute_error: 453.2424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 528177.6875 - mean_squared_error: 528177.6875 - mean_absolute_error: 534.5735\n",
      "Epoch 01040: val_loss improved from 288530.71875 to 288500.96875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 323us/sample - loss: 369029.1025 - mean_squared_error: 369029.0938 - mean_absolute_error: 426.2827 - val_loss: 288500.9688 - val_mean_squared_error: 288500.9688 - val_mean_absolute_error: 453.3050\n",
      "Epoch 1041/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 428452.3125 - mean_squared_error: 428452.3125 - mean_absolute_error: 465.2978\n",
      "Epoch 01041: val_loss improved from 288500.96875 to 288455.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 368790.6342 - mean_squared_error: 368790.6562 - mean_absolute_error: 426.1745 - val_loss: 288455.3750 - val_mean_squared_error: 288455.3750 - val_mean_absolute_error: 453.1879\n",
      "Epoch 1042/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 412060.8750 - mean_squared_error: 412060.8750 - mean_absolute_error: 456.4305\n",
      "Epoch 01042: val_loss improved from 288455.37500 to 288396.18750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 368525.7376 - mean_squared_error: 368525.7500 - mean_absolute_error: 425.9426 - val_loss: 288396.1875 - val_mean_squared_error: 288396.1875 - val_mean_absolute_error: 452.9320\n",
      "Epoch 1043/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 452369.1562 - mean_squared_error: 452369.1562 - mean_absolute_error: 452.7121\n",
      "Epoch 01043: val_loss improved from 288396.18750 to 288333.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 368301.2978 - mean_squared_error: 368301.3125 - mean_absolute_error: 425.6442 - val_loss: 288333.4688 - val_mean_squared_error: 288333.4688 - val_mean_absolute_error: 452.6233\n",
      "Epoch 1044/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 506067.8125 - mean_squared_error: 506067.8125 - mean_absolute_error: 506.4830\n",
      "Epoch 01044: val_loss improved from 288333.46875 to 288282.90625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 368145.2059 - mean_squared_error: 368145.2188 - mean_absolute_error: 425.3992 - val_loss: 288282.9062 - val_mean_squared_error: 288282.9062 - val_mean_absolute_error: 452.3789\n",
      "Epoch 1045/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 464260.8125 - mean_squared_error: 464260.8125 - mean_absolute_error: 451.5671\n",
      "Epoch 01045: val_loss improved from 288282.90625 to 288261.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 367943.1434 - mean_squared_error: 367943.1562 - mean_absolute_error: 425.1818 - val_loss: 288261.8750 - val_mean_squared_error: 288261.8750 - val_mean_absolute_error: 452.3975\n",
      "Epoch 1046/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 152193.3438 - mean_squared_error: 152193.3438 - mean_absolute_error: 321.2708\n",
      "Epoch 01046: val_loss improved from 288261.87500 to 288243.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 440us/sample - loss: 367709.9412 - mean_squared_error: 367709.9375 - mean_absolute_error: 425.0603 - val_loss: 288243.0625 - val_mean_squared_error: 288243.0625 - val_mean_absolute_error: 452.3905\n",
      "Epoch 1047/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 138949.5312 - mean_squared_error: 138949.5312 - mean_absolute_error: 290.8001\n",
      "Epoch 01047: val_loss improved from 288243.06250 to 288218.56250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 367525.3428 - mean_squared_error: 367525.3125 - mean_absolute_error: 424.9591 - val_loss: 288218.5625 - val_mean_squared_error: 288218.5625 - val_mean_absolute_error: 452.3195\n",
      "Epoch 1048/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 620407.7500 - mean_squared_error: 620407.7500 - mean_absolute_error: 549.1772\n",
      "Epoch 01048: val_loss improved from 288218.56250 to 288177.62500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 367397.4320 - mean_squared_error: 367397.4375 - mean_absolute_error: 424.8323 - val_loss: 288177.6250 - val_mean_squared_error: 288177.6250 - val_mean_absolute_error: 452.1128\n",
      "Epoch 1049/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 503404.1875 - mean_squared_error: 503404.1875 - mean_absolute_error: 499.4070\n",
      "Epoch 01049: val_loss improved from 288177.62500 to 288132.65625, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 367184.4729 - mean_squared_error: 367184.4688 - mean_absolute_error: 424.5540 - val_loss: 288132.6562 - val_mean_squared_error: 288132.6562 - val_mean_absolute_error: 451.8347\n",
      "Epoch 1050/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 379951.0000 - mean_squared_error: 379951.0000 - mean_absolute_error: 423.8349\n",
      "Epoch 01050: val_loss improved from 288132.65625 to 288077.34375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 381us/sample - loss: 367050.1484 - mean_squared_error: 367050.1562 - mean_absolute_error: 424.3103 - val_loss: 288077.3438 - val_mean_squared_error: 288077.3438 - val_mean_absolute_error: 451.4552\n",
      "Epoch 1051/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 314830.3438 - mean_squared_error: 314830.3438 - mean_absolute_error: 422.7620\n",
      "Epoch 01051: val_loss improved from 288077.34375 to 288015.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 366888.3971 - mean_squared_error: 366888.3750 - mean_absolute_error: 423.9934 - val_loss: 288015.3750 - val_mean_squared_error: 288015.3750 - val_mean_absolute_error: 451.0051\n",
      "Epoch 1052/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 335011.7500 - mean_squared_error: 335011.7500 - mean_absolute_error: 406.0233\n",
      "Epoch 01052: val_loss improved from 288015.37500 to 287954.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 366819.2261 - mean_squared_error: 366819.2500 - mean_absolute_error: 423.6895 - val_loss: 287954.1250 - val_mean_squared_error: 287954.1250 - val_mean_absolute_error: 450.5178\n",
      "Epoch 1053/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 292817.3750 - mean_squared_error: 292817.3750 - mean_absolute_error: 386.4734\n",
      "Epoch 01053: val_loss improved from 287954.12500 to 287905.21875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 366736.7224 - mean_squared_error: 366736.7500 - mean_absolute_error: 423.4280 - val_loss: 287905.2188 - val_mean_squared_error: 287905.2188 - val_mean_absolute_error: 450.1389\n",
      "Epoch 1054/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 293282.8125 - mean_squared_error: 293282.8125 - mean_absolute_error: 354.5797\n",
      "Epoch 01054: val_loss improved from 287905.21875 to 287877.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 366566.3456 - mean_squared_error: 366566.3125 - mean_absolute_error: 423.1197 - val_loss: 287877.5000 - val_mean_squared_error: 287877.5000 - val_mean_absolute_error: 450.0139\n",
      "Epoch 1055/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 297556.8438 - mean_squared_error: 297556.8438 - mean_absolute_error: 422.1140\n",
      "Epoch 01055: val_loss improved from 287877.50000 to 287874.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 366350.1379 - mean_squared_error: 366350.1562 - mean_absolute_error: 422.9994 - val_loss: 287874.0938 - val_mean_squared_error: 287874.0938 - val_mean_absolute_error: 450.1982\n",
      "Epoch 1056/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 596761.0000 - mean_squared_error: 596761.0000 - mean_absolute_error: 534.5904\n",
      "Epoch 01056: val_loss improved from 287874.09375 to 287862.87500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 366210.4246 - mean_squared_error: 366210.4062 - mean_absolute_error: 422.9803 - val_loss: 287862.8750 - val_mean_squared_error: 287862.8750 - val_mean_absolute_error: 450.2640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1057/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 546229.5000 - mean_squared_error: 546229.5000 - mean_absolute_error: 458.9839\n",
      "Epoch 01057: val_loss improved from 287862.87500 to 287837.12500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 365880.0207 - mean_squared_error: 365880.0312 - mean_absolute_error: 422.8130 - val_loss: 287837.1250 - val_mean_squared_error: 287837.1250 - val_mean_absolute_error: 450.1519\n",
      "Epoch 1058/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 367070.1875 - mean_squared_error: 367070.1875 - mean_absolute_error: 435.3965\n",
      "Epoch 01058: val_loss improved from 287837.12500 to 287809.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 365666.0744 - mean_squared_error: 365666.0938 - mean_absolute_error: 422.6606 - val_loss: 287809.2812 - val_mean_squared_error: 287809.2812 - val_mean_absolute_error: 449.9896\n",
      "Epoch 1059/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 563242.5625 - mean_squared_error: 563242.5625 - mean_absolute_error: 502.4565\n",
      "Epoch 01059: val_loss improved from 287809.28125 to 287779.46875, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 365556.2822 - mean_squared_error: 365556.2812 - mean_absolute_error: 422.5448 - val_loss: 287779.4688 - val_mean_squared_error: 287779.4688 - val_mean_absolute_error: 449.8174\n",
      "Epoch 1060/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 170133.2500 - mean_squared_error: 170133.2500 - mean_absolute_error: 327.0757\n",
      "Epoch 01060: val_loss improved from 287779.46875 to 287744.06250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 365362.2518 - mean_squared_error: 365362.2500 - mean_absolute_error: 422.3893 - val_loss: 287744.0625 - val_mean_squared_error: 287744.0625 - val_mean_absolute_error: 449.5807\n",
      "Epoch 1061/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 298591.4062 - mean_squared_error: 298591.4062 - mean_absolute_error: 354.7778\n",
      "Epoch 01061: val_loss improved from 287744.06250 to 287701.31250, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 352us/sample - loss: 365253.8975 - mean_squared_error: 365253.9062 - mean_absolute_error: 422.2561 - val_loss: 287701.3125 - val_mean_squared_error: 287701.3125 - val_mean_absolute_error: 449.2753\n",
      "Epoch 1062/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 413217.3750 - mean_squared_error: 413217.3750 - mean_absolute_error: 453.7681\n",
      "Epoch 01062: val_loss improved from 287701.31250 to 287671.68750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 365197.5092 - mean_squared_error: 365197.5000 - mean_absolute_error: 422.1264 - val_loss: 287671.6875 - val_mean_squared_error: 287671.6875 - val_mean_absolute_error: 449.0919\n",
      "Epoch 1063/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 374246.7188 - mean_squared_error: 374246.7188 - mean_absolute_error: 425.8517\n",
      "Epoch 01063: val_loss improved from 287671.68750 to 287660.78125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 411us/sample - loss: 365090.6103 - mean_squared_error: 365090.6250 - mean_absolute_error: 422.0168 - val_loss: 287660.7812 - val_mean_squared_error: 287660.7812 - val_mean_absolute_error: 449.1399\n",
      "Epoch 1064/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 287587.1250 - mean_squared_error: 287587.1250 - mean_absolute_error: 400.1989\n",
      "Epoch 01064: val_loss did not improve from 287660.78125\n",
      "68/68 [==============================] - 0s 205us/sample - loss: 364937.8658 - mean_squared_error: 364937.8750 - mean_absolute_error: 421.9925 - val_loss: 287664.3125 - val_mean_squared_error: 287664.3125 - val_mean_absolute_error: 449.3774\n",
      "Epoch 1065/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 354888.4375 - mean_squared_error: 354888.4375 - mean_absolute_error: 411.5765\n",
      "Epoch 01065: val_loss did not improve from 287660.78125\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 364825.8888 - mean_squared_error: 364825.8750 - mean_absolute_error: 422.0056 - val_loss: 287667.8750 - val_mean_squared_error: 287667.8750 - val_mean_absolute_error: 449.6889\n",
      "Epoch 1066/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 324216.5625 - mean_squared_error: 324216.5625 - mean_absolute_error: 382.5465\n",
      "Epoch 01066: val_loss did not improve from 287660.78125\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 364681.1949 - mean_squared_error: 364681.2188 - mean_absolute_error: 422.0135 - val_loss: 287668.0000 - val_mean_squared_error: 287668.0000 - val_mean_absolute_error: 449.9047\n",
      "Epoch 1067/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 627054.5625 - mean_squared_error: 627054.5625 - mean_absolute_error: 562.8140\n",
      "Epoch 01067: val_loss did not improve from 287660.78125\n",
      "68/68 [==============================] - 0s 235us/sample - loss: 364602.3481 - mean_squared_error: 364602.3438 - mean_absolute_error: 421.9759 - val_loss: 287672.2188 - val_mean_squared_error: 287672.2188 - val_mean_absolute_error: 450.1809\n",
      "Epoch 1068/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 592321.3750 - mean_squared_error: 592321.3750 - mean_absolute_error: 538.4137\n",
      "Epoch 01068: val_loss did not improve from 287660.78125\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 364406.6199 - mean_squared_error: 364406.6250 - mean_absolute_error: 421.9464 - val_loss: 287667.3438 - val_mean_squared_error: 287667.3438 - val_mean_absolute_error: 450.3211\n",
      "Epoch 1069/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 545588.6875 - mean_squared_error: 545588.6875 - mean_absolute_error: 484.6676\n",
      "Epoch 01069: val_loss improved from 287660.78125 to 287655.09375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 364268.5524 - mean_squared_error: 364268.5625 - mean_absolute_error: 421.9269 - val_loss: 287655.0938 - val_mean_squared_error: 287655.0938 - val_mean_absolute_error: 450.3373\n",
      "Epoch 1070/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 462308.3750 - mean_squared_error: 462308.3750 - mean_absolute_error: 463.3895\n",
      "Epoch 01070: val_loss improved from 287655.09375 to 287638.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 425us/sample - loss: 364111.4003 - mean_squared_error: 364111.4062 - mean_absolute_error: 421.8265 - val_loss: 287638.3750 - val_mean_squared_error: 287638.3750 - val_mean_absolute_error: 450.2749\n",
      "Epoch 1071/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 424405.6875 - mean_squared_error: 424405.6875 - mean_absolute_error: 462.4631\n",
      "Epoch 01071: val_loss improved from 287638.37500 to 287622.37500, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 367us/sample - loss: 364004.6581 - mean_squared_error: 364004.6562 - mean_absolute_error: 421.7239 - val_loss: 287622.3750 - val_mean_squared_error: 287622.3750 - val_mean_absolute_error: 450.2121\n",
      "Epoch 1072/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 280729.8125 - mean_squared_error: 280729.8125 - mean_absolute_error: 385.4016\n",
      "Epoch 01072: val_loss improved from 287622.37500 to 287617.50000, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 363895.7399 - mean_squared_error: 363895.7500 - mean_absolute_error: 421.6511 - val_loss: 287617.5000 - val_mean_squared_error: 287617.5000 - val_mean_absolute_error: 450.2946\n",
      "Epoch 1073/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 198439.4531 - mean_squared_error: 198439.4531 - mean_absolute_error: 353.1022\n",
      "Epoch 01073: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 363787.5221 - mean_squared_error: 363787.5312 - mean_absolute_error: 421.6295 - val_loss: 287621.6562 - val_mean_squared_error: 287621.6562 - val_mean_absolute_error: 450.5020\n",
      "Epoch 1074/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/68 [=============>................] - ETA: 0s - loss: 373300.6562 - mean_squared_error: 373300.6562 - mean_absolute_error: 422.2422\n",
      "Epoch 01074: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 363667.4090 - mean_squared_error: 363667.3750 - mean_absolute_error: 421.6158 - val_loss: 287626.0312 - val_mean_squared_error: 287626.0312 - val_mean_absolute_error: 450.7505\n",
      "Epoch 1075/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 436426.9375 - mean_squared_error: 436426.9375 - mean_absolute_error: 433.5117\n",
      "Epoch 01075: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 176us/sample - loss: 363488.5662 - mean_squared_error: 363488.5625 - mean_absolute_error: 421.5316 - val_loss: 287628.7188 - val_mean_squared_error: 287628.7188 - val_mean_absolute_error: 450.9271\n",
      "Epoch 1076/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 149238.5312 - mean_squared_error: 149238.5312 - mean_absolute_error: 320.3176\n",
      "Epoch 01076: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 363266.4632 - mean_squared_error: 363266.4688 - mean_absolute_error: 421.4642 - val_loss: 287643.0625 - val_mean_squared_error: 287643.0625 - val_mean_absolute_error: 451.2176\n",
      "Epoch 1077/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 240405.3594 - mean_squared_error: 240405.3594 - mean_absolute_error: 360.6915\n",
      "Epoch 01077: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 363058.6471 - mean_squared_error: 363058.6562 - mean_absolute_error: 421.4379 - val_loss: 287679.3750 - val_mean_squared_error: 287679.3750 - val_mean_absolute_error: 451.7076\n",
      "Epoch 1078/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 604856.1875 - mean_squared_error: 604856.1875 - mean_absolute_error: 551.2122\n",
      "Epoch 01078: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 191us/sample - loss: 362951.2675 - mean_squared_error: 362951.2812 - mean_absolute_error: 421.4276 - val_loss: 287729.8750 - val_mean_squared_error: 287729.8750 - val_mean_absolute_error: 452.2542\n",
      "Epoch 1079/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 259906.6406 - mean_squared_error: 259906.6406 - mean_absolute_error: 368.1220\n",
      "Epoch 01079: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 191us/sample - loss: 362641.0455 - mean_squared_error: 362641.0312 - mean_absolute_error: 421.4304 - val_loss: 287773.3750 - val_mean_squared_error: 287773.3750 - val_mean_absolute_error: 452.6668\n",
      "Epoch 1080/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 268031.7188 - mean_squared_error: 268031.7188 - mean_absolute_error: 388.9099\n",
      "Epoch 01080: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 362374.1176 - mean_squared_error: 362374.1250 - mean_absolute_error: 421.4005 - val_loss: 287837.6250 - val_mean_squared_error: 287837.6250 - val_mean_absolute_error: 453.2176\n",
      "Epoch 1081/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 410191.9688 - mean_squared_error: 410191.9688 - mean_absolute_error: 420.9542\n",
      "Epoch 01081: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 191us/sample - loss: 362210.2923 - mean_squared_error: 362210.2500 - mean_absolute_error: 421.4023 - val_loss: 287914.5625 - val_mean_squared_error: 287914.5625 - val_mean_absolute_error: 453.8247\n",
      "Epoch 1082/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 436839.1250 - mean_squared_error: 436839.1250 - mean_absolute_error: 438.1245\n",
      "Epoch 01082: val_loss did not improve from 287617.50000\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 361971.7684 - mean_squared_error: 361971.7500 - mean_absolute_error: 421.3386 - val_loss: 287977.6875 - val_mean_squared_error: 287977.6875 - val_mean_absolute_error: 454.2855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d418bfd978>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=trainingData_features,\n",
    "          y=trainingData_label,\n",
    "          batch_size=32,\n",
    "          epochs=2000,\n",
    "          validation_split=0.2,\n",
    "          callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\User\\\\Python_ST_EX\\\\Session05-2 - Learn DL'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 13:47:28.304024  9340 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "21/21 [==============================] - 0s 0s/sample - loss: 390382.2812 - mean_squared_error: 390382.2812 - mean_absolute_error: 489.6915\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[390382.28125, 390382.28, 489.6915]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x=testData_features,\n",
    "              y=testData_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 13:47:30.580351  9340 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "21/21 [==============================] - 0s 95us/sample - loss: 390382.2812 - mean_squared_error: 390382.2812 - mean_absolute_error: 489.6915\n"
     ]
    }
   ],
   "source": [
    "lose, mse, mae = model.evaluate(x=testData_features,\n",
    "              y=testData_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 14:54:46.839422 15840 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    }
   ],
   "source": [
    "predictDf = pd.DataFrame(model.predict(testData_features), columns=[\"PREDICT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData_answer = testData_all.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalResult = pd.concat([testData_answer,predictDf],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>REGIONID</th>\n",
       "      <th>PRODUCTGROUP</th>\n",
       "      <th>PRODUCT</th>\n",
       "      <th>ITEM</th>\n",
       "      <th>YEARWEEK</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>WEEK</th>\n",
       "      <th>QTY</th>\n",
       "      <th>HOLIDAY</th>\n",
       "      <th>HCLUS</th>\n",
       "      <th>PROMOTION</th>\n",
       "      <th>PRO_PERCENT</th>\n",
       "      <th>LE_PROMO</th>\n",
       "      <th>LE_HORI</th>\n",
       "      <th>PREDICT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SEOUL_BANK_001</td>\n",
       "      <td>PG02</td>\n",
       "      <td>PRODUCT0010</td>\n",
       "      <td>ITEM0115</td>\n",
       "      <td>201634</td>\n",
       "      <td>2016</td>\n",
       "      <td>34</td>\n",
       "      <td>1700</td>\n",
       "      <td>Y</td>\n",
       "      <td>1</td>\n",
       "      <td>Y</td>\n",
       "      <td>0.308584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1710.857666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         REGIONID PRODUCTGROUP      PRODUCT      ITEM  YEARWEEK  YEAR  WEEK  \\\n",
       "0  SEOUL_BANK_001         PG02  PRODUCT0010  ITEM0115    201634  2016    34   \n",
       "\n",
       "    QTY HOLIDAY  HCLUS PROMOTION  PRO_PERCENT  LE_PROMO  LE_HORI      PREDICT  \n",
       "0  1700       Y      1         Y     0.308584         1        1  1710.857666  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalResult.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 14)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testData_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights(\"linear_keras_sellout.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 불러 와서 기존 데이터로 재 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기 for문으로 합침\n",
    "from tensorflow.keras.models import model_from_json \n",
    "\n",
    "json_file = open(\"model.json\", \"r\") \n",
    "loaded_model_json = json_file.read() \n",
    "json_file.close() \n",
    "\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "loaded_model.load_weights(\"linear_keras_sellout.h5\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 121\n",
      "Trainable params: 121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequatial 방싱 케라스모델\n",
    "# 손실함수(LOSS): 훈련동안 최소화될 값 지표 (mse, categorical_crossentropy)\n",
    "# 손실함수를 기반으로 Neural Net 업데이터 결정 (mse, mae, accuracy)\n",
    "# 위로 합침\n",
    "loaded_model.compile(loss='mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error','mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'logs\\\\20191015_145332'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "log_folder = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "log_dirs = os.path.join(\"logs\",log_folder)\n",
    "log_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1015 14:53:33.905218 15840 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68 samples, validate on 18 samples\n",
      "Epoch 1/2000\n",
      "64/68 [===========================>..] - ETA: 0s - loss: 375646.5781 - mean_squared_error: 375646.5625 - mean_absolute_error: 431.7144\n",
      "Epoch 00001: val_loss improved from inf to 286152.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 3ms/sample - loss: 360175.0772 - mean_squared_error: 360175.0625 - mean_absolute_error: 421.7243 - val_loss: 286152.4375 - val_mean_squared_error: 286152.4375 - val_mean_absolute_error: 457.0770\n",
      "Epoch 2/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 471787.7812 - mean_squared_error: 471787.7812 - mean_absolute_error: 469.8833\n",
      "Epoch 00002: val_loss improved from 286152.43750 to 286116.28125, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 456us/sample - loss: 359814.3309 - mean_squared_error: 359814.3438 - mean_absolute_error: 421.4568 - val_loss: 286116.2812 - val_mean_squared_error: 286116.2812 - val_mean_absolute_error: 456.5971\n",
      "Epoch 3/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 382179.5312 - mean_squared_error: 382179.5312 - mean_absolute_error: 424.8364\n",
      "Epoch 00003: val_loss improved from 286116.28125 to 286021.43750, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 396us/sample - loss: 359631.6103 - mean_squared_error: 359631.6250 - mean_absolute_error: 421.1478 - val_loss: 286021.4375 - val_mean_squared_error: 286021.4375 - val_mean_absolute_error: 455.9868\n",
      "Epoch 4/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 249730.4375 - mean_squared_error: 249730.4375 - mean_absolute_error: 351.1183\n",
      "Epoch 00004: val_loss improved from 286021.43750 to 285961.84375, saving model to ./model_r_weights.h5\n",
      "68/68 [==============================] - 0s 337us/sample - loss: 359632.9706 - mean_squared_error: 359632.9375 - mean_absolute_error: 420.9677 - val_loss: 285961.8438 - val_mean_squared_error: 285961.8438 - val_mean_absolute_error: 455.5000\n",
      "Epoch 5/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 421844.2812 - mean_squared_error: 421844.2812 - mean_absolute_error: 418.6972\n",
      "Epoch 00005: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 359465.0000 - mean_squared_error: 359465.0000 - mean_absolute_error: 420.7617 - val_loss: 286000.8438 - val_mean_squared_error: 286000.8438 - val_mean_absolute_error: 455.7233\n",
      "Epoch 6/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 401333.8125 - mean_squared_error: 401333.8125 - mean_absolute_error: 437.0335\n",
      "Epoch 00006: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 359307.4357 - mean_squared_error: 359307.4062 - mean_absolute_error: 420.7560 - val_loss: 286084.8750 - val_mean_squared_error: 286084.8750 - val_mean_absolute_error: 456.2373\n",
      "Epoch 7/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 387013.0938 - mean_squared_error: 387013.0938 - mean_absolute_error: 428.0275\n",
      "Epoch 00007: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 359078.0469 - mean_squared_error: 359078.0312 - mean_absolute_error: 420.6875 - val_loss: 286144.7188 - val_mean_squared_error: 286144.7188 - val_mean_absolute_error: 456.4525\n",
      "Epoch 8/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 335840.2500 - mean_squared_error: 335840.2500 - mean_absolute_error: 394.4047\n",
      "Epoch 00008: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 358876.0450 - mean_squared_error: 358876.0625 - mean_absolute_error: 420.6096 - val_loss: 286152.6250 - val_mean_squared_error: 286152.6250 - val_mean_absolute_error: 456.3616\n",
      "Epoch 9/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 417955.3125 - mean_squared_error: 417955.3125 - mean_absolute_error: 419.4542\n",
      "Epoch 00009: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 358702.8125 - mean_squared_error: 358702.8125 - mean_absolute_error: 420.4227 - val_loss: 286127.6250 - val_mean_squared_error: 286127.6250 - val_mean_absolute_error: 456.0463\n",
      "Epoch 10/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 290583.8750 - mean_squared_error: 290583.8750 - mean_absolute_error: 407.9588\n",
      "Epoch 00010: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 191us/sample - loss: 358662.4265 - mean_squared_error: 358662.4062 - mean_absolute_error: 420.2660 - val_loss: 286107.4375 - val_mean_squared_error: 286107.4375 - val_mean_absolute_error: 455.7148\n",
      "Epoch 11/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 358117.5625 - mean_squared_error: 358117.5625 - mean_absolute_error: 422.1991\n",
      "Epoch 00011: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 147us/sample - loss: 358505.6903 - mean_squared_error: 358505.6875 - mean_absolute_error: 420.1646 - val_loss: 286161.7812 - val_mean_squared_error: 286161.7812 - val_mean_absolute_error: 455.8914\n",
      "Epoch 12/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 300421.9375 - mean_squared_error: 300421.9375 - mean_absolute_error: 420.4631\n",
      "Epoch 00012: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 358277.2992 - mean_squared_error: 358277.2812 - mean_absolute_error: 420.0124 - val_loss: 286189.6562 - val_mean_squared_error: 286189.6562 - val_mean_absolute_error: 455.8731\n",
      "Epoch 13/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 156080.3594 - mean_squared_error: 156080.3594 - mean_absolute_error: 334.5864\n",
      "Epoch 00013: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 132us/sample - loss: 358126.7022 - mean_squared_error: 358126.7188 - mean_absolute_error: 419.9197 - val_loss: 286233.2812 - val_mean_squared_error: 286233.2812 - val_mean_absolute_error: 455.9514\n",
      "Epoch 14/2000\n",
      "32/68 [=============>................] - ETA: 0s - loss: 264784.0000 - mean_squared_error: 264784.0000 - mean_absolute_error: 360.1927\n",
      "Epoch 00014: val_loss did not improve from 285961.84375\n",
      "68/68 [==============================] - 0s 161us/sample - loss: 357931.9547 - mean_squared_error: 357931.9375 - mean_absolute_error: 419.7830 - val_loss: 286304.0000 - val_mean_squared_error: 286304.0000 - val_mean_absolute_error: 456.2183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d416b2d320>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callback_list = [\n",
    "    TensorBoard(log_dir = log_dirs),\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10), \n",
    "    ModelCheckpoint(filepath=\"./model_r_weights.h5\", monitor=\"val_loss\", verbose=1, save_best_only=True)   \n",
    "]\n",
    "\n",
    "loaded_model.fit(x=trainingData_features,\n",
    "                 y=trainingData_label,\n",
    "                 batch_size=32,\n",
    "                 epochs=2000,\n",
    "                 validation_split=0.2,\n",
    "                 callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_cluster=0\n",
    "promotion_ratio=0.6\n",
    "promotion_yn=1\n",
    "holiday_yn=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1  2  3\n",
       "0  0  0.6  1  1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampledata = pd.DataFrame([[holiday_cluster,promotion_ratio,promotion_yn,holiday_yn]])\n",
    "sampledata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1015 14:53:38.686449 15840 training.py:504] Falling back from v2 loop because of error: Failed to find data adapter that can handle input: <class 'pandas.core.frame.DataFrame'>, <class 'NoneType'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1897.0986]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(sampledata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
